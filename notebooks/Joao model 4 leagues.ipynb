{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ede83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaosantos/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063e9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab05bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1cb3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(league1, wall=False):\n",
    "    \n",
    "    if wall:\n",
    "        data = pd.DataFrame()\n",
    "        leagues = listdir(f'./../raw_data4/')\n",
    "        data = pd.DataFrame()\n",
    "        for league in leagues:\n",
    "            files = listdir(f'./../raw_data4/{league}')\n",
    "            for file in files:\n",
    "                df = pd.read_csv((f'./../raw_data4/{league}/'+file))\n",
    "                data = pd.concat([data, df])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        files = [file for file in listdir(f'./../raw_data4/{league1}')]\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "        for file in files:\n",
    "            df = pd.read_csv(f'./../raw_data4/{league1}/'+file)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22ecaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('italy', wall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "        '''\n",
    "    #------------------------Number of Goals, Over and Under -----------------------------------\n",
    "    \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "    \n",
    "    #-----------------------------Payout Opening ----------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average OPENING odds\n",
    "    data['payout_avg_under_2.5'] = data['under_2.5_goals']*data['Avg<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average OPENING odds\n",
    "    data['payout_avg_over_2.5'] = data['over_2.5_goals']*data['Avg>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['P<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['P>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365>2.5']\n",
    "    \n",
    "    #------------------------------Payout Closing --------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_under_closing_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_over_closing_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE closing ddds specifically\n",
    "    data['payout_under_2.5_pinacle_closing'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE closing odds specifically\n",
    "    data['payout_over_2.5_pinacle_closing'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 closing odds specifically\n",
    "    data['payout_under_2.5_365_closing'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 closing odds specifically\n",
    "    data['payout_over_2.5_365_closing'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #-------------------------- Implied Probability Opening ----------------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability <2.5 avg']=1/data['Avg<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability >2.5 avg']=1/data['Avg>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['P<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['P>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365>2.5']*100\n",
    "    \n",
    "    #------------------------- Implied Probability Closing -----------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability <2.5 avg closing']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability >2.5 avg closing']=1/data['AvgC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability <2.5 pinacle closing']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability >2.5 pinacle closing']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability <2.5 365 closing']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability >2.5 365 closing']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    #---------------------------- Binning IP Opening -------------------------------------\n",
    "\n",
    "    b=b\n",
    "    bins = np.arange(0, 101, int(100/b))\n",
    "    bins = bins.tolist()\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned <2.5 avg'] = pd.cut(data['Implied Probability <2.5 avg'], bins)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned >2.5 avg'] = pd.cut(data['Implied Probability >2.5 avg'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "    \n",
    "    #----------------------------- Binning IP Closing ------------------------------------------------\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market closing odds\n",
    "    data['binned <2.5 avg closing'] = pd.cut(data['Implied Probability <2.5 avg closing'], bins)\n",
    "\n",
    "    #Binning OVER 2.5 Average Market closing odds\n",
    "    data['binned >2.5 avg closing'] = pd.cut(data['Implied Probability >2.5 avg closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle closing odds\n",
    "    data['binned <2.5 pinacle closing'] = pd.cut(data['Implied Probability <2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle CLOSING odds\n",
    "    data['binned >2.5 pinacle closing'] = pd.cut(data['Implied Probability >2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 CLOSING odds\n",
    "    data['binned <2.5 365 closing'] = pd.cut(data['Implied Probability <2.5 365 closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 CLOSING odds\n",
    "    data['binned >2.5 365 closing'] = pd.cut(data['Implied Probability >2.5 365 closing'], bins)\n",
    "    \n",
    "    #---------------------------- Binning Odds Opening ----------------------------------------------------\n",
    "    \n",
    "    bins2 = [1, 1.5, 2, 3, 99999]\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle'] = pd.cut(data['P<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle'] = pd.cut(data['P>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365'] = pd.cut(data['B365<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365'] = pd.cut(data['B365>2.5'], bins2)\n",
    "    \n",
    "    #----------------------------- Binning Odds Closing ----------------------------------------------------------\n",
    "    \n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg closing'] = pd.cut(data['AvgC<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg closing'] = pd.cut(data['AvgC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle closing'] = pd.cut(data['PC<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle closing'] = pd.cut(data['PC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365 closing'] = pd.cut(data['B365C<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365 closing'] = pd.cut(data['B365C>2.5'], bins2)\n",
    "    \n",
    "    \n",
    "    #----------------------------- Other Features from D3 ------------------------------------------------------\n",
    "    \n",
    "    data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "    data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "    data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "    data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "    data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "    data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "    \n",
    "    #----------------------- Odds and probability of the home team scoring under 2.5 -------------------------------\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    \n",
    "    lst1 = []\n",
    "    lst2 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst1.append(1/(n_under_home[1]/total))\n",
    "            lst2.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst1.append(np.nan)\n",
    "            lst2.append(np.nan)\n",
    "\n",
    "    data['odds_home_under'] = lst1\n",
    "    data['prob_home_under'] = lst2\n",
    "    \n",
    "    \n",
    "    \n",
    "    #----------------------- Odds and probability of the away team scoring under 2.5 -------------------------------\n",
    "    \n",
    "    lst3 = []\n",
    "    lst4  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst3.append(1/(n_under_away2[1] / total2))\n",
    "            lst4.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst3.append(np.nan)\n",
    "            lst4.append(np.nan)\n",
    "\n",
    "    data['odds_away_under'] = lst3\n",
    "    data['prob_away_under'] = lst4\n",
    "    \n",
    "        #----------------------- Odds and probability of the home team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst5 = []\n",
    "    lst6 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst5.append(1/(n_under_home[1]/total))\n",
    "            lst6.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst5.append(np.nan)\n",
    "            lst6.append(np.nan)\n",
    "\n",
    "    data['odds_home_over'] = lst5\n",
    "    data['prob_home_over'] = lst6\n",
    "    \n",
    "     #----------------------- Odds and probability of the away team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst7 = []\n",
    "    lst8  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst7.append(1/(n_under_away2[1] / total2))\n",
    "            lst8.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst7.append(np.nan)\n",
    "            lst8.append(np.nan)\n",
    "\n",
    "    data['odds_away_over'] = lst7\n",
    "    data['prob_away_over'] = lst8\n",
    "    \n",
    "    # -------------------- binning the odds and probability of the home and away teams under 2.5 ----------------------\n",
    "    if binned:\n",
    "\n",
    "        #------- Probability -------\n",
    "\n",
    "        #binning the probability of the home team to have a game of less than 2.5 score\n",
    "        data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, bins)\n",
    "\n",
    "        #binning the probability of the away team to have a game of less than 2.5 score\n",
    "        data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, bins)\n",
    "\n",
    "        #--------- Odds ------------\n",
    "        binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "\n",
    "        #binning the odds of the away team to have a game of less than 2.5 score\n",
    "        data['binned odds_away_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "\n",
    "        #binning the odds of the home team to have a game of less than 2.5 score\n",
    "        data['binned odds_home_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "\n",
    "\n",
    "        # -------------------- binning the odds and probability of the home and away teams over 2.5 ----------------------\n",
    "\n",
    "        #------- Probability -------\n",
    "\n",
    "        #binning the probability of the home team to have a game of less than 2.5 score\n",
    "        data['binned prob_home_over'] = pd.cut(data['prob_home_over']*100, bins)\n",
    "\n",
    "        #binning the probability of the away team to have a game of less than 2.5 score\n",
    "        data['binned prob_away_over'] = pd.cut(data['prob_away_over']*100, bins)\n",
    "\n",
    "        #--------- Odds ------------\n",
    "        binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "\n",
    "        #binning the odds of the away team to have a game of less than 2.5 score\n",
    "        data['binned odds_away_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "\n",
    "        #binning the odds of the home team to have a game of less than 2.5 score\n",
    "        data['binned odds_home_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "\n",
    "\n",
    "    #-------------------------- Creating the prob and odds of the game -----------------------------------------------\n",
    "    \n",
    "    #---------------- Under --------------\n",
    "    '''the mean between the probability of the home team to have a score of under 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data['odds_game_under'] = (data['odds_away_under'] +  data['odds_home_under']) / 2\n",
    "    data['prob_game_under'] = (data['prob_away_under'] + data['prob_home_under']) / 2\n",
    "    \n",
    "    #---------------- Over -------------\n",
    "\n",
    "    '''the mean between the probability of the home team to have a score of over 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data['odds_game_over'] = (data['odds_away_over'] +  data['odds_home_over']) / 2\n",
    "    data['prob_game_over'] = (data['prob_away_over'] + data['prob_home_over']) / 2\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned probabilities columns ------------------------------------------\n",
    "    \n",
    "    if binned:\n",
    "        if b == 5:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "\n",
    "        if b == 10:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "            data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "            data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "\n",
    "        if b == 20:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "            data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "            data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "            data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "            data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "            data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "            data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "\n",
    "    #-------------------------- OneHotEncoding the binned odds columns ------------------------------------------\n",
    "    \n",
    "        #-------------------- Under -----------------------                                       \n",
    "        data = data[~data['binned odds_away_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned odds_away_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned odds_away_under']])\n",
    "        data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "        data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "        data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "\n",
    "        #-------------------- Over -----------------------\n",
    "        data = data[~data['binned odds_away_over'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned odds_away_over']])\n",
    "        bins_encoded = ohe.transform(data[['binned odds_away_over']])\n",
    "        data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "        data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "        data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "    \n",
    "    #------------------------------------ Cleaning the data ---------------------------------------------------------\n",
    "    \n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data = data[~data['PC>2.5'].isna()]\n",
    "    #data.drop(columns=['Referee', 'Unnamed: 105'], inplace=True)\n",
    "    #data.dropna()\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365829f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_engineering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mfeature_engineering\u001b[0;34m(data, b, binned)\u001b[0m\n\u001b[1;32m    201\u001b[0m date \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[1;32m    202\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data[(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHomeTeam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m team) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m date)])\n\u001b[0;32m--> 203\u001b[0m n_under_home \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHomeTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mteam\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munder_2.5_goals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     lst1\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(n_under_home[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39mtotal))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/base.py:970\u001b[0m, in \u001b[0;36mIndexOpsMixin.value_counts\u001b[0;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_counts\u001b[39m(\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    886\u001b[0m     normalize: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    890\u001b[0m     dropna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    891\u001b[0m ):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;124;03m    Return a Series containing counts of unique values.\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/algorithms.py:874\u001b[0m, in \u001b[0;36mvalue_counts\u001b[0;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[1;32m    871\u001b[0m         result \u001b[38;5;241m=\u001b[39m Series(counts, index\u001b[38;5;241m=\u001b[39mkeys, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort:\n\u001b[0;32m--> 874\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m    877\u001b[0m     result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m/\u001b[39m counts\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/series.py:3528\u001b[0m, in \u001b[0;36mSeries.sort_values\u001b[0;34m(self, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   3525\u001b[0m values_to_sort \u001b[38;5;241m=\u001b[39m ensure_key_mapped(\u001b[38;5;28mself\u001b[39m, key)\u001b[38;5;241m.\u001b[39m_values \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   3526\u001b[0m sorted_index \u001b[38;5;241m=\u001b[39m nargsort(values_to_sort, kind, \u001b[38;5;28mbool\u001b[39m(ascending), na_position)\n\u001b[0;32m-> 3528\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43msorted_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43msorted_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[1;32m   3533\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(sorted_index))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/series.py:402\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    399\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# GH#13296 we are dealing with a compound dtype, which\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;66;03m#  should be treated as 2D\u001b[39;00m\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot construct a Series from an ndarray with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompound dtype.  Use DataFrame instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Series):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359d5081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20905, 177)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1774bbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.46\n",
       "1      1.50\n",
       "2      1.66\n",
       "3      0.00\n",
       "4      0.00\n",
       "       ... \n",
       "301    2.25\n",
       "302    0.00\n",
       "303    2.19\n",
       "304    0.00\n",
       "305    0.00\n",
       "Name: payout_under_2.5_pinacle_closing, Length: 20905, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = data['payout_under_2.5_pinacle_closing']\n",
    "data['payout_under_2.5_pinacle_closing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95312f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_away_under</th>\n",
       "      <th>odds_home_over</th>\n",
       "      <th>prob_home_over</th>\n",
       "      <th>odds_away_over</th>\n",
       "      <th>prob_away_over</th>\n",
       "      <th>odds_game_under</th>\n",
       "      <th>prob_game_under</th>\n",
       "      <th>odds_game_over</th>\n",
       "      <th>prob_game_over</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Dijon</td>\n",
       "      <td>Angers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Reims</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>2.511364</td>\n",
       "      <td>0.526190</td>\n",
       "      <td>3.015152</td>\n",
       "      <td>0.473810</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.904762</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Oostende</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1.823529</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>2.718254</td>\n",
       "      <td>0.380979</td>\n",
       "      <td>1.636765</td>\n",
       "      <td>0.619021</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Oud-Heverlee Leuven</td>\n",
       "      <td>Waasland-Beveren</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.953782</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.091346</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>St Truiden</td>\n",
       "      <td>Anderlecht</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.093750</td>\n",
       "      <td>0.480287</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.519713</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Beerschot VA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>2.735714</td>\n",
       "      <td>0.388438</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>0.611562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Waregem</td>\n",
       "      <td>Gent</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>2.579861</td>\n",
       "      <td>0.413237</td>\n",
       "      <td>1.758333</td>\n",
       "      <td>0.586763</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20905 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Div       Date   Time             HomeTeam          AwayTeam  FTHG  FTAG  \\\n",
       "0    F1 2020-08-21  18:00             Bordeaux            Nantes     0     0   \n",
       "1    F1 2020-08-22  16:00                Dijon            Angers     0     1   \n",
       "2    F1 2020-08-22  20:00                Lille            Rennes     1     1   \n",
       "3    F1 2020-08-23  12:00               Monaco             Reims     2     2   \n",
       "4    F1 2020-08-23  14:00              Lorient        Strasbourg     3     1   \n",
       "..   ..        ...    ...                  ...               ...   ...   ...   \n",
       "301  B1 2021-04-18  17:00             Oostende     Cercle Brugge     1     1   \n",
       "302  B1 2021-04-18  17:00  Oud-Heverlee Leuven  Waasland-Beveren     1     2   \n",
       "303  B1 2021-04-18  17:00           St Truiden        Anderlecht     0     1   \n",
       "304  B1 2021-04-18  17:00             Standard      Beerschot VA     3     0   \n",
       "305  B1 2021-04-18  17:00              Waregem              Gent     2     7   \n",
       "\n",
       "    FTR  HTHG  HTAG  ... prob_away_under  odds_home_over  prob_home_over  \\\n",
       "0     D   0.0   0.0  ...        0.533333        3.000000        0.333333   \n",
       "1     A   0.0   1.0  ...        0.466667        1.875000        0.533333   \n",
       "2     D   1.0   0.0  ...        0.800000        1.888889        0.529412   \n",
       "3     D   1.0   2.0  ...        0.785714        1.363636        0.733333   \n",
       "4     H   0.0   1.0  ...        0.600000        1.875000        0.533333   \n",
       "..   ..   ...   ...  ...             ...             ...             ...   \n",
       "301   D   0.0   0.0  ...        0.451613        1.450000        0.689655   \n",
       "302   A   0.0   1.0  ...        0.566667        1.875000        0.533333   \n",
       "303   A   0.0   0.0  ...        0.444444        2.066667        0.483871   \n",
       "304   H   1.0   0.0  ...        0.294118        1.933333        0.517241   \n",
       "305   A   0.0   3.0  ...        0.516129        1.450000        0.689655   \n",
       "\n",
       "     odds_away_over  prob_away_over  odds_game_under  prob_game_under  \\\n",
       "0          2.142857        0.466667         1.687500         0.600000   \n",
       "1          1.875000        0.533333         2.142857         0.466667   \n",
       "2          5.000000        0.200000         1.687500         0.635294   \n",
       "3          4.666667        0.214286         2.511364         0.526190   \n",
       "4          2.500000        0.400000         1.904762         0.533333   \n",
       "..              ...             ...              ...              ...   \n",
       "301        1.823529        0.548387         2.718254         0.380979   \n",
       "302        2.307692        0.433333         1.953782         0.516667   \n",
       "303        1.800000        0.555556         2.093750         0.480287   \n",
       "304        1.416667        0.705882         2.735714         0.388438   \n",
       "305        2.066667        0.483871         2.579861         0.413237   \n",
       "\n",
       "     odds_game_over  prob_game_over  target  \n",
       "0          2.571429        0.400000    True  \n",
       "1          1.875000        0.533333    True  \n",
       "2          3.444444        0.364706    True  \n",
       "3          3.015152        0.473810   False  \n",
       "4          2.187500        0.466667   False  \n",
       "..              ...             ...     ...  \n",
       "301        1.636765        0.619021    True  \n",
       "302        2.091346        0.483333   False  \n",
       "303        1.933333        0.519713    True  \n",
       "304        1.675000        0.611562   False  \n",
       "305        1.758333        0.586763   False  \n",
       "\n",
       "[20905 rows x 178 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a1dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['target'] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1d80f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features that we will use in the model to predict the under\n",
    "X = data[['odds_game_over', 'odds_game_under', 'PC<2.5', 'AvgC<2.5','PC>2.5', 'AvgC>2.5', 'Pin_pays_better_under_difference', '%vig_p', '%vig_avg', 'PC<2.5_P_relative_diff']]\n",
    "y = data['payout_under_2.5_pinacle_closing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f974e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalling our features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3190a1",
   "metadata": {},
   "source": [
    "## Under Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e5afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train/Test\n",
    "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7537a0bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit model in the training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_under_p \u001b[38;5;241m=\u001b[39m \u001b[43mXGBRegressor\u001b[49m(base_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, booster\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbtree\u001b[39m\u001b[38;5;124m'\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m               colsample_bylevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, colsample_bynode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, colsample_bytree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      4\u001b[0m               early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m               eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, gpu_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, grow_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepthwise\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m               importance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interaction_constraints\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m               learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0009012\u001b[39m, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, max_cat_to_onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      8\u001b[0m               max_delta_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, max_leaves\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_child_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, monotone_constraints\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      9\u001b[0m               n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_parallel_tree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     10\u001b[0m               reg_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, reg_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m model_under_p\u001b[38;5;241m.\u001b[39mfit(X_train_under, y_train_under)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XGBRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# fit model in the training data\n",
    "model_under_p = XGBRegressor(base_score=0.3, booster='gbtree', callbacks=None,\n",
    "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
    "              early_stopping_rounds=None, enable_categorical=False,\n",
    "              eval_metric=None, gamma=1, gpu_id=-1, grow_policy='depthwise',\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.0009012, max_bin=512, max_cat_to_onehot=4,\n",
    "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=3, monotone_constraints='()', n_estimators=100,\n",
    "              n_jobs=1, num_parallel_tree=1, predictor='auto', random_state=0,\n",
    "              reg_alpha=1, reg_lambda=1)\n",
    "model_under_p.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6c92f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation score: 1.00\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model_under_p, X_train_under, y_train_under,cv=10)\n",
    "print(\"Mean cross-validation score: %.2f\" % scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6668fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  1.0\n"
     ]
    }
   ],
   "source": [
    "score = model_under_p.score(X_train_under, y_train_under)  \n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e31e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28b37156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_under_p.predict(X_test_under)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39770e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "226+137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbaeb228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4181\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual = y_test_under - y_pred\n",
    "residual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb57b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe36e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test_under, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09306c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84790219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb6db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
