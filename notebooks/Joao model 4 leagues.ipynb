{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ede83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaosantos/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063e9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab05bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cb3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(league1, wall=False):\n",
    "    \n",
    "    if wall:\n",
    "        data = pd.DataFrame()\n",
    "        leagues = listdir(f'./../raw_data4/')\n",
    "        data = pd.DataFrame()\n",
    "        for league in leagues:\n",
    "            files = listdir(f'./../raw_data4/{league}')\n",
    "            for file in files:\n",
    "                df = pd.read_csv((f'./../raw_data4/{league}/'+file))\n",
    "                data = pd.concat([data, df])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        files = [file for file in listdir(f'./../raw_data4/{league1}')]\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "        for file in files:\n",
    "            df = pd.read_csv(f'./../raw_data4/{league1}/'+file)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22ecaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('italy', wall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "        '''\n",
    "    #------------------------Number of Goals, Over and Under -----------------------------------\n",
    "    \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "    \n",
    "    #-----------------------------Payout Opening ----------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average OPENING odds\n",
    "    data['payout_avg_under_2.5'] = data['under_2.5_goals']*data['Avg<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average OPENING odds\n",
    "    data['payout_avg_over_2.5'] = data['over_2.5_goals']*data['Avg>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['P<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['P>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365>2.5']\n",
    "    \n",
    "    #------------------------------Payout Closing --------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_under_closing_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_over_closing_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE closing ddds specifically\n",
    "    data['payout_under_2.5_pinacle_closing'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE closing odds specifically\n",
    "    data['payout_over_2.5_pinacle_closing'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 closing odds specifically\n",
    "    data['payout_under_2.5_365_closing'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 closing odds specifically\n",
    "    data['payout_over_2.5_365_closing'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #-------------------------- Implied Probability Opening ----------------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability <2.5 avg']=1/data['Avg<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability >2.5 avg']=1/data['Avg>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['P<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['P>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365>2.5']*100\n",
    "    \n",
    "    #------------------------- Implied Probability Closing -----------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability <2.5 avg closing']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability >2.5 avg closing']=1/data['AvgC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability <2.5 pinacle closing']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability >2.5 pinacle closing']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability <2.5 365 closing']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability >2.5 365 closing']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    #---------------------------- Binning IP Opening -------------------------------------\n",
    "\n",
    "    b=b\n",
    "    bins = np.arange(0, 101, int(100/b))\n",
    "    bins = bins.tolist()\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned <2.5 avg'] = pd.cut(data['Implied Probability <2.5 avg'], bins)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned >2.5 avg'] = pd.cut(data['Implied Probability >2.5 avg'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "    \n",
    "    #----------------------------- Binning IP Closing ------------------------------------------------\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market closing odds\n",
    "    data['binned <2.5 avg closing'] = pd.cut(data['Implied Probability <2.5 avg closing'], bins)\n",
    "\n",
    "    #Binning OVER 2.5 Average Market closing odds\n",
    "    data['binned >2.5 avg closing'] = pd.cut(data['Implied Probability >2.5 avg closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle closing odds\n",
    "    data['binned <2.5 pinacle closing'] = pd.cut(data['Implied Probability <2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle CLOSING odds\n",
    "    data['binned >2.5 pinacle closing'] = pd.cut(data['Implied Probability >2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 CLOSING odds\n",
    "    data['binned <2.5 365 closing'] = pd.cut(data['Implied Probability <2.5 365 closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 CLOSING odds\n",
    "    data['binned >2.5 365 closing'] = pd.cut(data['Implied Probability >2.5 365 closing'], bins)\n",
    "    \n",
    "    #---------------------------- Binning Odds Opening ----------------------------------------------------\n",
    "    \n",
    "    bins2 = [1, 1.5, 2, 3, 99999]\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle'] = pd.cut(data['P<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle'] = pd.cut(data['P>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365'] = pd.cut(data['B365<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365'] = pd.cut(data['B365>2.5'], bins2)\n",
    "    \n",
    "    #----------------------------- Binning Odds Closing ----------------------------------------------------------\n",
    "    \n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg closing'] = pd.cut(data['AvgC<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg closing'] = pd.cut(data['AvgC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle closing'] = pd.cut(data['PC<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle closing'] = pd.cut(data['PC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365 closing'] = pd.cut(data['B365C<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365 closing'] = pd.cut(data['B365C>2.5'], bins2)\n",
    "    \n",
    "    \n",
    "    #----------------------------- Other Features from D3 ------------------------------------------------------\n",
    "    \n",
    "    data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "    data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "    data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "    data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "    data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "    data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "    \n",
    "    #----------------------- Odds and probability of the home team scoring under 2.5 -------------------------------\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    \n",
    "    lst1 = []\n",
    "    lst2 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst1.append(1/(n_under_home[1]/total))\n",
    "            lst2.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst1.append(np.nan)\n",
    "            lst2.append(np.nan)\n",
    "\n",
    "    data['odds_home_under'] = lst1\n",
    "    data['prob_home_under'] = lst2\n",
    "    \n",
    "    \n",
    "    \n",
    "    #----------------------- Odds and probability of the away team scoring under 2.5 -------------------------------\n",
    "    \n",
    "    lst3 = []\n",
    "    lst4  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst3.append(1/(n_under_away2[1] / total2))\n",
    "            lst4.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst3.append(np.nan)\n",
    "            lst4.append(np.nan)\n",
    "\n",
    "    data['odds_away_under'] = lst3\n",
    "    data['prob_away_under'] = lst4\n",
    "    \n",
    "        #----------------------- Odds and probability of the home team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst5 = []\n",
    "    lst6 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst5.append(1/(n_under_home[1]/total))\n",
    "            lst6.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst5.append(np.nan)\n",
    "            lst6.append(np.nan)\n",
    "\n",
    "    data['odds_home_over'] = lst5\n",
    "    data['prob_home_over'] = lst6\n",
    "    \n",
    "     #----------------------- Odds and probability of the away team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst7 = []\n",
    "    lst8  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst7.append(1/(n_under_away2[1] / total2))\n",
    "            lst8.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst7.append(np.nan)\n",
    "            lst8.append(np.nan)\n",
    "\n",
    "    data['odds_away_over'] = lst7\n",
    "    data['prob_away_over'] = lst8\n",
    "    \n",
    "    # -------------------- binning the odds and probability of the home and away teams under 2.5 ----------------------\n",
    "    if binned:\n",
    "\n",
    "        #------- Probability -------\n",
    "\n",
    "        #binning the probability of the home team to have a game of less than 2.5 score\n",
    "        data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, bins)\n",
    "\n",
    "        #binning the probability of the away team to have a game of less than 2.5 score\n",
    "        data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, bins)\n",
    "\n",
    "        #--------- Odds ------------\n",
    "        binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "\n",
    "        #binning the odds of the away team to have a game of less than 2.5 score\n",
    "        data['binned odds_away_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "\n",
    "        #binning the odds of the home team to have a game of less than 2.5 score\n",
    "        data['binned odds_home_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "\n",
    "\n",
    "        # -------------------- binning the odds and probability of the home and away teams over 2.5 ----------------------\n",
    "\n",
    "        #------- Probability -------\n",
    "\n",
    "        #binning the probability of the home team to have a game of less than 2.5 score\n",
    "        data['binned prob_home_over'] = pd.cut(data['prob_home_over']*100, bins)\n",
    "\n",
    "        #binning the probability of the away team to have a game of less than 2.5 score\n",
    "        data['binned prob_away_over'] = pd.cut(data['prob_away_over']*100, bins)\n",
    "\n",
    "        #--------- Odds ------------\n",
    "        binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "\n",
    "        #binning the odds of the away team to have a game of less than 2.5 score\n",
    "        data['binned odds_away_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "\n",
    "        #binning the odds of the home team to have a game of less than 2.5 score\n",
    "        data['binned odds_home_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "\n",
    "\n",
    "    #-------------------------- Creating the prob and odds of the game -----------------------------------------------\n",
    "    \n",
    "    #---------------- Under --------------\n",
    "    '''the mean between the probability of the home team to have a score of under 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data['odds_game_under'] = (data['odds_away_under'] +  data['odds_home_under']) / 2\n",
    "    data['prob_game_under'] = (data['prob_away_under'] + data['prob_home_under']) / 2\n",
    "    \n",
    "    #---------------- Over -------------\n",
    "\n",
    "    '''the mean between the probability of the home team to have a score of over 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data['odds_game_over'] = (data['odds_away_over'] +  data['odds_home_over']) / 2\n",
    "    data['prob_game_over'] = (data['prob_away_over'] + data['prob_home_over']) / 2\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned probabilities columns ------------------------------------------\n",
    "    \n",
    "    if binned:\n",
    "        if b == 5:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "\n",
    "        if b == 10:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "            data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "            data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "\n",
    "        if b == 20:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "            data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "            data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "            data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "            data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "            data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "            data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "\n",
    "    #-------------------------- OneHotEncoding the binned odds columns ------------------------------------------\n",
    "    \n",
    "        #-------------------- Under -----------------------                                       \n",
    "        data = data[~data['binned odds_away_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned odds_away_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned odds_away_under']])\n",
    "        data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "        data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "        data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "\n",
    "        #-------------------- Over -----------------------\n",
    "        data = data[~data['binned odds_away_over'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned odds_away_over']])\n",
    "        bins_encoded = ohe.transform(data[['binned odds_away_over']])\n",
    "        data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "        data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "        data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "    \n",
    "    #------------------------------------ Cleaning the data ---------------------------------------------------------\n",
    "    \n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data = data[~data['PC>2.5'].isna()]\n",
    "    #data.drop(columns=['Referee', 'Unnamed: 105'], inplace=True)\n",
    "    #data.dropna()\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365829f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359d5081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20905, 177)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1774bbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.46\n",
       "1      1.50\n",
       "2      1.66\n",
       "3      0.00\n",
       "4      0.00\n",
       "       ... \n",
       "301    2.25\n",
       "302    0.00\n",
       "303    2.19\n",
       "304    0.00\n",
       "305    0.00\n",
       "Name: payout_under_2.5_pinacle_closing, Length: 20905, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = data['payout_under_2.5_pinacle_closing']\n",
    "data['payout_under_2.5_pinacle_closing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95312f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_away_under</th>\n",
       "      <th>odds_home_over</th>\n",
       "      <th>prob_home_over</th>\n",
       "      <th>odds_away_over</th>\n",
       "      <th>prob_away_over</th>\n",
       "      <th>odds_game_under</th>\n",
       "      <th>prob_game_under</th>\n",
       "      <th>odds_game_over</th>\n",
       "      <th>prob_game_over</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Dijon</td>\n",
       "      <td>Angers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Reims</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>2.511364</td>\n",
       "      <td>0.526190</td>\n",
       "      <td>3.015152</td>\n",
       "      <td>0.473810</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1</td>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.904762</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Oostende</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1.823529</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>2.718254</td>\n",
       "      <td>0.380979</td>\n",
       "      <td>1.636765</td>\n",
       "      <td>0.619021</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Oud-Heverlee Leuven</td>\n",
       "      <td>Waasland-Beveren</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.953782</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.091346</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>St Truiden</td>\n",
       "      <td>Anderlecht</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.093750</td>\n",
       "      <td>0.480287</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.519713</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Beerschot VA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>2.735714</td>\n",
       "      <td>0.388438</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>0.611562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>B1</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Waregem</td>\n",
       "      <td>Gent</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>2.579861</td>\n",
       "      <td>0.413237</td>\n",
       "      <td>1.758333</td>\n",
       "      <td>0.586763</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20905 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Div       Date   Time             HomeTeam          AwayTeam  FTHG  FTAG  \\\n",
       "0    F1 2020-08-21  18:00             Bordeaux            Nantes     0     0   \n",
       "1    F1 2020-08-22  16:00                Dijon            Angers     0     1   \n",
       "2    F1 2020-08-22  20:00                Lille            Rennes     1     1   \n",
       "3    F1 2020-08-23  12:00               Monaco             Reims     2     2   \n",
       "4    F1 2020-08-23  14:00              Lorient        Strasbourg     3     1   \n",
       "..   ..        ...    ...                  ...               ...   ...   ...   \n",
       "301  B1 2021-04-18  17:00             Oostende     Cercle Brugge     1     1   \n",
       "302  B1 2021-04-18  17:00  Oud-Heverlee Leuven  Waasland-Beveren     1     2   \n",
       "303  B1 2021-04-18  17:00           St Truiden        Anderlecht     0     1   \n",
       "304  B1 2021-04-18  17:00             Standard      Beerschot VA     3     0   \n",
       "305  B1 2021-04-18  17:00              Waregem              Gent     2     7   \n",
       "\n",
       "    FTR  HTHG  HTAG  ... prob_away_under  odds_home_over  prob_home_over  \\\n",
       "0     D   0.0   0.0  ...        0.533333        3.000000        0.333333   \n",
       "1     A   0.0   1.0  ...        0.466667        1.875000        0.533333   \n",
       "2     D   1.0   0.0  ...        0.800000        1.888889        0.529412   \n",
       "3     D   1.0   2.0  ...        0.785714        1.363636        0.733333   \n",
       "4     H   0.0   1.0  ...        0.600000        1.875000        0.533333   \n",
       "..   ..   ...   ...  ...             ...             ...             ...   \n",
       "301   D   0.0   0.0  ...        0.451613        1.450000        0.689655   \n",
       "302   A   0.0   1.0  ...        0.566667        1.875000        0.533333   \n",
       "303   A   0.0   0.0  ...        0.444444        2.066667        0.483871   \n",
       "304   H   1.0   0.0  ...        0.294118        1.933333        0.517241   \n",
       "305   A   0.0   3.0  ...        0.516129        1.450000        0.689655   \n",
       "\n",
       "     odds_away_over  prob_away_over  odds_game_under  prob_game_under  \\\n",
       "0          2.142857        0.466667         1.687500         0.600000   \n",
       "1          1.875000        0.533333         2.142857         0.466667   \n",
       "2          5.000000        0.200000         1.687500         0.635294   \n",
       "3          4.666667        0.214286         2.511364         0.526190   \n",
       "4          2.500000        0.400000         1.904762         0.533333   \n",
       "..              ...             ...              ...              ...   \n",
       "301        1.823529        0.548387         2.718254         0.380979   \n",
       "302        2.307692        0.433333         1.953782         0.516667   \n",
       "303        1.800000        0.555556         2.093750         0.480287   \n",
       "304        1.416667        0.705882         2.735714         0.388438   \n",
       "305        2.066667        0.483871         2.579861         0.413237   \n",
       "\n",
       "     odds_game_over  prob_game_over  target  \n",
       "0          2.571429        0.400000    True  \n",
       "1          1.875000        0.533333    True  \n",
       "2          3.444444        0.364706    True  \n",
       "3          3.015152        0.473810   False  \n",
       "4          2.187500        0.466667   False  \n",
       "..              ...             ...     ...  \n",
       "301        1.636765        0.619021    True  \n",
       "302        2.091346        0.483333   False  \n",
       "303        1.933333        0.519713    True  \n",
       "304        1.675000        0.611562   False  \n",
       "305        1.758333        0.586763   False  \n",
       "\n",
       "[20905 rows x 178 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a1dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['target'] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1d80f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features that we will use in the model to predict the under\n",
    "X = data[['odds_game_over', 'odds_game_under', 'PC<2.5', 'AvgC<2.5','PC>2.5', 'AvgC>2.5', 'Pin_pays_better_under_difference', '%vig_p', '%vig_avg', 'PC<2.5_P_relative_diff']]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f974e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalling our features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3190a1",
   "metadata": {},
   "source": [
    "## Under Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e5afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train/Test\n",
    "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7537a0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.3, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=1, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.0009012, max_bin=512, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=3,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=1, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=1, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.3, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=1, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.0009012, max_bin=512, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=3,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=1, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=1, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.3, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=1, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.0009012, max_bin=512, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=3,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=1, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=1, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model in the training data\n",
    "model_under_p = XGBClassifier(base_score=0.3, booster='gbtree', callbacks=None,\n",
    "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
    "              early_stopping_rounds=None, enable_categorical=False,\n",
    "              eval_metric=None, gamma=1, gpu_id=-1, grow_policy='depthwise',\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.0009012, max_bin=512, max_cat_to_onehot=4,\n",
    "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=3, monotone_constraints='()', n_estimators=100,\n",
    "              n_jobs=1, num_parallel_tree=1, predictor='auto', random_state=0,\n",
    "              reg_alpha=1, reg_lambda=1)\n",
    "model_under_p.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6c92f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation score: 1.00\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model_under_p, X_train_under, y_train_under,cv=10)\n",
    "print(\"Mean cross-validation score: %.2f\" % scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6668fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  1.0\n"
     ]
    }
   ],
   "source": [
    "score = model_under_p.score(X_train_under, y_train_under)  \n",
    "print(\"Training score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e31e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28b37156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_under_p.predict(X_test_under)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39770e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "226+137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbaeb228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4181\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual = y_test_under - y_pred\n",
    "residual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb57b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe36e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test_under, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09306c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84790219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb6db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
