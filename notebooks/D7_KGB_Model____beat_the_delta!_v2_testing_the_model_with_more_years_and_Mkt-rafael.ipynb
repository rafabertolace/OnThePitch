{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1816ff7",
   "metadata": {},
   "source": [
    "# Imports and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4cf7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Only Rafa\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e1f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "import shap\n",
    "from sklearn.metrics import r2_score, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295e690",
   "metadata": {},
   "source": [
    "# Loading the Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4f75c",
   "metadata": {},
   "source": [
    "## Merging the Seasons csv files (2019-2020 untill 2021-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b6d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spain_2019_2020_1.csv', 'italy_2020_2021_2.csv', 'italy_2021_2022_1.csv', 'italy_2021_2022_2.csv', 'spain_2020_2021_1.csv', 'spain_2020_2021_2.csv', 'scotland_2020_2021_2.csv', 'Turkey_2021_2022_1.csv', 'scotland_2020_2021_3.csv', 'scotland_2019_2020_1.csv', 'france_2021_2022_1.csv', 'germany_2021_2022_1.csv', 'belgium_2020_2021_1.csv', 'scotland_2021_2022_4.csv', 'scotland_2020_2021_1.csv', 'france_2019_2020_1.csv', 'germany_2021_2022_2.csv', 'germany_2019_2020_1.csv', 'england_2020_2021_3.csv', 'scotland_2019_2020_2.csv', 'italy_2019_2020_1.csv', 'scotland_2020_2021_4.csv', 'portugal_2021_2022_1.csv', 'france_2020_2021_2.csv', 'scotland_2021_2022_3.csv', 'england_2021_2022_3.csv', 'portugal_2019_2020_1.csv', 'Greece_2021_2022_1.csv', 'england_2020_2021_4.csv', 'england_2021_2022_4.csv', 'france_2020_2021_1.csv', 'germany_2020_2021_1.csv', 'scotland_2019_2020_4.csv', 'spain_2019_20220_2.csv', 'germany_2019_2020_2.csv', 'england_2019_2020_4.csv', 'scotland_2021_2022_1.csv', 'england_2020_2021_2.csv', 'france_2019_2020_2.csv', 'Turkey_2019_2020_1.csv', 'england_2019_2020_2.csv', 'Eredivisie_2021_2022_1.csv', 'Turkey_2020_2021_1.csv', 'spain_2021_2022_1.csv', 'france_2021_2022_2.csv', 'belgium_2021_2022_1.csv', 'Greece_2019_2020_1.csv', 'belgium_2019_2020_1.csv', 'england_2019_2020_1.csv', 'Greece_2020_2021_1.csv', 'spain_2021_2022_2.csv', 'italy_2019_2020_2.csv', 'portugal_2020_2021_1.csv', 'Eredivisie_2020_2021_1.csv', 'italy_2020_2021_1.csv', 'Eredivisie_2019_2020_1.csv', 'england_2021_2022_2.csv', 'england_2020_2021_1.csv', 'england_2019_2020_3.csv', 'scotland_2021_2022_2.csv', 'scotland_2019_2020_3.csv', 'england_2021_2022_1.csv', 'germany_2020_2021_2.csv']\n"
     ]
    }
   ],
   "source": [
    "# Customise based on your path and folder organisation\n",
    "print(os.listdir('../raw_data/All4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2208c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the CSVs\n",
    "\n",
    "files = [file for file in os.listdir('../raw_data/All4') if file.endswith('.csv')]\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv('../raw_data/All4/' + file)\n",
    "    df['country']=str(file)[0:2]\n",
    "    df['country_division']=int(str(file)[-5:-4])\n",
    "    data = pd.concat([data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8faf8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(league1, wall=False):\n",
    "    if wall:\n",
    "        data = pd.DataFrame()\n",
    "        leagues = listdir(f'./../raw_data/')\n",
    "        data = pd.DataFrame()\n",
    "        for league in leagues:\n",
    "            files = listdir(f'./../raw_data/{league}')\n",
    "            for file in files:\n",
    "                df = pd.read_csv((f'./../raw_data/{league}/'+file))\n",
    "                df['country']=str(file)[0:2]\n",
    "                data = pd.concat([data, df])\n",
    "        return data\n",
    "    else:\n",
    "        files = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        data = pd.DataFrame()\n",
    "        for file in files:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file)\n",
    "            data = pd.concat([data, df])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8ad8d",
   "metadata": {},
   "source": [
    "# Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acad4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the function\n",
    "\n",
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "        '''\n",
    "    #------------------------Number of Goals, Over and Under -----------------------------------\n",
    "    \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "    \n",
    "    #-----------------------------Payout Opening ----------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average OPENING odds\n",
    "    data['payout_avg_under_2.5'] = data['under_2.5_goals']*data['Avg<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average OPENING odds\n",
    "    data['payout_avg_over_2.5'] = data['over_2.5_goals']*data['Avg>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['P<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['P>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365>2.5']\n",
    "    \n",
    "    #------------------------------Payout Closing --------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_under_closing_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_over_closing_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE closing ddds specifically\n",
    "    data['payout_under_2.5_pinacle_closing'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE closing odds specifically\n",
    "    data['payout_over_2.5_pinacle_closing'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 closing odds specifically\n",
    "    data['payout_under_2.5_365_closing'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 closing odds specifically\n",
    "    data['payout_over_2.5_365_closing'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #-------------------------- Implied Probability Opening ----------------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability <2.5 avg']=1/data['Avg<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability >2.5 avg']=1/data['Avg>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['P<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['P>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365>2.5']*100\n",
    "    \n",
    "    #------------------------- Implied Probability Closing -----------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability <2.5 avg closing']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability >2.5 avg closing']=1/data['AvgC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability <2.5 pinacle closing']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability >2.5 pinacle closing']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability <2.5 365 closing']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability >2.5 365 closing']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    #---------------------------- Binning IP Opening -------------------------------------\n",
    "\n",
    "    b=b\n",
    "    bins = np.arange(0, 101, int(100/b))\n",
    "    bins = bins.tolist()\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned <2.5 avg'] = pd.cut(data['Implied Probability <2.5 avg'], bins)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned >2.5 avg'] = pd.cut(data['Implied Probability >2.5 avg'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "    \n",
    "    #----------------------------- Binning IP Closing ------------------------------------------------\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market closing odds\n",
    "    data['binned <2.5 avg closing'] = pd.cut(data['Implied Probability <2.5 avg closing'], bins)\n",
    "\n",
    "    #Binning OVER 2.5 Average Market closing odds\n",
    "    data['binned >2.5 avg closing'] = pd.cut(data['Implied Probability >2.5 avg closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle closing odds\n",
    "    data['binned <2.5 pinacle closing'] = pd.cut(data['Implied Probability <2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle CLOSING odds\n",
    "    data['binned >2.5 pinacle closing'] = pd.cut(data['Implied Probability >2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 CLOSING odds\n",
    "    data['binned <2.5 365 closing'] = pd.cut(data['Implied Probability <2.5 365 closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 CLOSING odds\n",
    "    data['binned >2.5 365 closing'] = pd.cut(data['Implied Probability >2.5 365 closing'], bins)\n",
    "    \n",
    "    #---------------------------- Binning Odds Opening ----------------------------------------------------\n",
    "    \n",
    "    bins2 = [1, 1.5, 2, 3, 10]\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle'] = pd.cut(data['P<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle'] = pd.cut(data['P>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365'] = pd.cut(data['B365<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365'] = pd.cut(data['B365>2.5'], bins2)\n",
    "    \n",
    "    #----------------------------- Binning Odds Closing ----------------------------------------------------------\n",
    "    \n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg closing'] = pd.cut(data['AvgC<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg closing'] = pd.cut(data['AvgC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle closing'] = pd.cut(data['PC<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle closing'] = pd.cut(data['PC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365 closing'] = pd.cut(data['B365C<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365 closing'] = pd.cut(data['B365C>2.5'], bins2)\n",
    "    \n",
    "    \n",
    "    #----------------------------- Other Features from D3 ------------------------------------------------------\n",
    "    \n",
    "    data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "    data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "    data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "    data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "    data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "    data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "    \n",
    "    #----------------------- Odds and probability of the home team scoring under 2.5 -------------------------------\n",
    "    \n",
    "\n",
    "    \n",
    "    #------------------------------------ Cleaning the data ---------------------------------------------------------\n",
    "    \n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data = data[~data['PC>2.5'].isna()]\n",
    "    data.drop(columns=['Referee','Unnamed: 105'], inplace=True) #, 'Unnamed: 105' 'Referee', \n",
    "    #data.dropna()\n",
    "    \n",
    "     #-------------------------- OneHotEncoding the binned odds ------------------------------------------\n",
    "   \n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['binned odds <2.5 pinacle closing']])\n",
    "    bins_encoded = ohe.transform(data[['binned odds <2.5 pinacle closing']])\n",
    "    data[\"1.0_to_1.5\"], data[\"1.5_to_2.0\"], data[\"2.0_to_3\"], data[\"3_to_10\"] = bins_encoded.T\n",
    "    data.drop(columns='binned odds <2.5 pinacle closing', inplace=True)\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned odds ------------------------------------------\n",
    "   \n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['binned odds <2.5 avg closing']])\n",
    "    bins_encoded = ohe.transform(data[['binned odds <2.5 avg closing']])\n",
    "    data[\"avg_1.0_to_1.5\"], data[\"avg_1.5_to_2.0\"], data[\"avg_2.0_to_3\"], data[\"avg_3_to_10\"] = bins_encoded.T\n",
    "    data.drop(columns='binned odds <2.5 avg closing', inplace=True)\n",
    "    \n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned countries ------------------------------------------\n",
    "\n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['country']])\n",
    "    bins_encoded = ohe.transform(data[['country']])\n",
    "    data[\"country_1\"], data[\"country_2\"], data[\"country_3\"], data[\"country_4\"], data[\"country_5\"],data[\"country_6\"], data[\"country_7\"], data[\"country_8\"], data[\"country_9\"], data[\"country_10\"], data[\"country_11\"] = bins_encoded.T\n",
    "    data.drop(columns='country', inplace=True)\n",
    "\n",
    "    #-------------------------- OneHotEncoding the binned country divisions ------------------------------------------\n",
    "    \n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['country_division']])\n",
    "    bins_encoded = ohe.transform(data[['country_division']])\n",
    "    data[\"country_div_1\"], data[\"country_div_2\"], data[\"country_div_3\"], data[\"country_div_4\"] = bins_encoded.T\n",
    "    #data.drop(columns='country_division', inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c518df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the function and creating the dataset data\n",
    "\n",
    "data = feature_engineering(data, b=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d725b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE WILL NEED TO ADD ALL THOSE IN THE feature_engineering FUNCTION\n",
    "\n",
    "## Adding the Year Feature \n",
    "data_date = data['Date']\n",
    "data_time = data['Time']\n",
    "data_date_2 = pd.to_datetime(data_date, dayfirst = True)\n",
    "data_time_2 = pd.to_datetime(data_time, dayfirst = True)\n",
    "data['month'] = pd.DatetimeIndex(data_date_2).month\n",
    "data['month_after_July'] = data['month']>=7\n",
    "data['year'] = pd.DatetimeIndex(data_date_2).year\n",
    "data['year_2021_2022'] = data['year']>=2021\n",
    "data['year_2022'] = data['year']>=2022\n",
    "data['year_2020'] = data['year']==2020\n",
    "data['season_21_22'] = data_date_2>='2021-09-01'\n",
    "data['season_20_21'] = (data_date_2>='2020-09-01') & (data_date_2<'2021-09-01')\n",
    "data['season_training2'] = (data_date_2<'2020-09-01')\n",
    "\n",
    "data['hour'] = pd.DatetimeIndex(data_time_2).hour\n",
    "data['game_starts_after_4pm']=data['hour']>=16\n",
    "\n",
    "#Other features\n",
    "data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "data['%vig_p_bool'] = data['%vig_p']>3.3\n",
    "data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "data['%vig_avg_bool'] = data['%vig_avg']>5.4\n",
    "data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "data['MaxC>2.5_AvgC_relative_diff'] = data['MaxC>2.5']/data['AvgC>2.5']\n",
    "data['Market_consensus'] = data['MaxC>2.5_AvgC_relative_diff']<1.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba33728",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month_number']=data['month']\n",
    "data['month_number_ratio']=data['month']/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4accb5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['year_number'] = data['year'].map({2019:1, 2020:2, 2021:3, 2022:4})\n",
    "data['year_number_ratio'] = data['year'].map({2019:1, 2020:2, 2021:3, 2022:4})/4\n",
    "data['year_number_month_ratio'] = data['year_number']+data['month_number_ratio']\n",
    "data['year_number_month_decimal'] = data['year_number']+data['month_number']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9523dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False) \n",
    "ohe.fit(data[['year_number']])\n",
    "bins_encoded = ohe.transform(data[['year_number']])\n",
    "data[\"year_1\"], data[\"year_2\"], data[\"year_3\"], data[\"year_4\"] = bins_encoded.T\n",
    "   # data.drop(columns='country_division', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6794277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False) \n",
    "ohe.fit(data[['month_number']])\n",
    "bins_encoded = ohe.transform(data[['month_number']])\n",
    "data[\"month_1\"], data[\"month_2\"], data[\"month_3\"], data[\"month_4\"], data[\"month_5\"], data[\"month_6\"], data[\"month_7\"], data[\"month_8\"], data[\"month_9\"], data[\"month_10\"], data[\"month_11\"], data[\"month_12\"] = bins_encoded.T\n",
    "   # data.drop(columns='country_division', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94006a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False) \n",
    "ohe.fit(data[['game_starts_after_4pm']])\n",
    "bins_encoded = ohe.transform(data[['game_starts_after_4pm']])\n",
    "data[\"game_starts_after_4pm_1\"], data[\"game_starts_after_4pm_2\"] = bins_encoded.T\n",
    "   # data.drop(columns='country_division', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ce4b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False) \n",
    "ohe.fit(data[['game_starts_after_4pm']])\n",
    "bins_encoded = ohe.transform(data[['game_starts_after_4pm']])\n",
    "data[\"game_starts_after_4pm_1\"], data[\"game_starts_after_4pm_2\"] = bins_encoded.T\n",
    "   # data.drop(columns='country_division', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb704b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hour_number'] = data['hour'].map({10:1, 11:2, 12:3, 13:4, 14:5, 15:6, 16:7, 17:8, 18:9, 19:10, 20:11, 21:12})\n",
    "data['hour_number_2'] = data['hour'].map({10:1, 11:1, 12:1, 13:2, 14:2, 15:2, 16:3, 17:3, 18:3, 19:4, 20:4, 21:4})\n",
    "data['hour_number_2_ratio'] = data['hour'].map({10:1, 11:1, 12:1, 13:2, 14:2, 15:2, 16:3, 17:3, 18:3, 19:4, 20:4, 21:4})/4\n",
    "data['hour_number_ratio'] = data['hour'].map({10:1, 11:2, 12:3, 13:4, 14:5, 15:6, 16:7, 17:8, 18:9, 19:10, 20:11, 21:12})/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "308990e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False) \n",
    "ohe.fit(data[['hour_number_2']])\n",
    "bins_encoded = ohe.transform(data[['hour_number_2']])\n",
    "data[\"hour_group_1\"], data[\"hour_group_2\"], data[\"hour_group_3\"], data[\"hour_group_4\"] = bins_encoded.T\n",
    "   # data.drop(columns='country_division', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1b178ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PC<2.5']\n",
    "\n",
    "data.rename(columns = {'PC<2.5':'PC_under_2.5'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a0f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ohe = OneHotEncoder(sparse=False) \n",
    "#     ohe.fit(data[[\"binned_odds\"]])\n",
    "#     bins_encoded = ohe.transform(data[[\"binned_odds\"]])\n",
    "#     data[\"bin_odds_1\"], data[\"bin_odds_2\"],data[\"bin_odds_3\"], data[\"bin_odds_4\"] = bins_encoded.T\n",
    "   # data.drop(columns='country_division', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0df27",
   "metadata": {},
   "source": [
    "# Running the XGB model for under 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "899a0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model dataset with relevant variables\n",
    "data_linear_booleans_lean_P_under = data[['year_number','year_number_ratio','year_number_month_ratio','year_number_month_decimal','month_number','month_number_ratio','country_div_1','country_div_2','country_div_3','country_div_4','month_after_July','season_21_22','year_2020','game_starts_after_4pm','Market_consensus','%vig_p_bool','%vig_avg_bool','avg_1.0_to_1.5','avg_1.5_to_2.0','avg_2.0_to_3','avg_3_to_10','payout_under_2.5_pinacle_closing','year_1','year_2','year_3','year_4','month_1','month_2','month_3','month_4','month_5','month_6','month_7','month_8','month_9','month_10','month_11','month_12','hour_number','hour_number_ratio','hour_number_2','hour_number_2_ratio',\"game_starts_after_4pm_1\",\"game_starts_after_4pm_2\",'hour_group_1','hour_group_2','hour_group_3','hour_group_4','country_division','season_training2','season_20_21','payout_avg_under_closing_2.5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0bb8a",
   "metadata": {},
   "source": [
    "## Defining the function testing_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220dd440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# back up\n",
    "def testing_models(iterations):   \n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while i < iterations:\n",
    "        # Split into Train/Test\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.3) # Split into Train/Test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_test_0, y_test_0, test_size=test_size_0) # Split into Train/Test\n",
    "\n",
    "            #------------------------Run the Models -----------------------------------\n",
    "\n",
    "        #Initiate XGBoost\n",
    "        m = 0\n",
    "        m = xgb.XGBRegressor()\n",
    "        \n",
    "        #Rename columns for XGBoost to run\n",
    "        ##X_test.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        ##X_train.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        \n",
    "        #Fit XGBoost\n",
    "        m.fit(X_train_0,y_train_0) \n",
    "        \n",
    "        #Make and store the predictions XGBoost\n",
    "        y_pred_xgb = m.predict(X_test)\n",
    "        y_pred_xgb = pd.DataFrame(y_pred_xgb)\n",
    "\n",
    "            #------------------------Creating the bins for the predictions for both models -----------------------------------\n",
    "        #Function to replace bin with default value when it is null\n",
    "        def ifnull(var, val):\n",
    "          if var > 0:\n",
    "            return var\n",
    "          return val\n",
    "\n",
    "        #XGB bins\n",
    "        y_pred_xgb_under_0_median = y_pred_xgb[y_pred_xgb<0].median()\n",
    "        y_pred_xgb_under_0_min = y_pred_xgb[y_pred_xgb<0].min()\n",
    "        y_pred_xgb_over_0_median = ifnull(y_pred_xgb[0][y_pred_xgb[0]>0].median(),0.05)\n",
    "\n",
    "            #------------------------Betting decisions for both models -----------------------------------\n",
    "\n",
    "        #XGB\n",
    "        bins3_xgb = [y_pred_xgb_under_0_min[0]-0.0000002, y_pred_xgb_under_0_median[0]-0.0000001, 0, y_pred_xgb_over_0_median+0.0000001, 1] #int(y_pred_xgb_over_0_median[0])\n",
    "        y_xgb_df = pd.DataFrame(y_test)\n",
    "        y_pred_xgb_df = pd.DataFrame(y_pred_xgb)\n",
    "        y_pred_xgb_df[\"binned_pred\"] = pd.cut(y_pred_xgb_df[0], bins3_xgb)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_1\"] = y_pred_xgb_df[0]<y_pred_xgb_under_0_median[0]-0.0000001\n",
    "        y_pred_xgb_df[\"binned_pred_bin_2\"] = (y_pred_xgb_df[0]>y_pred_xgb_under_0_median[0]-0.0000001) & (y_pred_xgb_df[0]<0)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_3\"] = (y_pred_xgb_df[0]>0) & (y_pred_xgb_df[0]<y_pred_xgb_over_0_median+0.0000001)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_4\"] = (y_pred_xgb_df[0]>y_pred_xgb_over_0_median+0.0000001)\n",
    "        y_pred_xgb_df[\"bin_number\"] = y_pred_xgb_df[\"binned_pred_bin_1\"]*1 + y_pred_xgb_df[\"binned_pred_bin_2\"]*2 + y_pred_xgb_df[\"binned_pred_bin_3\"]*3 + y_pred_xgb_df[\"binned_pred_bin_4\"]*4     \n",
    "        ind = np.arange(0, len(y_pred_xgb_df))\n",
    "        ind = ind.tolist()\n",
    "        y_xgb_df['ind'] = ind\n",
    "        y_pred_xgb_df['ind'] = ind\n",
    "        y_final_xgb = y_xgb_df.merge(y_pred_xgb_df, on=\"ind\")#, on = \"axis\")#, how = \"inner\")\n",
    "        \n",
    "        #Defining the variable bet_opp based on the y_pred of the XGB\n",
    "        y_final_xgb['bet_opp']=y_final_xgb[0]>0\n",
    "\n",
    "            #------------------------Getting the results based on predictions -----------------------------------    \n",
    "\n",
    "        #XGB\n",
    "        #xgb_count = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].count()\n",
    "        #xgb_mean = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].mean()\n",
    "        #xgb_results = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].agg([\"mean\", \"count\"])\n",
    "        xgb_results_False = y_final_xgb[y_final_xgb['bet_opp']==False]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_True = y_final_xgb[y_final_xgb['bet_opp']==True]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_bin_1 = y_final_xgb[y_final_xgb['bin_number']==1]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_bin_2 = y_final_xgb[y_final_xgb['bin_number']==2]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_bin_3 = y_final_xgb[y_final_xgb['bin_number']==3]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_bin_4 = y_final_xgb[y_final_xgb['bin_number']==4]['payout_avg_under_closing_2.5'].mean()\n",
    "        \n",
    "        results_xgb_false.append(xgb_results_False)\n",
    "        results_xgb_true.append(xgb_results_True)\n",
    "        results_xgb_1.append(xgb_results_bin_1)\n",
    "        results_xgb_2.append(xgb_results_bin_2)\n",
    "        results_xgb_3.append(xgb_results_bin_3)\n",
    "        results_xgb_4.append(xgb_results_bin_4)\n",
    "        \n",
    "        return y_test, y_train_0, y_pred_xgb, y_final_xgb \n",
    "        \n",
    "        i=i+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60320b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lr_true = []\n",
    "# results_lr_false = []\n",
    "\n",
    "def testing_models_classifier(iterations):   \n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while i < iterations:\n",
    "        # Split into Train/Test\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.3) # Split into Train/Test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_test_0, y_test_0_classifier, test_size=test_size_0) # Split into Train/Test\n",
    "\n",
    "            #------------------------Run the Models -----------------------------------\n",
    "\n",
    "        #Initiate XGBoost\n",
    "        m = 0\n",
    "        m = xgb.XGBClassifier()\n",
    "        \n",
    "        #Fit XGBoost\n",
    "        m.fit(X_train_0,y_train_0_classifier) \n",
    "        \n",
    "        #Make and store the predictions XGBoost\n",
    "        y_pred_test = m.predict(X_test)\n",
    "        y_pred_test_df = pd.DataFrame(y_pred_test,columns=['prediction'])\n",
    "        y_pred_train = m.predict(X_train_0)\n",
    "        y_pred_train_df = pd.DataFrame(y_pred_train)\n",
    "        y_test_df = pd.DataFrame(y_test).reset_index()\n",
    "        y_final_df = y_pred_test_df.copy()\n",
    "        y_final_df['actual'] = y_test_df['payout_avg_under_closing_2.5']\n",
    "\n",
    "        \n",
    "        # accuracy\n",
    "        accuracy_test = accuracy_score(y_test,y_pred_test)\n",
    "        accuracy_train = accuracy_score(y_train_0_classifier,y_pred_train)\n",
    "        \n",
    "        # precision\n",
    "        precision_test = precision_score(y_test,y_pred_test)\n",
    "        precision_train = precision_score(y_train_0_classifier,y_pred_train)\n",
    "    \n",
    "  #------------------------Creating the bins for the predictions for both models -----------------------------------\n",
    "        #Function to replace bin with default value when it is null\n",
    "        def ifnull(var, val):\n",
    "          if var > 0:\n",
    "            return var\n",
    "          return val\n",
    "        \n",
    "        #XGB\n",
    "        #ind = np.arange(0, len(y_pred_test_df))\n",
    "        #ind = ind.tolist()\n",
    "        #y_xgb_df['ind'] = ind\n",
    "        #y_pred_test_df['ind'] = ind\n",
    "        \n",
    "        #Defining the variable bet_opp based on the y_pred of the XGB\n",
    "\n",
    "        y_final_df['payout_avg_under_closing_2.5'] = y_test_0.loc[y_test.index].reset_index()['payout_avg_under_closing_2.5']\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        #y_final_df['payout_avg_under_closing_2.5'] = 0\n",
    "\n",
    "        result_False = y_final_df[y_final_df['prediction']==False]['payout_avg_under_closing_2.5'].mean()\n",
    "        result_True = y_final_df[y_final_df['prediction']==True]['payout_avg_under_closing_2.5'].mean()\n",
    "        \n",
    "        results_False.append(result_False)\n",
    "        results_True.append(result_True)\n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "    return accuracy_test, accuracy_train, precision_train, precision_test, y_final_df\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27bb9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test, accuracy_train, precision_train, precision_test, y_final_df = testing_models_classifier(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b042b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5586996799730504,\n",
       " 0.5889999301139143,\n",
       " 0.5811435660313522,\n",
       " 0.5491886409736308)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test, accuracy_train, precision_train, precision_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab21f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lr_true = []\n",
    "# results_lr_false = []\n",
    "\n",
    "def testing_models2(iterations):   \n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while i < iterations:\n",
    "        # Split into Train/Test\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.3) # Split into Train/Test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_test_0, y_test_0, test_size=test_size_0) # Split into Train/Test\n",
    "\n",
    "            #------------------------Run the Models -----------------------------------\n",
    "\n",
    "        #Initiate XGBoost\n",
    "        m = 0\n",
    "        m = xgb.XGBRegressor()\n",
    "        \n",
    "        #Rename columns for XGBoost to run\n",
    "        ##X_test.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        ##X_train.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        \n",
    "        #Fit XGBoost\n",
    "        m.fit(X_train_0,y_train_0) \n",
    "\n",
    "        #Make and store the predictions XGBoost\n",
    "        y_pred_xgb_vector = m.predict(X_test)\n",
    "        y_pred_xgb = pd.DataFrame(y_pred_xgb_vector)\n",
    "        y_pred_xgb_train_vector = m.predict(X_train_0)\n",
    "        y_pred_xgb_train = pd.DataFrame(y_pred_xgb_train_vector)\n",
    "        r2_score_test = r2_score(y_test,y_pred_xgb_vector)\n",
    "        r2_score_train = r2_score(y_train_0,y_pred_xgb_train_vector)\n",
    "\n",
    "            #------------------------Creating the bins for the predictions for both models -----------------------------------\n",
    "        #Function to replace bin with default value when it is null\n",
    "        def ifnull(var, val):\n",
    "          if var > 0:\n",
    "            return var\n",
    "          return val\n",
    "\n",
    "        #XGB bins\n",
    "        y_pred_xgb_under_0_median = y_pred_xgb[y_pred_xgb<0].median()\n",
    "        y_pred_xgb_under_0_min = y_pred_xgb[y_pred_xgb<0].min()\n",
    "        y_pred_xgb_over_0_median = ifnull(y_pred_xgb[0][y_pred_xgb[0]>0].median(),0.05)\n",
    "\n",
    "            #------------------------Betting decisions for both models -----------------------------------\n",
    "\n",
    "        #XGB\n",
    "        bins3_xgb = [y_pred_xgb_under_0_min[0]-0.0000002, y_pred_xgb_under_0_median[0]-0.0000001, 0, y_pred_xgb_over_0_median+0.0000001, 1] #int(y_pred_xgb_over_0_median[0])\n",
    "        y_xgb_df = pd.DataFrame(y_test)\n",
    "        y_pred_xgb_df = pd.DataFrame(y_pred_xgb)\n",
    "        y_pred_xgb_df[\"binned_pred\"] = pd.cut(y_pred_xgb_df[0], bins3_xgb)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_1\"] = y_pred_xgb_df[0]<y_pred_xgb_under_0_median[0]-0.0000001\n",
    "        y_pred_xgb_df[\"binned_pred_bin_2\"] = (y_pred_xgb_df[0]>y_pred_xgb_under_0_median[0]-0.0000001) & (y_pred_xgb_df[0]<0)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_3\"] = (y_pred_xgb_df[0]>0) & (y_pred_xgb_df[0]<y_pred_xgb_over_0_median+0.0000001)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_4\"] = (y_pred_xgb_df[0]>y_pred_xgb_over_0_median+0.0000001)\n",
    "        y_pred_xgb_df[\"bin_number\"] = y_pred_xgb_df[\"binned_pred_bin_1\"]*1 + y_pred_xgb_df[\"binned_pred_bin_2\"]*2 + y_pred_xgb_df[\"binned_pred_bin_3\"]*3 + y_pred_xgb_df[\"binned_pred_bin_4\"]*4     \n",
    "        ind = np.arange(0, len(y_pred_xgb_df))\n",
    "        ind = ind.tolist()\n",
    "        y_xgb_df['ind'] = ind\n",
    "        y_pred_xgb_df['ind'] = ind\n",
    "        y_final_xgb = y_xgb_df.merge(y_pred_xgb_df, on=\"ind\")#, on = \"axis\")#, how = \"inner\")\n",
    "        \n",
    "        #Defining the variable bet_opp based on the y_pred of the XGB\n",
    "        y_final_xgb['bet_opp']=y_final_xgb[0]>0\n",
    "\n",
    "            #------------------------Getting the results based on predictions -----------------------------------     \n",
    "\n",
    "        #XGB\n",
    "        #xgb_count = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].count()\n",
    "        #xgb_mean = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].mean()\n",
    "        #xgb_results = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].agg([\"mean\", \"count\"])\n",
    "        xgb_results_False = y_final_xgb[y_final_xgb['bet_opp']==False]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_True = y_final_xgb[y_final_xgb['bet_opp']==True]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_bin_1 = y_final_xgb[y_final_xgb['bin_number']==1]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_bin_2 = y_final_xgb[y_final_xgb['bin_number']==2]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_bin_3 = y_final_xgb[y_final_xgb['bin_number']==3]['payout_avg_under_closing_2.5'].mean()\n",
    "        xgb_results_bin_4 = y_final_xgb[y_final_xgb['bin_number']==4]['payout_avg_under_closing_2.5'].mean()\n",
    "        \n",
    "        results_xgb_false.append(xgb_results_False)\n",
    "        results_xgb_true.append(xgb_results_True)\n",
    "        results_xgb_1.append(xgb_results_bin_1)\n",
    "        results_xgb_2.append(xgb_results_bin_2)\n",
    "        results_xgb_3.append(xgb_results_bin_3)\n",
    "        results_xgb_4.append(xgb_results_bin_4)\n",
    "        \n",
    "        return y_test, y_train_0, y_pred_xgb, y_final_xgb, r2_score_test, r2_score_train\n",
    "        \n",
    "        i=i+1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dac4f9",
   "metadata": {},
   "source": [
    "## Running the function testing_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b44a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the indices\n",
    "data_linear_booleans_lean_P_under.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Select here the variables you want to include in the testing\n",
    "#'hour_number','hour_number_ratio',\"hour_10\",\"hour_11\",\"hour_12\",\"hour_13\",\"hour_14\",\"hour_15\",\"hour_16\",\"hour_17\",\"hour_18\",\"hour_19\",\"hour_20\",\"hour_21\",'hour_number','hour_number_ratio','hour_number_2_ratio'\n",
    "X_train_0 = data_linear_booleans_lean_P_under[data_linear_booleans_lean_P_under['season_21_22']==False][['country_div_1','country_div_2','country_div_3','country_div_4','%vig_avg_bool','Market_consensus','year_number',\"game_starts_after_4pm_2\",\"game_starts_after_4pm_1\",'avg_1.0_to_1.5','avg_1.5_to_2.0','avg_2.0_to_3','avg_3_to_10']]#,'year_number_ratio','month_number_ratio']]\n",
    "X_test_0 = data_linear_booleans_lean_P_under[data_linear_booleans_lean_P_under['season_21_22']==True][['country_div_1','country_div_2','country_div_3','country_div_4','%vig_avg_bool','Market_consensus','year_number',\"game_starts_after_4pm_2\",\"game_starts_after_4pm_1\",'avg_1.0_to_1.5','avg_1.5_to_2.0','avg_2.0_to_3','avg_3_to_10']]#,'year_number_ratio','month_number_ratio']]\n",
    "y_train_0 = data_linear_booleans_lean_P_under[data_linear_booleans_lean_P_under['season_21_22']==False]['payout_avg_under_closing_2.5']-1\n",
    "y_test_0 = data_linear_booleans_lean_P_under[data_linear_booleans_lean_P_under['season_21_22']==True]['payout_avg_under_closing_2.5']-1\n",
    "\n",
    "#creating the classifier model\n",
    "y_test_0_classifier = data_linear_booleans_lean_P_under[data_linear_booleans_lean_P_under['season_21_22']==True]['payout_avg_under_closing_2.5']!=0\n",
    "y_train_0_classifier = data_linear_booleans_lean_P_under[data_linear_booleans_lean_P_under['season_21_22']==False]['payout_avg_under_closing_2.5']!=0\n",
    "\n",
    "#div_1',country_div_1','country_div_2','country_div_3','country_div_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a8a24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function testing_models\n",
    "results_xgb_true = [] \n",
    "results_xgb_false = []\n",
    "results_xgb_1=[]\n",
    "results_xgb_2=[]\n",
    "results_xgb_3=[]\n",
    "results_xgb_4=[]\n",
    "results_False=[]\n",
    "results_True=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4ffb1d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m test_size_0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtesting_models_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m accuracy_test, accuracy_train, precision_train, precision_test, y_final_df \u001b[38;5;241m=\u001b[39m testing_models_classifier(\u001b[38;5;241m10\u001b[39m)\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mtesting_models_classifier\u001b[0;34m(iterations)\u001b[0m\n\u001b[1;32m     17\u001b[0m m \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#Fit XGBoost\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_0_classifier\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#Make and store the predictions XGBoost\u001b[39;00m\n\u001b[1;32m     23\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    531\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/xgboost/sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[1;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1381\u001b[0m )\n\u001b[1;32m   1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1383\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1384\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1397\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[1;32m   1398\u001b[0m )\n\u001b[0;32m-> 1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    531\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/xgboost/core.py:1733\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1733\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1737\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_size_0=0.90\n",
    "testing_models_classifier(100)\n",
    "accuracy_test, accuracy_train, precision_train, precision_test, y_final_df = testing_models_classifier(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "984bbff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_model_classifier_results(n=10):\n",
    "    \n",
    "    #empty_lists\n",
    "    results_False=[]\n",
    "    results_True=[]\n",
    "    \n",
    "    #empty_lists\n",
    "    accuracy_test, accuracy_train, precision_train, precision_test, y_final_df = testing_models_classifier(n)\n",
    "    median_results_bad_bets = np.median(np.array(results_False))\n",
    "    median_results_good_bets = np.median(np.array(results_True))\n",
    "    \n",
    "    #Plotting the results of the XGB\n",
    "    sns.histplot(results_True,kde=True,bins=20,color='green')\n",
    "    sns.histplot(results_False,kde=True,bins=20,color='red')\n",
    "    \n",
    "    return median_results_bad_bets, median_results_good_bets, accuracy_test, accuracy_train, precision_train, precision_test, y_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ff951c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "median_results_bad_bets, median_results_good_bets, accuracy_test, accuracy_train, precision_train, precision_test, y_final_df = checking_model_classifier_results(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8998cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Results of the X tests with XGB (that you ran with the function testing_models)\n",
    "median_results_bad_bets = np.median(np.array(results_xgb_false))\n",
    "median_results_good_bets = np.median(np.array(results_xgb_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of the X tests with XGB (that you ran with the function testing_models)\n",
    "median_results_bad_bets = np.median(np.array(results_False))\n",
    "median_results_good_bets = np.median(np.array(results_True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1cbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_results_bad_bets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00918cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta variable (gap between bad and good group) is the variable we aim to maximise with our features and models fine-tuning, the greater the better!\n",
    "delta = np.median(np.array(median_results_good_bets))-np.median(np.array(median_results_bad_bets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06315620",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_extremes = np.median(np.array(results_xgb_4))-np.median(np.array(results_xgb_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = np.median(np.array(results_xgb_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ca733",
   "metadata": {},
   "outputs": [],
   "source": [
    "worse_results = np.median(np.array(results_xgb_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c92802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delta, delta_extremes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results of the XGB\n",
    "sns.histplot(results_True,kde=True,bins=20,color='green')\n",
    "sns.histplot(results_False,kde=True,bins=20,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d42b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results of the XGB\n",
    "sns.histplot(results_xgb_true,kde=True,bins=20,color='green')\n",
    "sns.histplot(results_xgb_false,kde=True,bins=20,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01379d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results of the XGB\n",
    "sns.histplot(results_xgb_1,kde=True,bins=20,color='red')\n",
    "sns.histplot(results_xgb_2,kde=True,bins=20,color='orange')\n",
    "sns.histplot(results_xgb_3,kde=True,bins=20,color='grey')\n",
    "sns.histplot(results_xgb_4,kde=True,bins=20,color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4279cf1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# [SKIP] Comments regarding results of the tests we ran and Next Steps [SKIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd443a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Comments\n",
    "\n",
    "# baseline = 0.008297694850435258 (all features)\n",
    "\n",
    "# delta without Joao features = 0.014419296789770412 => F:-0.029970666611150436 and T:-0.015551369821380024\n",
    "# --> WE REMOVE JOAO FEATURE\n",
    "\n",
    "# delta when removing the odds buckets = -0.009317543146000251 => F:-0.022611272813043187 and T:-0.028804787343669917\n",
    "# --> WE KEEP THE ODDS BUCKETS\n",
    "\n",
    "# delta when removing the odds buckets = -0.009317543146000251 => F:-0.022611272813043187 and T:-0.028804787343669917\n",
    "# --> WE KEEP THE ODDS BUCKETS\n",
    "\n",
    "# delta when removing the countries and divisions = 0.004795286566703704\n",
    "# --> WE KEEP THE COUNTRIES AND DIVISIONS\n",
    "\n",
    "# delta when removing the divisions but keeping the countries = 0.008380480363148559 (worsening)\n",
    "# delta when removing the countries but keeping the divisions = 0.02259680830123266 (best score ever)\n",
    "# --> WE KEEP THE DIVSIONS AND REMOVE THE COUNTRIES\n",
    "\n",
    "# delta when removing the 'month_after_July': 0.013657154854343441 DECREASED A LOT! We keep month after July\n",
    "# year 2020_2021 = 0.012829398919170131 DECREASED A LOT! \n",
    "# TIME MATTERS!! We need months, years, time\n",
    "\n",
    "# New basline: 0.023917075840908224\n",
    "\n",
    "#'Pin pays better' does not improve the baseline and we remove it\n",
    "\n",
    "#'Market_consensus' MATTERS we keep it\n",
    "\n",
    "#VIG matters\n",
    "\n",
    "# We should remove the P<PC variable\n",
    "# BEST DELTA: 0.03151890594630853\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3ddff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Next steps:\n",
    "\n",
    "## Time: Further explore how to optimise the features of time (years, months, hours, etc.)\n",
    "## Odds: Further explore how to optimise the odds buckets (different bins, min-max scaling)\n",
    "## VIG + Mkt Consensus: Further explore how to optimise VIG + Market consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db8eb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70fd7a8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# [SKIP] Other models + stats package we could use [SKIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c50b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1a60e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_model = xgb.XGBRegressor()\n",
    "my_model.fit(X_train_0,y_train_0) \n",
    "        \n",
    "        #Make and store the predictions XGBoost\n",
    "       # y_pred_xgb = m.predict(X_test)\n",
    "       # y_pred_xgb = pd.DataFrame(y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ac051",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#my_model = RandomForestRegressor(random_state=0).fit(X_step_joao, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92f724",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = my_model.predict(X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1128b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4b403",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_test_0)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values, X_test_0)\n",
    "\n",
    "#- Vertical location shows what feature it is depicting\n",
    "#- Color shows whether that feature was high or low for that row of the dataset\n",
    "#- Horizontal location shows whether the effect of that value caused a higher or lower prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a37281",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_0, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70af6d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
