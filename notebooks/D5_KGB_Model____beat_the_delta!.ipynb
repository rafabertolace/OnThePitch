{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1816ff7",
   "metadata": {},
   "source": [
    "# Imports and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4cf7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install XGBoost\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e1f50a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295e690",
   "metadata": {},
   "source": [
    "# Loading the Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4f75c",
   "metadata": {},
   "source": [
    "## Merging the Seasons csv files (2019-2020 untill 2021-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b6d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spain_2019_2020_1.csv', 'italy_2020_2021_2.csv', 'italy_2021_2022_1.csv', 'italy_2021_2022_2.csv', 'spain_2020_2021_1.csv', 'spain_2020_2021_2.csv', 'scotland_2020_2021_2.csv', 'Turkey_2021_2022_1.csv', 'scotland_2020_2021_3.csv', 'scotland_2019_2020_1.csv', 'france_2021_2022_1.csv', 'germany_2021_2022_1.csv', 'belgium_2020_2021_1.csv', 'scotland_2021_2022_4.csv', 'scotland_2020_2021_1.csv', 'france_2019_2020_1.csv', 'germany_2021_2022_2.csv', 'germany_2019_2020_1.csv', 'england_2020_2021_3.csv', 'scotland_2019_2020_2.csv', 'italy_2019_2020_1.csv', 'scotland_2020_2021_4.csv', 'portugal_2021_2022_1.csv', 'france_2020_2021_2.csv', 'scotland_2021_2022_3.csv', 'england_2021_2022_3.csv', 'portugal_2019_2020_1.csv', 'Greece_2021_2022_1.csv', 'england_2020_2021_4.csv', 'england_2021_2022_4.csv', 'france_2020_2021_1.csv', 'germany_2020_2021_1.csv', 'scotland_2019_2020_4.csv', 'spain_2019_20220_2.csv', 'germany_2019_2020_2.csv', 'england_2019_2020_4.csv', 'scotland_2021_2022_1.csv', 'england_2020_2021_2.csv', 'france_2019_2020_2.csv', 'Turkey_2019_2020_1.csv', 'england_2019_2020_2.csv', 'Eredivisie_2021_2022_1.csv', 'Turkey_2020_2021_1.csv', 'spain_2021_2022_1.csv', 'france_2021_2022_2.csv', 'belgium_2021_2022_1.csv', 'Greece_2019_2020_1.csv', 'belgium_2019_2020_1.csv', 'england_2019_2020_1.csv', 'Greece_2020_2021_1.csv', 'spain_2021_2022_2.csv', 'italy_2019_2020_2.csv', 'portugal_2020_2021_1.csv', 'Eredivisie_2020_2021_1.csv', 'italy_2020_2021_1.csv', 'Eredivisie_2019_2020_1.csv', 'england_2021_2022_2.csv', 'england_2020_2021_1.csv', 'england_2019_2020_3.csv', 'scotland_2021_2022_2.csv', 'scotland_2019_2020_3.csv', 'england_2021_2022_1.csv', 'germany_2020_2021_2.csv']\n"
     ]
    }
   ],
   "source": [
    "# Customise based on your path and folder organisation\n",
    "print(os.listdir('../raw_data/All4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2208c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the CSVs\n",
    "\n",
    "files = [file for file in os.listdir('../raw_data/All4') if file.endswith('.csv')]\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv('../raw_data/All4/' + file)\n",
    "    df['country']=str(file)[0:2]\n",
    "    df['country_division']=str(file)[-5:-4]\n",
    "    data = pd.concat([data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ab8e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20940, 110)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8ad8d",
   "metadata": {},
   "source": [
    "# Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acad4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the function\n",
    "\n",
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "        '''\n",
    "    #------------------------Number of Goals, Over and Under -----------------------------------\n",
    "    \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "    \n",
    "    #-----------------------------Payout Opening ----------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average OPENING odds\n",
    "    data['payout_avg_under_2.5'] = data['under_2.5_goals']*data['Avg<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average OPENING odds\n",
    "    data['payout_avg_over_2.5'] = data['over_2.5_goals']*data['Avg>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['P<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['P>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365>2.5']\n",
    "    \n",
    "    #------------------------------Payout Closing --------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_under_closing_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_over_closing_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE closing ddds specifically\n",
    "    data['payout_under_2.5_pinacle_closing'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE closing odds specifically\n",
    "    data['payout_over_2.5_pinacle_closing'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 closing odds specifically\n",
    "    data['payout_under_2.5_365_closing'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 closing odds specifically\n",
    "    data['payout_over_2.5_365_closing'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #-------------------------- Implied Probability Opening ----------------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability <2.5 avg']=1/data['Avg<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability >2.5 avg']=1/data['Avg>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['P<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['P>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365>2.5']*100\n",
    "    \n",
    "    #------------------------- Implied Probability Closing -----------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability <2.5 avg closing']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability >2.5 avg closing']=1/data['AvgC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability <2.5 pinacle closing']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability >2.5 pinacle closing']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability <2.5 365 closing']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability >2.5 365 closing']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    #---------------------------- Binning IP Opening -------------------------------------\n",
    "\n",
    "    b=b\n",
    "    bins = np.arange(0, 101, int(100/b))\n",
    "    bins = bins.tolist()\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned <2.5 avg'] = pd.cut(data['Implied Probability <2.5 avg'], bins)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned >2.5 avg'] = pd.cut(data['Implied Probability >2.5 avg'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "    \n",
    "    #----------------------------- Binning IP Closing ------------------------------------------------\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market closing odds\n",
    "    data['binned <2.5 avg closing'] = pd.cut(data['Implied Probability <2.5 avg closing'], bins)\n",
    "\n",
    "    #Binning OVER 2.5 Average Market closing odds\n",
    "    data['binned >2.5 avg closing'] = pd.cut(data['Implied Probability >2.5 avg closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle closing odds\n",
    "    data['binned <2.5 pinacle closing'] = pd.cut(data['Implied Probability <2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle CLOSING odds\n",
    "    data['binned >2.5 pinacle closing'] = pd.cut(data['Implied Probability >2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 CLOSING odds\n",
    "    data['binned <2.5 365 closing'] = pd.cut(data['Implied Probability <2.5 365 closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 CLOSING odds\n",
    "    data['binned >2.5 365 closing'] = pd.cut(data['Implied Probability >2.5 365 closing'], bins)\n",
    "    \n",
    "    #---------------------------- Binning Odds Opening ----------------------------------------------------\n",
    "    \n",
    "    bins2 = [1, 1.5, 2, 3, 99999]\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle'] = pd.cut(data['P<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle'] = pd.cut(data['P>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365'] = pd.cut(data['B365<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365'] = pd.cut(data['B365>2.5'], bins2)\n",
    "    \n",
    "    #----------------------------- Binning Odds Closing ----------------------------------------------------------\n",
    "    \n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg closing'] = pd.cut(data['AvgC<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg closing'] = pd.cut(data['AvgC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle closing'] = pd.cut(data['PC<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle closing'] = pd.cut(data['PC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365 closing'] = pd.cut(data['B365C<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365 closing'] = pd.cut(data['B365C>2.5'], bins2)\n",
    "    \n",
    "    \n",
    "    #----------------------------- Other Features from D3 ------------------------------------------------------\n",
    "    \n",
    "    data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "    data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "    data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "    data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "    data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "    data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "    \n",
    "    #----------------------- Odds and probability of the home team scoring under 2.5 -------------------------------\n",
    "    \n",
    "#     lst1 = []\n",
    "#     lst2 = []\n",
    "#     for i, team in enumerate(data['HomeTeam']):\n",
    "#         date = data['Date'].iloc[i]\n",
    "#         total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "#         n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "#         try:\n",
    "#             lst1.append(1/(n_under_home[1]/total))\n",
    "#             lst2.append(n_under_home[1]/total)\n",
    "#         except:\n",
    "#             lst1.append(np.nan)\n",
    "#             lst2.append(np.nan)\n",
    "\n",
    "#     data['odds_home_under'] = lst1\n",
    "#     data['prob_home_under'] = lst2\n",
    "    \n",
    "#     #binning the probability of the home team to have a game of less than 2.5 score\n",
    "#     data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, bins)\n",
    "    \n",
    "    \n",
    "    #----------------------- Odds and probability of the away team scoring under 2.5 -------------------------------\n",
    "    \n",
    "#     lst3 = []\n",
    "#     lst4  = []\n",
    "#     for i, team in enumerate(data['AwayTeam']):\n",
    "#         date = data['Date'].iloc[i]\n",
    "#         total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "#         n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "#         try:\n",
    "#             lst3.append(1/(n_under_away2[1] / total2))\n",
    "#             lst4.append(n_under_away2[1] / total2)\n",
    "#         except:\n",
    "#             lst3.append(np.nan)\n",
    "#             lst4.append(np.nan)\n",
    "\n",
    "#     data['odds_away_under'] = lst3\n",
    "#     data['prob_away_under'] = lst4\n",
    "    \n",
    "#     #binning the probability of the away team to have a game of less than 2.5 score\n",
    "#     data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, bins)\n",
    "\n",
    "    #-------------------------- Creating the prob and odds of the game -----------------------------------------------\n",
    "#     '''the mean between the probability of the home team to have a score of under 2.5 and the probability \n",
    "#     of the away team to do the same'''\n",
    "    \n",
    "#     data['odds_game'] = (data['odds_away_under'] +  data['odds_home_under']) / 2\n",
    "#     data['prob_game'] = (data['prob_away_under'] + data['prob_home_under']) / 2\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned probabilities columns ------------------------------------------\n",
    "    \n",
    "\n",
    "#     if b == 5:\n",
    "#         data = data[~data['binned prob_home_under'].isna()]\n",
    "#         ohe = OneHotEncoder(sparse=False)\n",
    "#         ohe.fit(data[['binned prob_home_under']])\n",
    "#         bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "#         data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "        \n",
    "#     if b == 10:\n",
    "#         data = data[~data['binned prob_home_under'].isna()]\n",
    "#         ohe = OneHotEncoder(sparse=False)\n",
    "#         ohe.fit(data[['binned prob_home_under']])\n",
    "#         bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "#         data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "#         data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "        \n",
    "#     if b == 20:\n",
    "#         data = data[~data['binned prob_home_under'].isna()]\n",
    "#         ohe = OneHotEncoder(sparse=False)\n",
    "#         ohe.fit(data[['binned prob_home_under']])\n",
    "#         bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "#         data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "#         data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "#         data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "#         data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "    \n",
    "    #------------------------------------ Cleaning the data ---------------------------------------------------------\n",
    "    \n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data = data[~data['PC>2.5'].isna()]\n",
    "    data.drop(columns=['Referee','Unnamed: 105'], inplace=True) #, 'Unnamed: 105' 'Referee', \n",
    "    #data.dropna()\n",
    "    \n",
    "     #-------------------------- OneHotEncoding the binned odds ------------------------------------------\n",
    "   \n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['binned odds <2.5 pinacle closing']])\n",
    "    bins_encoded = ohe.transform(data[['binned odds <2.5 pinacle closing']])\n",
    "    data[\"1.0_to_1.5\"], data[\"1.5_to_2.0\"], data[\"2.0_to_3.0\"], data[\"3.0_to_99999.0\"] = bins_encoded.T\n",
    "    data.drop(columns='binned odds <2.5 pinacle closing', inplace=True)\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned countries ------------------------------------------\n",
    "\n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['country']])\n",
    "    bins_encoded = ohe.transform(data[['country']])\n",
    "    data[\"country_1\"], data[\"country_2\"], data[\"country_3\"], data[\"country_4\"], data[\"country_5\"],data[\"country_6\"], data[\"country_7\"], data[\"country_8\"], data[\"country_9\"], data[\"country_10\"], data[\"country_11\"] = bins_encoded.T\n",
    "    data.drop(columns='country', inplace=True)\n",
    "\n",
    "    #-------------------------- OneHotEncoding the binned country divisions ------------------------------------------\n",
    "    \n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['country_division']])\n",
    "    bins_encoded = ohe.transform(data[['country_division']])\n",
    "    data[\"country_div_1\"], data[\"country_div_2\"], data[\"country_div_3\"], data[\"country_div_4\"] = bins_encoded.T\n",
    "    data.drop(columns='country_division', inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c518df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the function and creating the dataset data\n",
    "\n",
    "data = feature_engineering(data, b=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d725b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE WILL NEED TO ADD ALL THOSE IN THE feature_engineering FUNCTION\n",
    "\n",
    "## Adding the Year Feature \n",
    "data_date = data['Date']\n",
    "data_time = data['Time']\n",
    "data_date_2 = pd.to_datetime(data_date, dayfirst = True)\n",
    "data_time_2 = pd.to_datetime(data_time, dayfirst = True)\n",
    "data['month'] = pd.DatetimeIndex(data_date_2).month\n",
    "data['month_after_July'] = data['month']>=7\n",
    "data['year'] = pd.DatetimeIndex(data_date_2).year\n",
    "data['year_2021_2022'] = data['year']>=2021\n",
    "data['hour'] = pd.DatetimeIndex(data_time_2).hour\n",
    "data['game_starts_after_4pm']=data['hour']>=16\n",
    "\n",
    "#Other features\n",
    "data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "data['%vig_p_bool'] = data['%vig_p']>3.3\n",
    "data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "data['MaxC>2.5_AvgC_relative_diff'] = data['MaxC>2.5']/data['AvgC>2.5']\n",
    "data['Market_consensus'] = data['MaxC>2.5_AvgC_relative_diff']<1.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0df27",
   "metadata": {},
   "source": [
    "# Running the XGB model for under 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899a0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model dataset with relevant variables\n",
    "data_linear_booleans_lean_P_under = data[['country_div_1','country_div_2','country_div_3', 'month_after_July','year_2021_2022','game_starts_after_4pm','Market_consensus','%vig_p_bool','1.0_to_1.5', '1.5_to_2.0', '2.0_to_3.0','3.0_to_99999.0','payout_under_2.5_pinacle_closing']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0bb8a",
   "metadata": {},
   "source": [
    "## Defining the function testing_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab21f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lr_true = []\n",
    "# results_lr_false = []\n",
    "results_xgb_true = [] \n",
    "results_xgb_false = []\n",
    "results_xgb_1=[]\n",
    "results_xgb_2=[]\n",
    "results_xgb_3=[]\n",
    "results_xgb_4=[]\n",
    "\n",
    "def testing_models(iterations):   \n",
    "    i=0\n",
    "    while i < iterations:\n",
    "        # Split into Train/Test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.3) # Split into Train/Test\n",
    "\n",
    "            #------------------------Run the Models -----------------------------------\n",
    "\n",
    "        #Run Linear Regression\n",
    "#         results_linear_regression = sm.OLS(y_train,X_train.astype(float)).fit()\n",
    "#         y_pred_lr = results_linear_regression.predict(X_test.astype(float))\n",
    "#         #results.summary()\n",
    "\n",
    "        #Initiate XGBoost\n",
    "        m = xgb.XGBRegressor()\n",
    "        \n",
    "        #Rename columns for XGBoost to run\n",
    "        X_test.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        X_train.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        \n",
    "        #Fit XGBoost\n",
    "        m.fit(X_train,y_train) \n",
    "        \n",
    "        #Make and store the predictions XGBoost\n",
    "        y_pred_xgb = m.predict(X_test)\n",
    "        y_pred_xgb = pd.DataFrame(y_pred_xgb)\n",
    "\n",
    "            #------------------------Creating the bins for the predictions for both models -----------------------------------\n",
    "        #Function to replace bin with default value when it is null\n",
    "        def ifnull(var, val):\n",
    "          if var > 0:\n",
    "            return var\n",
    "          return val\n",
    "\n",
    "        #Linear Regression\n",
    "#         y_pred_lr_under_0_median = y_pred_lr[y_pred_lr<0].median()\n",
    "#         y_pred_lr_under_0_min = y_pred_lr[y_pred_lr<0].min()\n",
    "#         y_pred_lr_over_0_median = ifnull(y_pred_lr[y_pred_lr>0].median(),0.05)\n",
    "\n",
    "        #XGB bins\n",
    "        y_pred_xgb_under_0_median = y_pred_xgb[y_pred_xgb<0].median()\n",
    "        y_pred_xgb_under_0_min = y_pred_xgb[y_pred_xgb<0].min()\n",
    "        y_pred_xgb_over_0_median = ifnull(y_pred_xgb[0][y_pred_xgb[0]>0].median(),0.05)\n",
    "        \n",
    "\n",
    "            #------------------------Betting decisions for both models -----------------------------------\n",
    "#         #Linear Regression\n",
    "#         bins3_lr = [y_pred_lr_under_0_min-0.0000002, y_pred_lr_under_0_median-0.0000001, 0, y_pred_lr_over_0_median+0.0000001, 1]\n",
    "#         y_lr_df = pd.DataFrame(y_test)\n",
    "#         y_pred_lr_df = pd.DataFrame(y_pred_lr)\n",
    "#         y_pred_lr_df[\"binned_pred\"] = pd.cut(y_pred_lr_df[0], bins3_lr)\n",
    "#         ind = np.arange(0, len(y_pred_lr_df))\n",
    "#         ind = ind.tolist()\n",
    "#         y_lr_df['ind'] = ind\n",
    "#         y_pred_lr_df['ind'] = ind\n",
    "#         y_final_lr = y_lr_df.merge(y_pred_lr_df, on=\"ind\")#, on = \"axis\")#, how = \"inner\")\n",
    "#         y_final_lr['bet_opp']=y_final_lr[0]>0\n",
    "\n",
    "        #XGB\n",
    "        bins3_xgb = [y_pred_xgb_under_0_min[0]-0.0000002, y_pred_xgb_under_0_median[0]-0.0000001, 0, y_pred_xgb_over_0_median+0.0000001, 1] #int(y_pred_xgb_over_0_median[0])\n",
    "        y_xgb_df = pd.DataFrame(y_test)\n",
    "        y_pred_xgb_df = pd.DataFrame(y_pred_xgb)\n",
    "        y_pred_xgb_df[\"binned_pred\"] = pd.cut(y_pred_xgb_df[0], bins3_xgb)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_1\"] = y_pred_xgb_df[0]<y_pred_xgb_under_0_median[0]-0.0000001\n",
    "        y_pred_xgb_df[\"binned_pred_bin_2\"] = (y_pred_xgb_df[0]>y_pred_xgb_under_0_median[0]-0.0000001) & (y_pred_xgb_df[0]<0)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_3\"] = (y_pred_xgb_df[0]>0) & (y_pred_xgb_df[0]<y_pred_xgb_over_0_median+0.0000001)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_4\"] = (y_pred_xgb_df[0]>y_pred_xgb_over_0_median+0.0000001)\n",
    "        y_pred_xgb_df[\"bin_number\"] = y_pred_xgb_df[\"binned_pred_bin_1\"]*1 + y_pred_xgb_df[\"binned_pred_bin_2\"]*2 + y_pred_xgb_df[\"binned_pred_bin_3\"]*3 + y_pred_xgb_df[\"binned_pred_bin_4\"]*4     \n",
    "        ind = np.arange(0, len(y_pred_xgb_df))\n",
    "        ind = ind.tolist()\n",
    "        y_xgb_df['ind'] = ind\n",
    "        y_pred_xgb_df['ind'] = ind\n",
    "        y_final_xgb = y_xgb_df.merge(y_pred_xgb_df, on=\"ind\")#, on = \"axis\")#, how = \"inner\")\n",
    "        \n",
    "        #Defining the variable bet_opp based on the y_pred of the XGB\n",
    "        y_final_xgb['bet_opp']=y_final_xgb[0]>0\n",
    "\n",
    "            #------------------------Getting the results based on predictions -----------------------------------\n",
    "        #Linear Regression\n",
    "#         y_final_lr.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].count()\n",
    "#         y_final_lr.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].agg([\"mean\", \"count\"])\n",
    "\n",
    "#         y_final_lr.groupby('binned_pred')['payout_under_2.5_pinacle_closing'].count()\n",
    "#         y_final_lr.groupby('binned_pred')['payout_under_2.5_pinacle_closing'].agg([\"mean\", \"count\"])\n",
    "#         lr_results_False = y_final_lr[y_final_lr['bet_opp']==False]['payout_under_2.5_pinacle_closing'].mean()\n",
    "#         lr_results_True = y_final_lr[y_final_lr['bet_opp']==True]['payout_under_2.5_pinacle_closing'].mean()        \n",
    "        \n",
    "\n",
    "        #XGB\n",
    "        #xgb_count = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].count()\n",
    "        #xgb_mean = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].mean()\n",
    "        #xgb_results = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].agg([\"mean\", \"count\"])\n",
    "        xgb_results_False = y_final_xgb[y_final_xgb['bet_opp']==False]['payout_under_2.5_pinacle_closing'].mean()\n",
    "        xgb_results_True = y_final_xgb[y_final_xgb['bet_opp']==True]['payout_under_2.5_pinacle_closing'].mean()\n",
    "        xgb_results_bin_1 = y_final_xgb[y_final_xgb['bin_number']==1]['payout_under_2.5_pinacle_closing'].mean()\n",
    "        xgb_results_bin_2 = y_final_xgb[y_final_xgb['bin_number']==2]['payout_under_2.5_pinacle_closing'].mean()\n",
    "        xgb_results_bin_3 = y_final_xgb[y_final_xgb['bin_number']==3]['payout_under_2.5_pinacle_closing'].mean()\n",
    "        xgb_results_bin_4 = y_final_xgb[y_final_xgb['bin_number']==4]['payout_under_2.5_pinacle_closing'].mean()\n",
    "        \n",
    "        results_xgb_false.append(xgb_results_False)\n",
    "        results_xgb_true.append(xgb_results_True)\n",
    "        results_xgb_1.append(xgb_results_bin_1)\n",
    "        results_xgb_2.append(xgb_results_bin_2)\n",
    "        results_xgb_3.append(xgb_results_bin_3)\n",
    "        results_xgb_4.append(xgb_results_bin_4)\n",
    "        \n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b51625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifnull(var, val):\n",
    "    if var > 0:\n",
    "        return var\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74fe44a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df_temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[0;32m----> 2\u001b[0m df_temp \u001b[38;5;241m=\u001b[39m \u001b[43mX1\u001b[49m\n\u001b[1;32m      3\u001b[0m df_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayout_under_2.5_pinacle_closing\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_linear_booleans_lean_P_under[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayout_under_2.5_pinacle_closing\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m df_temp\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X1' is not defined"
     ]
    }
   ],
   "source": [
    "df_temp = pd.DataFrame\n",
    "df_temp = X1\n",
    "df_temp['payout_under_2.5_pinacle_closing'] = data_linear_booleans_lean_P_under['payout_under_2.5_pinacle_closing']-1\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08748147",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results_False=[]\n",
    "xgb_results_True=[]\n",
    "results_xgb_1=[]\n",
    "results_xgb_2=[]\n",
    "results_xgb_3=[]\n",
    "results_xgb_4=[]\n",
    "\n",
    "\n",
    "# Split into Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.3) # Split into Train/Test\n",
    "\n",
    "\n",
    "        #Initiate XGBoost\n",
    "m = xgb.XGBRegressor()\n",
    "        \n",
    "        #Rename columns for XGBoost to run\n",
    "X_test.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "X_train.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        \n",
    "        #Fit XGBoost\n",
    "m.fit(X_train,y_train) \n",
    "        \n",
    "        #Make and store the predictions XGBoost\n",
    "y_pred_xgb = m.predict(X_test)\n",
    "y_pred_xgb = pd.DataFrame(y_pred_xgb)\n",
    "\n",
    "            #------------------------Creating the bins for the predictions for both models -----------------------------------\n",
    "        #Function to replace bin with default value when it is null\n",
    "        #Linear Regression\n",
    "#         y_pred_lr_under_0_median = y_pred_lr[y_pred_lr<0].median()\n",
    "#         y_pred_lr_under_0_min = y_pred_lr[y_pred_lr<0].min()\n",
    "#         y_pred_lr_over_0_median = ifnull(y_pred_lr[y_pred_lr>0].median(),0.05)\n",
    "\n",
    "        #XGB bins\n",
    "y_pred_xgb_under_0_median = y_pred_xgb[y_pred_xgb<0].median()\n",
    "y_pred_xgb_under_0_min = y_pred_xgb[y_pred_xgb<0].min()\n",
    "y_pred_xgb_over_0_median = ifnull(y_pred_xgb[0][y_pred_xgb[0]>0].median(),0.05)\n",
    "\n",
    "            #------------------------Betting decisions for both models -----------------------------------\n",
    "#         #Linear Regression\n",
    "#         bins3_lr = [y_pred_lr_under_0_min-0.0000002, y_pred_lr_under_0_median-0.0000001, 0, y_pred_lr_over_0_median+0.0000001, 1]\n",
    "#         y_lr_df = pd.DataFrame(y_test)\n",
    "#         y_pred_lr_df = pd.DataFrame(y_pred_lr)\n",
    "#         y_pred_lr_df[\"binned_pred\"] = pd.cut(y_pred_lr_df[0], bins3_lr)\n",
    "#         ind = np.arange(0, len(y_pred_lr_df))\n",
    "#         ind = ind.tolist()\n",
    "#         y_lr_df['ind'] = ind\n",
    "#         y_pred_lr_df['ind'] = ind\n",
    "#         y_final_lr = y_lr_df.merge(y_pred_lr_df, on=\"ind\")#, on = \"axis\")#, how = \"inner\")\n",
    "#         y_final_lr['bet_opp']=y_final_lr[0]>0\n",
    "\n",
    "        #XGB\n",
    "bins3_xgb = [y_pred_xgb_under_0_min[0]-0.0000002, y_pred_xgb_under_0_median[0]-0.0000001, 0, y_pred_xgb_over_0_median+0.0000001, 1] #int(y_pred_xgb_over_0_median[0])\n",
    "y_xgb_df = pd.DataFrame(y_test)\n",
    "y_pred_xgb_df = pd.DataFrame(y_pred_xgb)\n",
    "y_pred_xgb_df[\"binned_pred\"] = pd.cut(y_pred_xgb_df[0], bins3_xgb)\n",
    "\n",
    "y_pred_xgb_df[\"binned_pred_bin_1\"] = y_pred_xgb_df[0]<y_pred_xgb_under_0_median[0]-0.0000001\n",
    "y_pred_xgb_df[\"binned_pred_bin_2\"] = (y_pred_xgb_df[0]>y_pred_xgb_under_0_median[0]-0.0000001) & (y_pred_xgb_df[0]<0)\n",
    "y_pred_xgb_df[\"binned_pred_bin_3\"] = (y_pred_xgb_df[0]>0) & (y_pred_xgb_df[0]<y_pred_xgb_over_0_median+0.0000001)\n",
    "y_pred_xgb_df[\"binned_pred_bin_4\"] = (y_pred_xgb_df[0]>y_pred_xgb_over_0_median+0.0000001)\n",
    "y_pred_xgb_df[\"bin_number\"] = y_pred_xgb_df[\"binned_pred_bin_1\"]*1 + y_pred_xgb_df[\"binned_pred_bin_2\"]*2 + y_pred_xgb_df[\"binned_pred_bin_3\"]*3 + y_pred_xgb_df[\"binned_pred_bin_4\"]*4\n",
    "\n",
    "ind = np.arange(0, len(y_pred_xgb_df))\n",
    "ind = ind.tolist()\n",
    "y_xgb_df['ind'] = ind\n",
    "y_pred_xgb_df['ind'] = ind\n",
    "y_final_xgb = y_xgb_df.merge(y_pred_xgb_df, on=\"ind\")#, on = \"axis\")#, how = \"inner\")\n",
    "        \n",
    "        #Defining the variable bet_opp based on the y_pred of the XGB\n",
    "y_final_xgb['bet_opp']=y_final_xgb[0]>0\n",
    "\n",
    "xgb_results_False = y_final_xgb[y_final_xgb['bet_opp']==False]['payout_under_2.5_pinacle_closing'].mean()\n",
    "xgb_results_True = y_final_xgb[y_final_xgb['bet_opp']==True]['payout_under_2.5_pinacle_closing'].mean()\n",
    "xgb_results_bin_1 = y_final_xgb[y_final_xgb['bin_number']==1]['payout_under_2.5_pinacle_closing'].mean()\n",
    "xgb_results_bin_2 = y_final_xgb[y_final_xgb['bin_number']==2]['payout_under_2.5_pinacle_closing'].mean()\n",
    "xgb_results_bin_3 = y_final_xgb[y_final_xgb['bin_number']==3]['payout_under_2.5_pinacle_closing'].mean()\n",
    "xgb_results_bin_4 = y_final_xgb[y_final_xgb['bin_number']==4]['payout_under_2.5_pinacle_closing'].mean()\n",
    "\n",
    "\n",
    "results_xgb_false.append(xgb_results_False)\n",
    "results_xgb_true.append(xgb_results_True)\n",
    "results_xgb_1.append(xgb_results_bin_1)\n",
    "results_xgb_2.append(xgb_results_bin_2)\n",
    "results_xgb_3.append(xgb_results_bin_3)\n",
    "results_xgb_4.append(xgb_results_bin_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18786804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03303382663847781]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_xgb_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dac4f9",
   "metadata": {},
   "source": [
    "## Running the function testing_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83b36f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPO\n",
    "# CLIMA\n",
    "# INICIO DE TEMPORADA\n",
    "# FINAL DE TEMPORADA\n",
    "\n",
    "# AGOSTO SETEMBRO OUTUBRO \n",
    "# NOVEMBRO DEZEMBRO JANEIRO\n",
    "# FEVEREIRO MARCO ABRIL\n",
    "\n",
    "# AFTER 4 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a566ee46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Market_consensus',\n",
       " '%vig_p_bool',\n",
       " '1.0_to_1.5',\n",
       " '1.5_to_2.0',\n",
       " '2.0_to_3.0',\n",
       " '3.0_to_99999.0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'country_div_1','country_div_2','country_div_3','country_div_4','month_after_July','year_2021_2022','game_starts_after_4pm',\n",
    "'Market_consensus','%vig_p_bool','1.0_to_1.5', '1.5_to_2.0', '2.0_to_3.0','3.0_to_99999.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b44a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select here the variables you want to include in the testing\n",
    "X1 = data_linear_booleans_lean_P_under[['country_div_1','country_div_2','country_div_3', 'month_after_July','year_2021_2022','game_starts_after_4pm','Market_consensus','%vig_p_bool','1.0_to_1.5', '1.5_to_2.0', '2.0_to_3.0','3.0_to_99999.0']]\n",
    "y = data_linear_booleans_lean_P_under['payout_under_2.5_pinacle_closing']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a8a24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function testing_models\n",
    "testing_models(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8998cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of the X tests with XGB (that you ran with the function testing_models)\n",
    "median_results_bad_bets = np.median(np.array(results_xgb_false))\n",
    "median_results_good_bets = np.median(np.array(results_xgb_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00918cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta variable (gap between bad and good group) is the variable we aim to maximise with our features and models fine-tuning, the greater the better!\n",
    "delta = np.median(np.array(median_results_good_bets))-np.median(np.array(median_results_bad_bets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06315620",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_extremes = np.median(np.array(results_xgb_4))-np.median(np.array(results_xgb_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "655b2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = np.median(np.array(results_xgb_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c1ca733",
   "metadata": {},
   "outputs": [],
   "source": [
    "worse_results = np.median(np.array(results_xgb_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72c92802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04440093010471683 0.05730233722035934\n"
     ]
    }
   ],
   "source": [
    "print(delta, delta_extremes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d42b641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the results of the XGB\n",
    "sns.histplot(results_xgb_true,kde=True,bins=20,color='green')\n",
    "sns.histplot(results_xgb_false,kde=True,bins=20,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01379d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD4CAYAAAD//dEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABejklEQVR4nO2dd1hU19aH35mh916kDXasWLAbiSXR3BSNSTTVJJYU06tpF0z5EtM0PdeSXqwx0RRrJHZExYKNIl2pClKkzvn+OEhEigPMmRlgv88zD8w5++z1m8Mwa/bea6+lAiQEAoFAILgKalMLEAgEAkHbQDgMgUAgEOiFcBgCgUAg0AvhMAQCgUCgF8JhCAQCgUAvLEwtQB9ycnJITU01tQyBQCBoUwQFBeHl5WWw/tqEw0hNTSUsLMzUMgQCgaBNERMTY9D+xJSUQCAQCPRCOAyBQCAQ6IVwGAKBQCDQC+EwBAKBQKAXwmEIBAKBQC+EwxAIBAKBXijmMKytrYmOjubQoUPExcURGRkJgFarZe/evSQkJLB8+XIsLS2VkiAQCAQCA6KYwygvL2fs2LGEhoYSGhrKxIkTGTp0KAsWLGDhwoV069aN8+fPM3PmTKUkCAQCgcCAKDolVVJSAoClpSWWlpZIksTYsWNZvXo1AN9++y2TJ09WUoJAIBAIDISiDkOtVhMbG0tOTg6bN28mKSmJgoICqqurAcjIyMDPz6/Ba2fPnk1MTAwxMTF4eHgoKVOgMOnJyUiSdNVHenKyqaUKBIImUDQ1iE6nY8CAATg7O7N27Vp69uyp97VLlixhyZIlgOG3twuMi79WS6RKddV2kZIo/igQmDNGiZIqLCxk27ZtDB8+HBcXFzQaDQD+/v5kZmYaQ4JAIBAIWoliDsPDwwNnZ2cAbGxsmDBhAidOnGDbtm3cdtttAMyYMYPffvtNKQkCgUAgMCCKTUn5+vry7bffotFoUKvVrFy5kj/++IPjx4+zfPly3nzzTWJjY1m2bJlSEgQCgUBgQBRzGEePHmXgwIH1jicnJzN06FClzAoEAoFAIcROb4FAIBDohXAYAoFAINAL4TAEAoFAoBfCYQgEAoFAL4TDEAgEAoFeCIchEAgEAr0QDkMgEAgEeiEchkAgEAj0QjgMgdmSnqpnlttUkeVWIDAGimarFQhag3+glsipemS5XSOy3AoExkCMMAQCgUCgF8JhCAQCgUAvhMMQCAQCgV4IhyEQCAQCvRAOo4Mh6mu3bZL1jByTJIlkET0mMDAiSqqDIeprt220gVpU11797wcgbRN/Q4FhESMMgUAgEOiFcBgCgUAg0AvhMAQCgUCgF8JhCAQCgUAvhMMQCAQCgV4IhyEQCAQCvRAOQyAQCAR6IRyGQCAQCPRCOAyBQCAQ6IViDsPf35+///6bY8eOERcXxxNPPAFAREQEGRkZxMbGEhsby6RJk5SSIBAIBAIDolhqkKqqKp599lliY2NxcHDgwIEDbN68GYCFCxfywQcfKGVaIBAIBAqgmMPIysoiKysLgOLiYk6cOIGfn59S5gQCgUCgMEZJPhgUFMSAAQOIjo5m5MiRPPbYY9x3333s37+fZ599loKCgnrXzJ49mzlz5gDg4eFhDJkCI/FMajJOgdoGz0kmSHqYnJyOVuvf7OtSUjIIDg5QQFHDJCenA/K0rj5U6ar0vp8paSkEBwW3WJugY6ACFP0Ptbe3559//uGtt95i7dq1eHl5kZeXhyRJvPHGG/j6+jJz5swm+4iJiSEsLExJmR0GSZL0zlar0qNdS2xGShJRDdTqDo+IIHL+/H/brZH0rundGq2SJKFSRbbgukiD3SP97Mn/qqprw/Vrvy0K1bXhRESEM/+y+9pwW8P9vQXmg6E/OxWNkrKwsGDNmjX8+OOPrF27FoCcnBx0Oh2SJLFkyRKGDBmipASBQCAQGAhFHcayZcs4ceIECxcurD3m4+NT+/uUKVOIi4tTUoJAIBAIDIRiaxgjR47kvvvu48iRI8TGxgLw8ssvc+eddxIaGookSaSkpPDQQw8pJUEgEAgEBkQxh7Fr164G50T/+usvpUwKBAKBQEHETm+BQCAQ6IVwGAKBQCDQC+EwBAZDDbgBtqYWIhAIFEE4DEGr8AWeAnYAJUA+UAokAK8DLqYSJhAIDI5RdnoL2h9dgZeAewFL4CDwGZAO2AOjgFeAhwC2bjWNSIFAYFCEwxA0CwcgAngSqAK+QHYU8Q207Q/8CHhNnEgP4JSxRAoEAkUQU1ICvRkLnACeAb4BgpEdR0POAuAwMAJgwABuQ56+EggEbRfhMARXRQMsALYCRcBwYA6Qrce1FwD++IOLwG3I01cCgaBtIqakBA1TVZPptLAQpk2DjRvh4YcJ+eADou3sAMhISSEgWI8Mp56erAEeAMYoKlqARRVYlUPlv65Zp9Mvw+2VmW2NnY1XYP4IhyFoGAsL3lWpmAF4AH8AB7/8Er78srZJZDNSkacCscijExISDCpVIIFPFvidAcfi2qM9P+0JflXoqOKN+Tub7CEynHoZeyUpsqGmgg6McBiChsnLYwbyvoofgdMG6HIL0BvQXCXVtqAZWJdB7+PgVARFDnA6GMqswaoCjwAPTnXbxeIDi8E+EEocTK1W0MYRaxiCelgCTJyIG/AThnEWIO/TiAb46SdsiwzUaUfGvhgGHQS7UjgeAgcGQlog5HhDRgA7H9wJR/pwseoiDDgELgWmVixo4wiHIajHzQAHD7IKSDZw33sBrKwISDRwxx0NuxIIPQw6tewocryQ66FdwTl3Zg2YBeXW0PcoOF0wulRB+0E4DEEdRgB9Ad56q9Fw2dZQAnDffXingkW5AgY6AhaV0DcOJBUc6g8X7Zps7mzjDIf7Q4UV9ImTp7EEghYgHIagFm9gHHAcYN485Qw9+igaHXhlKGeivSJJEvSIB+tyiOsDZXpm7qqwgiN9Qa2T1zxUOmWFCtolwmEIAHmvxRTgIrAeQJ/6zjWht1d71CM0lCJn8E016EvoEHx3+DvwzIPkYLjg1LyLL9rBqR7yAnlAujICBe0aESUlAOTcTz7Az8hOQy8sLIjUw7E0FH6bFQTdjoB9IZQ4N0NoBya1IJXH/3ocCpwh3b9lneR6Qo4naFMhzwNK7Q0rUtCuESMMAc7IDiMO4+V7ygkAnQp8xChDbx7+42EkJDjZgwYXuPUloStUa6DnKUD/vTQCgXAYAsbX/NxsRJuV1pDvC97pYjpdL7rChsQNzA+fr/+6RWNUWslOw6kIfM8aRp+gQyAcRgfHHzkqajdQaGTb2QFyFgvn/MbbeDvBoGAYqAVPR6NJMy/UwPXQ1a0rjw15zDB95nhBoRMEp4CmyjB9Cto9Yg2jgzMOOaHgLhPYPucN1WrwOAMFnnXPOdsBf1/HIxPqHk/Mht8PQkGp0WSansGAJ3xw3QdYaawM1KkKErvAoFgIEOFqAv0QDqMDE4iconwDUGEC+zoLOO8tO4zEfv8e93WBe0cB+dFsPAInMuXjvfzhmh7w0Dj4eTekNTEyaTdYAeHAabip+02G7bvISV4AD0jnTNEZw/YtaJcIh9GBuQbQebgzMTWNiXb1N39dHt10IS2FD4P0yEzbTPI6gcdZcCyQn7s7wH2jobwS7K7fz57l3Wvb7o6XncfdI+GeUfD1P3C2QH9b6anJ+AdqGzwXERFZ+/uFwgIWLlrU3JeiDEMAO2ALqPQJdW4up4PBI4/X/3kdOU5OIGgc4TA6KH7IZVZ5/gWi7q0fWhkeEUHUZUkCw9coE02T5yNvWPY4A+gqmD4cJAm+3QFPzu5Wr/35EvjmH5h1LUwfDov/1t+Wf6CWyKn1P3Qj10hErYisfR4+LbJeG5Nghbz1PgFQagBQZgtnffgq9itwmgsXRIyzoHHEoncHZSQ1+y0eecSkOqqsocCjxmFkb8PTCVbvkx1DYxSXw4q9YGcNtw8FdJXGkmtcwpBHF1EK20kLlMN1R5piJUvQlhAOowPiAvQE9gM4mj70KN8X7L2A/GhiTsPpnKtfc7YA1h8ArSdw4j2FFZoAS+TRRSKQqbCtchtm9J8hZ751EGmEBY2j2JSUv78/3333Hd7e3kiSxOLFi/n4449xdXVlxYoVaLVaUlJSuOOOOygoKFBKhqABwmp+xgCjTSmkhvOXklhVWrPlqP6J8Y6kQ49O0Fs9nxC/fxfH2wUDAHvgn38PVVdDcjKQNxJKgqEkCCqdQbKUIwgsi8AqD2xywCGeomZ89r806iWWHfhKHmVsnGjgFyNoLyg2wqiqquLZZ5+ld+/eDBs2jLlz5xISEsK8efPYunUr3bt3Z+vWrcxTMsmdoD4lJQwETlBTb9sMcOoDBAD/uFPezC0Bfx4CLB35ag6oFVgTNglqYLgG0lwg/XngG2A/jo7QrRsQ9xYkz4LCvlDlAJIa1BVQ5gV5o+VzR9/FwwM48jYndvQEnaZJk13cusCRfvIow1bv5DCCDoZiI4ysrCyysrIAKC4u5sSJE/j5+XHLLbcQHh4OwLfffktUVJRwGsbkxx+xpaaQkRmgUkNQCFSkgdWqXNTj5RIP+lJSDgz6mGHldzN7LPxvq2JSDYgG6IS8bTLgip+B0PMEuN4PG79CTgmZCcTx8MPQpw/M/OwRsEsBi0Y+2KtsoSiEx8d/yAefdGXlf4eD7UjQfg1efzeeVWTPcLnGxqD9sNMcxp4Cc8MoUVJBQUEMGDCA6OhovL29ax1JVlYW3t7eDV4ze/Zs5syZA4CHh4cxZHYMliwhG0gztY4afLVgYw8pm0FbXIH/OUhr7p876E62Lb2bt26HVdFwrvjqlyiLDdAF6Ia80yWAuo7BB9lp/IuDAwQEgJ+/xJEhjyFpurJq8c306wOurn7IcW0yM78/0bR5i4vgepD334cPYqZz+9g5rHpvEJz4L5y5GXq8B3YNzN9le0NSZxi6T3YeAsEVKL7obW9vz5o1a3jqqacoamBStcH018CSJUsICwsjLCyMvLw8pWV2CPoC7N/PQVMLqUGthqAeUJgHGRcBtYou2S3oSKXiie/k3eGv32ZolfpgA0wGFgGxyGWi4oC1wIfAbORq5kXARuCtmmOTOHoUGOVM8SAVJ7xVbLFTk2MZQ+6JRML/a4HbrSpU18qPyKjI5ktTV9NrzAkYPBu6vwclXWD/Usi6vuH2u0eAY7FcoEkguAJFRxgWFhasWbOGH3/8kbVr1wKQnZ2Nj48PWVlZ+Pj4kJOjR0iMwCDMBLCy4kiFKfZ118c3GKzt4MR+qLIC+vrRNS2Dbb2b31dcOny+BeZOkPdmHDHCECouDuBj4B7AFShFzsr1JvIqUTxyRfSCRvvo0wewuGw1yR+oBLIMLFYlQac/wG0fnHwZTr4ERd2g6+d1sz8mdYZsLxi+p9Evc4KOi6IjjGXLlnHixAkWLlxYe2zdunXMmDEDgBkzZvDbb78pKUFQgxXyxxqTJ+tf70JB1BoI7AHnc6Agt+bgsM74ngebFvqziNXydNQnMwwmsxFcgNvo2xdgDvAXcpiXCzABiACWAwdpylnUwwrwAM4CSmXwtcmFfs+B/0rIvA1OvHTFgrhKno7yzmHzaWPmLxa0BRRzGCNHjuS+++5j7NixxMbGEhsby6RJk3jnnXeYMGEC8fHxjB8/nnfeeUcpCYLLuAVwB5g508RKZDp1BmtbSLl8Oj4sGDUQ2MIcUQWl8PJKuKYnTBtmCJUNMRR4FOjOa6+BvLZwN/A38tCgFXSq+al0Wid1tTyyCF4MORPgeATll9dXP9oHihx4f/f7CgsRtDUUm5LatWtXo7lvxo8f3+BxgXLMRF7oDhw3ztRSoLKYwO5wLltev6ilnz9VatDmQrxvy7r+KgoeHgfv3w2/x9ZEURkEa+R1ihDkqabfef31Z3jjDQNlQFQBvsA5QP+tKK0j6CfQlEHiE9x2G8jfH3VQbQHRQ9jsuFku9N6SdSVBu0Ts9O4ABCBPlHwNoGk6Ht8oJHyGlQ2kHL/iuLUFGW6gbUWMg06Cx74Bfzf4762tEXk5jsADQHfk3L4/YfBdLB7IPsnYSWP9f4FuC/n9d4BJ/x4/MBhbC1t5QCUQ1CAcRgfgHuQ/9NemFoI8DcXxd8nPggvn6p9P9gTfgpavYwDsTYRlUfD0ROjld9XmV8EJ2Vm4IjuKva3tsGE6ISf3MkXKdr/feO55HRDGe+9FIkmRSKULmNF/BtZh1mQXZyNJUp1HcmqyCYQKTI1wGB2A6cgFksyhfPbQ64GKc/VHFzWkeMizM0GtjKSetxyKyuCz+1vTix0wAzlHx3dAUutENWXGFeOPLi5jwTtq8NzG88+Dqs9rqK4NR6PWUF5djvdc79rQ3ksPbSNp4gXtG+Ew2jk9gX7AClMLAWzsYPgNgN/NFJ1vuE2mG1SqWzctBZBXBC+tgPBecNeIlvRgAdyJPML4AUUzAPohR0UZOpS2GajVQM+3wfE4nJwHFzvhYechj3g60fjucEGHQjiMds4dyJ9Fq00tBBg2EWztgb6Rjbap0kCGu7zw3VqWboN9SfDB3eBSvz5Uo8jbD25C3hSxBkhvvZhGKCovkheWc2h1kFWr0VRA7/mgqoZjEVRVaCADeW3Fy8TaBGaBcBjtnGnAduTQflNi6wDDJsHxfYDbgCbbJnuATyFwroFFjmagk+ChZeDhCB/dp/91MTEA/YFtwMlWabgaPxz5QR7MmEuFVJts6LkAinuw+X8T4DzyxnV/UwsTmAPCYbRj+gC9MI/pqNG3gJUNbNNjqJPiWTMDsn17q+0eSoW3fpPLvpJx9U2iJeWebNoEcujsjlbbvxqf7/9czhhiLqmDATx2gd9q9v0yDPJulEcZjoAoxtfhEQ6jHTMNqAZ+MbWQkjSGTIDD2yFXj6WATFeo1ABRUQYx/9avsuNg30PYWzfeTpLUnDo7GWtrgN8AhVNjBEJcTpzyBZJaQpcv8e6SBfH/gwxnebpMjDI6PMJhtGOmIU+qGCRbl66KSEmq8wDqHXumoXDLoxEgQZSenqtaA+luwLZthlBOZTXc+wVQWcjUIY2v36blj6SozI8bbgB5HqZpqqqoF26qzyM5uWZNZAi42LgY6A9kYNRV3PTcb6iqfOhvF8WoLqPAE5544QkiIiKAxl977esTtDuMkt5cYHxCkZNrv2uoDtUWRE2t+1EbHhFB1Pz5dY+tqfutvFMwcPpb9m2GwmbsMUjxgM5Hj2IbCBetWir6X+LSgcGf0zn6QcJ7wbYrwnqLy7xIzQvH0zGO3r37sFqPqTMLC1CpIputRZIiwQEIgQdCH2DhhoVXu8Qk+PU8i+T/I4c33gvn+sKkXXy8Zg0kdSUyvPHXLkkNHxe0fcQIo50yDXkWwZTTUSoV3HA/YOPFP2ubd22qJyBJBBoys32XB4hNgTEhdTf0SRLEZ92EhaaMbt5/GtBgEwwENPDI4EeMY6+laL8Du2Q4PB+yfcE3CzTNLIsoaDfo5TBGjKgfyN7QMYH5MA3YgpyayFQMGAP+XYEB71PezBS5ma6AtXWr92NcyR+xkJoHt4ZBgLt87OefoagsgM6em7G0KDWswQao0lXBICARurl3U9xeq1BXylFTFe4Q/RhYVIOPCTeMCEyKXg7jk08+0euYwDwIQ67zZsroKEcXGD8dUk8C2rubfX2VBhg2rNU7vuv1q4Ple+TMtncOB1c7O158ERysz+DtfNiwxhph/an1csRRjFHMtR6nk+D7Oxx6AfK9wD+Tal21qVUJTECTaxjDhg1jxIgReHp68vTTT9ced3JyQmMOSewEDTINqAB+NZF9lQpueQgsrWDdUnj89RZuEw4Px+eff7CuhHJLw+m7WAE/7IT7r4HcoufIyID+gRtQqYxTMOizmM+gEEgwijnD0Hkp5I6B3c/DTc+zPn69qRUJTECTDsPKygoHBwcsLCxwdHSsPX7hwgVuu80ktTAFV0GFvLt7I/JnkikImwBd+8HvX0F+a3YMjhkj18fIgwQ90p0nJ6ej1TYd+xl52aJ8xqk0PnzMkzuG/0KA6zb2n+7SCrF64pHL1uSt8uhCqSJJSmB5QXYasU/B2LdYtHcREG5aTQKj06TD2L59O9u3b+ebb74hLc0INS8FrWYYcjrzl0wlIHcP190F8bGwf2sr+xo2TK6PoafD0Gr9m4xaioiIJGrFv+dPnb2Z8kpfFsxeQoDlRj7aMIl1B8JaKfoqhMVgpbGi4qB5lMltFr5/wJkbYc/T/GMfAT49IKuFhUsEbRK91jCsra353//+x8aNG9m6dWvtQ2B+TEOuv7POBLatbYEdU7iQD2u/NECHtrZkurY+c21DXKxwJaswFF+XA2jvWUl0YjeeueFPnrj+TzQo9GFuVQ6hh7mj9x1y+e+2hkoH3T6CmCexwgGGRZtakcDI6LUPY9WqVXz55ZcsXbqU6mqx2GWuqIHbgT+Rs00YEwtL6DMCqCrl5w/hYrFh+k31gFHxYFUJFQZcx0jNvwa1qpoA951gOYxXV07joXGbmTZ8L4MvXsuXrkM5c97JcAYB+h0B6wrmhs3lB34wbN/Gwvk4OB5Cd+ABCP0ctoyDYserXydoF+g1wqiqquLLL78kJiaGgwcP1j4E5sUo5EzUxo6O0lhAv1Fg7wiMWqVX+g99SfEAtQQBBowPLq1wI7uwP74u+7G2kD2bTlLzxZbrmb9mKj7Whzn41mLCexmySJAEQ2LgjC9D/dp4GbvOi5H2PgkqCYYpVFBKYJbo5TDWr1/PI488go+PD66urrUPgXkxDXmm43cj2tRYQL+R4OACx6KBTtcbtP90d6hWGSbd+SXS8sagVlUT6L6z3rltx/uwOC2Gc8W2bHnpe164cScGySkVlApeuRAT1mit+zaDXSZz7+wCx26HsINgY6wi5AJTo5fDmDFjBs8//zy7d+/mwIEDHDhwgP379yutTdAMNMBtyM7CaNPjugr6jgAnNzge3cqIqEaotIAzBlzHKK1wJ/tCXzq57sPKouF8UXkVIQz57yxW7+vFgju3svbpFTjZtvJDcUgMlNrC0T6t68dMeO01YOczYF0GYftMLUdgJPRaw+jcubPSOgStZAxyjRtjTUep1UDqcpw95BoXeYao56DTEVmT2O4SkRER4LwFvt9D5AvzuFBewocffdRiE+n5I+S1C7fdTbYrLrNm+idT2R3vz/t3bWb/m0uYuugOjqZ7A/D0U08BcuRVU1woLGDhstch5ATsGQZVBlyIMSEeHkB2EcTfAMO2w97hUNk+XpugcfRyGPfee2+Dx7///nuDihG0nGnIC93GyISkUkHv4UBJMidjIDfDQB2r1XWSGYaviSRq/nzcsqBfFRx67v8I/SyiiQ6apqgIsi/0x9c5ttHRRV1UfLxxGPuTO7Hy8dXsnb+UWUtv5ufdfXFydgGoE6bbEOHTImHQAXm+f7/CIbtGJxp2PA0z/4SBByG6ja/NCK6KXg4jLOzfN7qNjQ3jxo3j4MGDwmGYCRbAVORQWmPMJvcYBO4+QKcbyU5XfsWk0F1eRXBp5bRUdLRc88LfbU+zrtsdH8jAV+aw4vHV/DT3F1zs9L/LVZTDoIOQ0A3Ot7d1vwpI10HqaBgRDfsHy7npBe0WvRzGE088Uee5s7Mzy5cvV0SQoPmMA9wxznRUcG/wCYLkYxDcZxDGWGKvtoQil9Y6DGv27wdPxxPYWjU/5CrnggPXL7iHlU+s5vMH/mRDzkLg6ateF8fP4FgMv7bXb98xsOMpuGeqHDYc23T5XUHbpkXpzUtKSggODm6yzbJly8jOzubo0aO1xyIiIsjIyCA2NpbY2FgmTZrUEvOCK5gGFCCnA1ESdx8I6glnk2uSChqRQk9wOgeUtzS19kDKyyHAbVeLNVRUWXDbR7ezKroXE72egdPfNdleQmIPH0K2FyS113XASki0gbMDYPReUIt9Wu0ZvUYY69atQ6qpsKbRaAgJCWHlypVNXvPNN9/w6aef8t13df+pFi5cyAcffNBCuYIrsQKmICcaVDTZREkaPQdDUQEkHFLSUMMUeEBAAnC0JQsmGmA4wcHgaN261fmqag33fD6FQX186Rz9IEO6TGdfUtcG2573OU2O6ijsuYXG6/y1Bw7CthfhrunQ3zgZfwWmQS+H8f7779f+XlVVRWpqKpmZTe/O2rFjB0FBQa1TJ7gqEwAXoGn3bQD2zECllsNndSZImndpHUO1P7UFV/cEnBg+HDINsN+0osqCFWd/4aWwMfz31tU8tHQOmefd6rXL6LkbB8mH4nYSSts4VRBvDxlDYMweKqrbYJ4sgV7oNSW1fft2Tp48iaOjI66urlRUtPwN8dhjj3H48GGWLVuGi4tLo+1mz55NTEwMMTExeHh4tNhee2cacpGkxadO6VVPuiV4BwA5USQdMVzKj+ZSZQXFzsCBljiMIcA5ujY8EGgR5TonGL0WnaRi/m0rsbKorHO+2Dmb8z6nGcLjUN0RKiHHwrYXwCWPpQeXmVqMQCH0chi33347+/bt4/bbb+eOO+4gOjqaqVOnNtvYF198QZcuXQgNDeXs2bNNTk0tWbKEsLAwwsLCyMtTIPtcO8AauAW5DKt/9+5EqlRXfTQXC0vo0g9wH8LZFMPqby6FHsCRdDTNGuH4AEFADAbfYO2g5c21t9LZO5vHr99Q51RGzz2oqywZzMMGNmquVEOSBaSNJGLLW3rOXQjaGno5jFdeeYWwsDDuv/9+ZsyYwZAhQ3jttdeabSwnJwedTockSSxZsoQhQ4Y0uw/Bv0wCnFA2OiooBCytgbDPFbSiHwUeQFkVnc4356ow5OrmsYpo2pfUjeV7RnDTwIOEdU4EoNymiJzAo/icDsWW+lNV7Zcj8Pc88ioy5RK0gnaHXg5DrVaTm/tvMp/8/HzU6uYHWPn4+NT+PmXKFOLi4prdh+BfpgE5wDaF+reyAb/OkJUCuJn+E6CwZmZS/7xStkA/4AhK7lD5JupaknM9ef7G9dhbl5HRYw+SSsI/fphiNs2TakixgORrYbQliI3f7Q69Bo4bNmxgw4YN/PzzzwBMmzaNP/9sek/xTz/9RHh4OB4eHqSnpxMREUF4eDihoaFIkkRKSgoPPfRQ619BB8UOuAn4DlAqkDGgu7yrO/UUmEOZnEproJsXwbk57OipzxWhyJ9ayuY6qqi2YMG6W/jsgWVMH/8XG2xP4JXWF9vijjS6uMQBnPa/xYXbR8BwYLup9QgMSZMOo0uXLnh7e/PCCy8wZcoURo0aBcCePXv48ccfm+z4rrvuqnfsq6++aoVUweXcANijYHRUVQmdgiE7Hcr0yaJhLIZ1JvDHHCyr5MSEjaNCno5KBbIVl3XyjB+/7BvCsS7R6M5D0LHRits0Typ5fvpwXjt6K4z8FQ7owJzeP4JW0eS80qJFi7hw4QIAa9eu5dlnn+XZZ59l7dq1LFq0yBj6BI0wDTiLgl/g8vag1hh/g95VGdEVC50+2Wu7Am4oPbq4nCV7h/JZIUzU2GFX5G40u+bG3LnA1lfAQiXKfrczmvyO5u3t3eA6Q1xcHFqtVilNgitIT07G//L7XVQEXl4waxbVn3xicHtqNXD+IHmZpgujbZSBgVSqoWs2JPo01XAIcjrGFng8SXfVLLQNcUobS7EE7weU0vuvnqC9E4DIyPp9XR7iHBHR8oSK5oirK5C/CQ48BIM/h2hABDq2C5p0GE3tk7C1tTW0FkEj+Gu1dUJi+yInG/zq009J+/RTACJbuMeiITz8gOqLZJ42WJeGw8aSVA/oktNUIzegG3I4QAtWeFRq/bLQXkaVZRmZ3fbhmR5C7yHWpG1+kLGbv8C/11j++SeqTtuIiHDmz5ePSduian+/GhER4Xq1Mw8WQlQM9P8KxpUZvwykQBGanJLav38/s2bNqnd85syZHDhwQDFRgqbpDVwA0hXqv1NnwMqNAgNWuTMkSd7gWQROjVaKCkN2FMZ7j2Z0j6baqpzAY9dAvzcJtC/j9qAso9k3P3Kg9DfY+TKEAIGm1iMwBE2OMJ566inWrl3L3XffXesgBg8ejJWVFVOmTDGKQEFdbJBn52MwSOHQetg5gosHNWG0mxWw0HoSveH6o/K01MF6OTAtgQHAccA482mVVqVk9NiDe0ZPHAp8oNMNHMh34vEeaRzIbGmyxPbA+7D3KAz+ACYWwhKUedMKjEaTI4ycnBxGjhzJ/PnzSUlJISUlhfnz5zNixAiys5WPPBHUpweyl1dqB0unzqCrBlxCFbLQenId4YJNY9NS/ZDdqvEWu1N7b6faooLgI2PlAyoV7x/X0smunBudO/JIPA0qf4fNH0InZD8uaNPotQ8jKiqKqKgohaUI9KE3cirzplM/tgyVCrz85drcnv3tFLBgIFTyKCPkjFzI7hLyMs4QIAvlJuzqctH+PGe6xuCbPAD7C561x/fkubI315nprrt5Tt2fSl2LKgm0A96DuIMQ9l8YlykP/IxR5UugCB31XdwmsQW6AMcU6t/FU97dnW2cz9pWkeQNtpXgd1makB07ALwx5ugiud/fqCQNQUfD6537Ij4QL8sL3NX0Cn075xCwFf5aJu82HWNiOYJWIVKEtSFCkCs7KDUd5eUPVZVwrg2s1Z72lKfDu2YBuiokSWLaNLCxgWeeuRlLy5sV1xCTGUNuUByBx0ZjXeZY7/w/Oa4klnkzf3g+qZ2mIV1WE2PMmPA6v5eXl7F3717FNRuKKl0VkhTZ6PnLw4bXra/glputCHecw86RX3Hk+yOEeIY0eF1KWgrBQU0XZxOYDuEw2hB9kMPZzyrQt0oNnn6Qd8Y09S6ay0VryHCD7lmA2oJnbvDjl82Z+DjtZtcvmxq85spQ2NYgIfHClhewLLMj4MTIRlqp+On8SP7r+wvdzq1h09maZFjh4aQci6ptlXIsCm3vcINpMwYWagtU14Y3eE4OG55f+1z3twT2R4h65y54aDG93uwlp/dqAGmbWBU3Z8SUVBvBAQhGudGFmzdYWEFOG5iOusTJTtCpAEhP50DyHKqroZNLjFFsx7OeqJQogo5dg0WVdaPt/inqTXqJDQ92aUmlwPaBSgUEvA95Y+BYT3mbTMfdCN+mEQ6jjdAbOTuSktNRleVwvg1Nt5+syYhYsWY9B5If4oYbwNaqWbnPW0S1ppINPElvz974Jg5uui1qvk/uxDDPQno6mdu2eSPitRysMmD7R3Juqa6IT582iPiTtRH6IMf+KJFhQaUCNx/IO3sp0qhtkO8oh9iuWVZASbkPjz1mHLvpITspUKXw6Q2fopY0V22/IsWHsmo193VuXT3xNo26EvwXwbnr4EhXOYIjwNSiBM1FOIy2QHIyAcBRhbp39gBLKzmctq1x0hc+jQvH3S6B665T3t5Fh3Okheyij3Qn4dpwva4prLTk13QvJgdk42RZefUL2iudloDmAsS+LicQDkLeMiNoMwiH0RZYISfiUSqc1qMTVFfDuTa4F3OT4wB2M4Ib3T6nBTW9mk3igI2odRqu4/1mXffdaT/sLHQdO12IxQXo9D/IuR2O+YEOOeWXoM0goqTaAsuXk468Yc/gSBLuvvLahU6pSkwK8kfeXOxUpTxc+Q2wUO/rft76BL6d/i1wFHUism6DyzLMnj1zjjvHfUx+p3jO+cXTOXYCjqGdmqXzeKED+/KcuC/4DN9IbSAMrRXodPUz8F56fiFXw0d3qhjssRrXHpFsTNrIHY/eQYhnCAUFF0whV9AMhMMwc3oCHD6s2GI3hXHY2kOaudW90IPScneOpt/FA70PMfh4ARQU6H2tbyc3tLeHA3D/3HC++Syq9py29xVhr6uiqLaoIGHQn9gVeuAXP1Qu5tdMvj3tx2dDTtCtPLH5F7ch1GrqZOCNDK/7HI9e7Pt1DORoYJg9Kw/+BjFniHh1nLGlCpqJmJIyc+4EUKsVm44iYx3QNtcvDqTMpkpnyxMvO2ChA379VTFbyX23Um5XSPd9N+u10N0QG894kH3RikElHTm/FBCwAnS2kDkZ4ruBTTkEpZhalUAPhMMwc6YDhIcrl3f17AaKzkNFuVIGlKFaZ8H+048S7LmFPtP7cM4eqKk5b2j2Zuwls/s+OiWE4Zzf8tCeKknNqjQfupUn4G3Txm64IXFIBrdoyJgK5z3hrA/4Z5JT0oZiujsowmGYMQOB7gB33qlI/1Y2QN7eNrnYffLMZC5cDGBol49BpSLOH9i6FZcqwxaQllQ6Zq2bhfVFJ4KPtH7KZGWqD2okbgvswIvfII8yKt0gewKc7gzVGv5M+LNOShGB+SEchhkzHagAuPVWRfrXhgBSVZvarHeJ6KQncbE7TTffPwBkh1FdzbVFhp28K/RI41juMbrt/0+TO7r1Ja3EltNWwUzTZqHqyMUhXA6CQzykT4MKKzjdmdTCVH448oOplQmaQDgMM0WF7DA2Abi5Nd24hXTuDWhsuJCvSPeKceb8QNLzRzGkyyeoVXLEUY4zEBrKxIJDBrNTYV1CoWca0/tMx/1Md4P1e9BuAIH2ZYzwLDBYn20OFRCwHC4GQv5wOOuDv6M/z21+TuzNMGNElJSZMgZ5I+zzwI0K2ejcF/C8Bp2u4WR95sq+pMex1BQzIOjruidmzqTH44/TtewsiTa+rbIhIXHOLx61TsMH131Ap6kNh9HWC8fVg5O2IZzPsWC6tg1GGhgSz3/gdBakTweP3dzQ7QaWxi6FccAfphYnaAjhMMyU+4BC4DeF+nd0kfNH4TOemnFMmyA73564jDsZqF2CjVVh3ZN3303FE0/xn4JYPvJpncMocjtDud0F3DN60MmxU20I7iW0vcMJD6dOOO4lUlbVP3Y5VSoL1qZ5c3fwGShTItlLG0FdLa9lJD4JBX3xdXTnsbDH+Fj3MRwGOm6+RrNFTEmZIbbAbcBqlCtO1rlPzS++ExSyoAyLVw+iWmfNkC6f1D/p6so/jr2YcOEIVrqWp+Aoo5AC72RsilyxL/BuhdrGWZHqg7VGgpTvFem/zeD7J1gWQLoc2PHm2DfhAnAT4tPJDBF/EjNkMuAIfKegjc59oKQQcOmnoBXDUqmz5ItVYXT1/gsPx/gG2/zhPAAHXTljio63yIaERAJ/gkrC7Uw3VJcVPTIkpy44EHvOEZKWQkde/NaUg98ayB9BTrIXjtaO8Cdy4cQRphYnuBLFHMayZcvIzs7m6NF/U+a5urqyadMm4uPj2bRpEy4uLkqZb9PcC6QCOxS00bkPnD6GXDmpjbAl7W7O5joytOuiRtscttOSZuXOlPMtq4tR6pTHOVU8LtlaLCttW6hUP35O8YXC4wx06+ApMfx+BfVFdv1cU4jqFHLitHDk2hkCs0GxT4tvvvmGiRMn1jk2b948tm7dSvfu3dm6dSvz5s1TynybxQe4Dvge5b53evqBoyucVizfiOHRSSpWJDxP/x5ZdPFqfM1FUqn4xXUIvcoy6XWxeZPg1epKzvkm4CD54pjv31rJV+X3DC+wcGC6toPvybAsgk7rObq1L6mpNcf+AqpQLuJD0CIUcxg7duzg3LlzdY7dcsstfPvttwB8++23TJ48WSnzbZY7ket2Kzmz3aWv/LMtOYy9Wf8htagXL9y/S67g1gQbnUMpVlsz9Vx0s2wU+CSjs6ikOzcpNhV1OaXVGgiazo1+OdipO/DObwD/VajUEh98UPO8GNgMdKZFebsEymDUKClvb2+ysuRvU1lZWXh7N76gOHv2bObMmQOAh4eHUfSZA/cB0UDDM/Stp6oKJr74HyiK5+k82Ur4mobHMuFrIgEoyTZuuErY5+nYe/vXaJC1vToKgoLgjuemYmFRX2/kZa/hotqK2JD/EH7iNw4N7k2Rg2ftufDw8NrftVotVVVVAJTZFVDsdhanXH8cPXzJ55QSL60+XWZhl7SUax3j+Ms4Fs0Tm1z6jT/C0qUDkOu35sNBoB/ykDsBuVKfwKSYNKy2qTQAS5YsYcmSJQDExBinTrOp6Yv8ZUrJwnEWqgount7Ehh39+ejmSMIjIklZEVmvnTY8nJSoKAC+acFeg9Zg7+3P/SGRaKfJ2nJKA9iVNpMhXn/y5uN2RNXoukT4tEiiVkTW2RNxoP9tjDy2ll5/LmSFl1xZSTvt39cE4RSkpOCi1VKlqyLfLx6LChucc7RgzO8n7kM4dcGO/zjF8gJdjWjY/BgxfReHNgwAHgci5TnZ9cAjwPXALyYUJwCMHCWVnZ2Nj48PAD4+PuTktMGcFApyL1AJLFfSSH40tjaVHIjrrKQVgxJ3biTW6lK6usTqfU2Bky97nfpw7fn9OFSVNtl2R+oOqqwv4namW4sz0bYYlYoVKb70ss2kr1sHrvkNeAblccstIDsMe/lgHnL0Rz/o4P7ULDCqw1i3bh0zZswAYMaMGfz2m1Lb0toeFsA9yBGFimbqyNpMtU7FoePBSloxGPllPqQX96SnWzSW6ubtrfjdfTRWUiXXnd/baJuLqgvsSt+FfYEXtsWmCclZm+5NhU7DzB4dfPEbkONg3IBZ/x7cAeQi781ofTovQStQzGH89NNP7Nmzhx49epCens6DDz7IO++8w4QJE4iPj2f8+PG88847Splvc9wA+AJLlTaUtYWTSX4Ul7aNhD2H88KxVJfRy7V5C9gAZ6w9OeDYi/Hn92FX3fAWyNPWB1Cr1LhkmW7Edb7Ckp3FPbm3azbWmvZdje9qDBsGEAU8C1jKB6uBX5E3J11vElmCGhRbw7jrrrsaPD5+/HilTLZpZgNnQNGFT2tbIH8fB+Laxo6os2chvbgnoR7bsNK0bM/7OvfRhBUdZ/z5aI5cca7YvoA8izSuDbyW00dM+0H9x4WBjPU/xuSgPFac9jKpFtPzDrABmEHtV6hMYBcwGjiBvAguMDptZ9dWO8YPmAR8jfxlSim0vQCpmv1xXRS0Yjj++Qes1BcJcW18SulqpNv4EOvQnevORWNVXlR7vFpXzRmfJKx19gz3H24Iua3iYGkwyUU2zOrZwRMSArAROVbwFWpHGSAPPHKQp6baxgC53SEchhlwP/Lei2UK2+nSB7Cw53iCgpvSdFVESlKdB1Dv+dXIL/Pl1Cno5bYHK03r9iisc78GB91FhkV/VHvs28PfctG2mM4Vg7DUWDZxtXGQUPHVKR/G+xUQ7HjR1HJMRpWuCkmS+PPPoYCWxYsrkCRJflRJ7H9lPxpnDff+dC+SJJGcmmxqyR0K4TBMjAqYCWwBlH7rd+4DeI2hqlrBSCC1BVFTVXUeHIms+1wPYnPHYmMDIS1Yu7iSZFs/Djj0ZOSud3GsKqHSopyXt76MXakTnlXaVvdvKL6J96ZaBw924MVvC7UFqmtV3LBABY57mfN4KqoxVqiuVaG6VsXguwdTnVzN90e+R3WHCm2g1tSSOxTCYZiYcUAwsERhO05u4NGJmnTm5s2mTZBZ0o3Ro2n16OISqz3HYllZwo35OzjaayfZJdn4ne1ilB3d+pJRYsOGDDce6J6FRtWBExKC/E1KGwnlQZB1f91zqcgZbXtAakFqvUsFyiEchomZgxxG+6vCdmrTmfuYdzrzaknNc8+Bg+U5hgwxXL9nrT05FPoAnaUYjvfYwz397sHuopPhDBiIpad88bOvYFJAGyuDqARuG8FxL6S+ArrLpg0loCYZ8d2/3C0+xYyIuNUmxA+YAnxFTe1uBencB4rOA869FbbUOjakPMDRozDIcwsWBo7hiwqP5OXxEhY6HW+Pe9uwnRuI31PdOFNixdxeZ0wtxfSogOCImlHGA3XPlQEJsCt9lxw5JTAKwmGYkIeR/yc+U9iOSnV5OnPzmYK5kqISK5Ydf5MRIyDIsWX1LJoizimF1X0k5u2U8D9tnpXuqiQ1X57wZWLAebo5N71DvUPgugmc9tSMMqzqnsuGe/rdI9czDjSJug6HcBgmwhp4CDlVjtKzsF7+4OBs/tlp31g8hvPlPnzwgeH9moTEBp7CvsSRR/bawFNPgZ4RW8Zm8clOVFSrxCgDatYyIqA8EM7Oqnf6sxs+gwLgdsDByNo6IKKmt4mYBngCDRQaNTid20A68/jzA/jwt+HcELSUYcNm8WVjDSWpTsbZS4SHh1Olq6qTgFCuwCPz7aFv+e63A3x/z/d4BxfBo48yblgvDgSbX4qU7ItWrEr25IHuWby6X0txZQf/N3XdDM7/QMp/wfs7sPg355aTtROsQM4kchtymcqOvVleUTr4O9F0PIFcVOxvI9jq3AdyM2vWMMyQap2G9w8uxdO1hIf7Pk+dPEJXolJdlnFW5lIWWgt1OKG3hwPgotVSkJIi96+u5mS3fTha+PHeG0tYqIMDffrwzJFEHhg2UJHX1Fo+OebH3V1zuLdrNl+c8DO1HNOiArq8AAejIf1ZCJ5f93w28lD9VmA80Hh9LUErEVNSJmA4MAjjjC40FqDtCUlHr97WVKxKfJqEwoF8+tKfOFoVGLz/XI80qiwr6ML1qFBRrVbBokX4lZZx2wHDr5UYgugcR2JyHXms9xk6dM3vSzjtA89VkP4clDdQR+cIsA+5DngvI2vrQAiHYQKeQp52VbKq3iUCuoGltflOR6UVdefr468zynctt447YfD+KyzLyPHIwKXAC2cC/j0xbhx/d3Ln3r1HcMgvarwDk6Hi02Od6OVayng/Mx0aGpvgl0GyhtTXGj6/EUgHJgON12YTtALhMIxMN+Sp1s8BY8TAdOkL1VWQetIIxppJWZUt86NXYWNRwpOhcxUJ4DrrLe+f982uv1bxYb8uaHQ6xi01xsRg81lx2ouzpVa80C/d1FLMA7tE8F0MZ+dAaff656uR1zPKgLsQi+AKIByGkXkRKAcWGclel36QkQjlZpie6KPDn5J8oQ+vDL4HD1vDJ90rsS2kwCUHzzx/rCrrZ6vLcLBl9cBeDNhwiAH5Fwxuv7WUV6tZeNSPCf4FDPQwx1GQCdDOB3UpJC5qeKauGPgJsAXuRKzSGhhxO42IP3JVvcXI9WDSk5Px12pb1NcTyem4aesmEayX2K8sB37xhn5vEvn6Ky2yoxR/pdzPhtQHubfHGwzx2Wjw/iUkzvgmYVFphVde40H63w/vx43Jqbx1MJ6bxg2S1zfMiC9PdOLl0DRe7J9Oc1ZbhsmFJRgzJrzOz8spLy9j796WZwI2CVa5cpht0iLI/0/DbbKQy7lOQ94ZuxqQIDk1We/cUylpKQQHmV8EnakRDsOIPIsc8PFezXN/rZZIPeZhGsrw6qb1J1wVWfs8PCKSqPmRddqMG3GU1+bCQzencipZPhcl1W1jCvbuhUWHPmeA59/M6KWMnhyLZEptigjI6IFG13iyxYtWlvz12ESmRa7ivqRMvu6mYCbfFlBUacHnxzsxLzSdz6r0TxdibS2PqFKORUF4uPzzCrS9ww0j0tj4fSZPSyUuoryxVGMngc3AdchlXreBNlCL6lr9vhBI20SgQUOIKSkj4Y5cJOknIM1INsP6JlFYZEt8iq+RLF6d9KJu3HQTeNie4bWw6WhUhg+a16mqSbY6gO1FB1wLrr76eeKaEKK8XXnmWApeFw2T7NCQfHTMn7JqNdcUbTe1FPNAXQVdn4Syrixc2ES73cBB5J3g/Ywjrb0jHIaReBq5rP0Co1mUCOubxP6jXZAk85hmySzuwjM75AXmBSMn4mqTq4idHI90ytWldNI3G61KxX8HdMNSJ/Hfw0mKaGoNORet+OSYH/0uHoFC8wwDNjpuW8BjLW++CU3mBfkDuW7ALbApSWzQaC3CYRgBL+RQ2hXI1SWNQZfAbNxdi4k5ah7V9RIL+vPk9u1U6qz5+2/wd0hUxE6FRTm5nul4VgbhUOqi93VpDrZ81jOQGzNyGZxkfk7j3cMBVKis4Mh/TS3FfOj6ZM0vXzTephpYDuTC1JVTReRUKxEOwwi8ipw76lUj2gzrJ3/oxRwxvcP49e+ePLl9O2pVNQuvCadvX+VsZXknIyERXDGo2df+r0cApx1sefqPP7CpUrJYbvM5V27JHvvhkL6GQSJiSsYmnf/7P4AbkEOiGqEc+BHcbN3kqSlR3rXFCIehMMHISQaXAsp8p26YsL5JJKV5kV/gaESrdblYZccnhxcx5enp+DvE89mY4QQ7KTelsi9zH+dds/HM98dWav7rrtCoeWVgN/zOn+fp4ymGF9hK9jgMBxsvFg1PROz+lpk7F2Av8BHySmEjFMGGuzfIUSf9qFMqXKA/IkpKAeqEy957L6xezcNJSTzcqZNR7NtYV9C3Rxq/bDRgBaJmoJNUbMuYxtJj/0dWaTCP3xnNjaXXYKVRruqHhMSTG57EotISr9xA/dNd10SgaWv+Xme1WtaVWDLr4EEOhfXjhK+nMoLrC2kw9PVyytVA//9jVNkspnfJZXmSl1GUGQtdTfxDRESE3tdIqiqOHBnGwIEwfXoe318tfcJRoD/QFziESFTYTITDUIBL4bLeyDUvdgFb/OonkGsoXNYQhIakYGVZbfT1i7yLvixaBB9sPklGcXe6Osfy0TWjeWLeOKLmK1siKin4MHsz9hKQ3QONrhlv65qw5kuJCgG+nDCBsONxPLcuijvHN39qq2WoGgx9rUN4OATfz4Hfn+LdIadZl+pOaZWC9dmNjLpmvmP+/Ci9r4ncFsma/Eiq/FT88EMEPxy8HbxWN9hW2ibJpV1PAL2Rc04dQwzWmoFwGApyPXKWgp1GtjssNIGLZZYcPRWk9zWV1VaUV9tRobOmSmeFJsuJ3It+qFU6jhwBjQZSL/REJ2nQoaak0pm8zb34J/Fx4gsGceLcMNKLe8BfEOJ6jteGTCPcbxVqlYRcuVw5yijkQP8tDPcfTklc6+caSq2teX1Qd77YeZSHzG1qSq3hiT1d2XXzId4YnMyze7uaWpF5EPQmnJsE8f8D591g3UQtkTwgAehe8zhlHIntAeEwFKIX0Bk5qq/MqJYlRgyMJ+ZoFyoaqaNQjRUFBHGeLqR8AzkZz3Kx+oo5/zQAOfX37/0vHbwixms7wB24WmfTy20Pk4K+4unVC8h6ZbjBXo0+RBFJmXUJn97wKQ9ueMYgfe7xcWOt1of7T6XDTmO7/KbZne3MZ8c68VSfTFad9mRvjrOpJZkedRWE3AP7Y+HkN9DvelA1MXQ4gxyJEoS8KJ5iDJFtH5M4jOTkZIqKiqiurqaqqoqwsDBTyFCOkhKuB84C+41sumtQFl7uF/hqdXid4xIqztGVm2+GXbyIhAY1lXSqBj+HRJys8rHRFGOlKcdCVYF3/35kHY5DJ6l57OM7qaqCuA+moVFVo0KHveUFrnvqVhK/isTFOrc2cWDPngvIMuLrPe+cwz4W0z1pEAN9DVvb4r3+XRicW0DA3XfjFOrPBSvzWSmdFxPMjYH5fHVNPAPWDqK8WsSvYJcAXZ+G+MWQ8TQEfNh0+2TACtAClUCm4grbPCYbYVx77bXk5+uf6qBN8fbbOFObwsaojBx0Cp0O9h6Ss3nq0HCWgaQzknJcyN0HfkTjRiLOpDF25qukrPitXj/agAAskhIAuPVW+ZjXipV12vTtNop8hTbf6YOExL6Bf2GDMwOOjDV4/6WWFrw0NIQfth/l/3QXeWxoiNnURC+utGDWju5svuEoHw5LYu6ubqaWZB74LpGnpk6/A47R4LKr6fbxyJ+C3ZCdRo7yEtsy4muJgekC8N57HEZOzW9sRgyI53iiP+cv2JNDb2KYSyL/wZoL9GIlaWnQhU24cho1VSZQaDiSgg+T5Z3CWN7CpsJOERtxbk7wxhvcmJHLHSnGHDtdnS2Zbrx32J9He53htmDTOW6zQgX0vB9sUuD4yoaLLV2OhDzTeh7oCbgprK+NYxKHIUkSmzZtYv/+/cyePbvBNrNnzyYmJoaYmBg8PDyMrLBlqJAz0WJjw2YT2PdwvUCPzmdZt3MMR7iXE9yOhkr68COhfIUnx7GyMoEwBbhoU0xM6Ea8cgMZxBxljT3/PLs8XXg9NpHe581r09zLMcHsyXZk6TWn6O5sjAorbQCLC9B7KlS5wPEVcLWoOR0QB5QgR085Ka6wzWIShzFq1CgGDRrEpEmTmDt3LqNHj67XZsmSJYSFhREWFkZeXp4JVDaf2cBYgA8+oPgqbZVg+IBTfLLxMSL+XkYR/nTjdwbxJe4k6JNRqU0RPfAvqiwqGbHvJlRKv401Gp4YGsI5a0v+t+cYbuXKhgg3hypJzfS/e1FWpeaP64/ibl1paknmgcNR6D4HCsc0XjvjcqqRy7yWA33hWM4xxSW2RUziMM6ckUPecnNzWbt2LUOGmGaDmSEJQE5bvgVg5kyj2y8thd/SnuGJ7z7BUUpjMJ/Tif2o2mGQeUrAMVIDjxMaF45zkXFGn/k2Vjw0vDeeZRV8uvcEmmrzSR2SVmzDLZv74G9fzq/XxWGlFrvRAPD5EQLegzNzIePJq7evRHYaOrjuh+vARWF9bRCjOww7OzscHBxqf7/uuuuIizPTgtPNYDHyzZwNRl8YLSSAxf+rJjplFHf3X0RffsSGQqNqMBaF6mx2h63HI9+P3ieNG7571M2RlwZ1Z0RuAXM3bqzdJW4OROc4cd8/PRnlc4Gvxpxql18UWkTnF8FjNSR9yG/1YzvqUwYcgdLKUrnamb3C+toYRncY3t7e7Ny5k0OHDrFv3z7++OMPNm40fMU1YzILmAjMw/jh3GcZyGHux86ymN2RI7DIi29300+X0Kl0/OLyf0gqidF7bkUtGX+X8y9BPizu5s+tMTGMWLnH6PabYtVpL16O0XJ31xwe89xgVg7NZKgkCLkPHGO4806gUI8vGSXw+52/y2sZdyPv1xAAJgirTU5OJjQ01NhmFaM7cn3uLcDnRrRbVQWJTCSTYbiSyIb/PoVjWTopmTcZUYVxOdJ7O2lWRxi1dzJOxaYLZ3m7X2e6Wjlz3ZebuXlIT9YFXr1Ik7F4+1Ag7tZVPNtvHxx6AZH3AtBchL4345+bTcKRPyF0LDjGNnnJyMCRsBKYjuw0fgDMZ+nKZIiw2lZgiVxBrwyYgfH+NS/iwg03QCbD8GMP1zj/j77ufxIV3ctICoxPmt9JDvf5h34XJ9A5xbTl0ySVircnTyY5VMv7MacYmX3epHrqouK56M6sLRgMJ97n6ZAUUwsyD6xy2LIFsCiEIxuhJOTq1yQAawB/ZKfRTiIMW4NIDdJM6mSifeEFeO89WLuWzMmTjWI/jx78zDqKoqA7v+FLLOOHH0Wlkti2t7dRNBib88457Bi2Fvf8TtxY+SyZGH8q6FI220tUWliw/I1p3P7gYpbtOca8W8ezv5MHGRkZRtdWHxUf59zAlEH9eZJlbC3azjemlmQGBAYC/cfDoe3YJ+5hxoc/4KltfP+KVDOltyJuBXf9chej/zeaz0cupnf3Hq3SkZyajDZQq3f7lLQUgoOCW2XTUAiH0UwuZaLtgrwmth/4fcqUOm2UykKbyPWsZjkWlLNtG7wyKhaQmDQmlsyyMNLOGCsVt/Eosb3A36N/xrLKimt3TsNyqGkmlC/PZgvg0ltLuYMNs4f2ZOn2w7y9ZjMv3jYBc3AXIKeCIex//LJtPbcGbmNOt84sTggwtSzTY5cI/cehSorm8zl3Q7/nwLF+pZrIcFCpIv890Gcy/9y6lkeZI69ptKL0uzZQi+pa/VcapW3mM60opqRagDMwFcgGjLFcL0mwlyf5iT9wIYVZDGHkSPlcd+1ZugTmEFv4oBGUGJcSctkc/j1l1qWM3TEd+4vmt6PqvI0Vs6/pzxk7Gxb8spWw3AJTS/oXtYbnD/bkqG0fXu5zmlldTZF7wAyxP8H9H30N6nI4vBAK9ZjKjesLv9zKrvRdcD8dNnpKOIzmUl7OHcg3bgVy6LaSVGPJnDmwkUX04DceZBQucipZACaFx1JeYUFc0XSFlRiXMqtSfuB6iu0LGLf9TjzO1a8nYi6cs7Fizpj+5Dja883Oo7B9u6kl1VItqVjrMoXfMzx5te9pZnYxlzGQaXH3PwcDnpB3hR/+APJGXP2iuD6sv3O9XNhvJuCqtErzQziM5vL00/gBvwLnFDZVggffsYWlS2E0b3AHt2FFSe15K8sqxo+IY3tMCGU6F4XVGI/T50/z1/ivyOME1+6chk+u1tSSrkq+jRVP33EdZ+1s4Prrufas+STW1KnUPLW/J39mevBavyTu7yycBgA22TDwMbBPhbg3IGPKVS+Z2HUifIdcF/xBwHy/xyiCcBjNYBbAF1+wCzipsK1s+rCUfZwhjJ9+grH8t95mrGvCjuNoX8aGf0IVVmM84uxg+LLhlFuXci9b8MtqOwWCzjnYcUd4f+jVi8W7j3FzWrapJdVSJal5IiaEDWc8iOyfxL3BIpc3AFbnIfQpcN8DiU9CwuOgu8r+ngzga6AKeAC55GsHQTgMPQmnZp/FxIlsVdjWUe5kGXuowpr7uUbecHQlksTtk/aSmunBwePmEUHRGqqBt05t58ku4GDlwKQtDxLISFPLajbnrK1g2zYOuDuxaN9JJu/bZ2pJtVRJah7fF8KmM+68EZrIzc7GrtZipmjKoM9/wX8FZE6FQ4s4e/Yq1+QCS5ALjU0BbkSOs2/niCgpPeiKHI6dAPRavhydi0u9Nk8kp+Om9a99rm+k1BPJ6XwcLEevVGLDBhZxkIcIZAdTmY4TjZSazN1Jj85n+WDZf5Ck+hEXw596Cmvn+joBwiMi9dKmL2FfJmPvqf23/zX1X3v4GtlmSW5KvXMJNvCRHxw7vo2xBfDLvIM8+cVCg2o0CpIkh986OfHfu2/kv79v56m//sJtWD++GhlqsJQxY8aEt/jaSknN3H29+HzocZ7x/YOTPbux5GQng+gyFTodRERE6NW20XYqHXT9ApxOwskXGDhQYvv2SBrIi1obbgtQpavila2v8C7vytX71oBRK4gZGeEwroIbsB45A/JNQJJzw+Uw3bT+hNeE4YVHRBI1P/KqfYdHRBIZKTuZfLqyilVkE8pI3mYsr6GmiQR3Jz+ksMiWTTsbHg9bO7uQsqIBDZGRdY5rp11d59Ww99Ry/6Pyh6H2jghSVs6vc147Zgwp//wDwDef//vPlmUJP3rBH27gXA3fDZqM/9e/4mzTRkuOqlS14bc5mRk82T+Y1x3duW/vITwys4gc3IMKjRq5xFvLSTkWddU22t7hjZ675DS+HZfF4tEJ6Br4wtGWUKth/vyoq7aLDP+3XUREeMONvLaBfTJOhd9wzTXV0OV/4L+qttxrREQ48+fPr3fZ5mWbmfD5BJgD7Ab+QfmIGBMgpqSawB74E/nfewpwWgEbkgQHeZDFHOQCAdzFDYzn5SadhZs3kPEb67YOpryibY2DJUniwJkDLPCHe3rCBleYkg/fn4R7A/u3qzxY1WoV7918Mx/3CeaG9By+3H4Yl3Lz+BSp0KmJOHsHf6W7snh0PCR9bWpJ5oN9CjExgMdOSHoUDn8IZU2nfxnfebw8Z30IGAU8CvSDdvWGRjiMRrECfgEGA9OAnQrYuHAB/vMfWM8yfDnAQ4TSjb+uet2YKYDGmrWb204t9AsaOGYHAxcPZPCSwWxzgcl58OMpePwMOLTXjNwqFV/1DOSFoSH0Pl/Ed9ticcswjwiqCsmCKZv7sDnTFaJn8kD3q03cdxycnIDeEdBjART1gJiv4OzEpvM5XgTWIS+IlwG3Ag8hl39tJ4gpqQbQAN8D1yEHQawzcP8Sas4wmL2fy8PpiTzOED7TKyW1px/0Gwl0f5xzBcqUJTUEEnDOAtKs4a/k/eTUlK0YqFLz2Q2fEfju3PbrJBpgU4AX2bbWLNx9jFlzl7EntBt7vEwfyF9erWbypt5cfMWepdfI21C/jvc1sSozQQX4/gUusXByHpyax4pXT4JuGdg0EZqcilzvoBdyRbW7gTPAHuC48rKVRIwwrsASWA7cATwLBs/BU4g/B5lNIjfg5weHD8NQPtW7fsHY26G8DOj1ooGVtR4d8h6KaEdY7QG/u8NRe7DTWBBWBLfmwoE5B3g07NEO5SwucdjDmfvGDqDY1YEfth/hoVNpZpGCvKxaA9f8yqYMV74aE8+DPcRIow62WRD6DHT+gqQDXWDfSUh7AXRNTAdLwDHgM+RvnJbI6SGehLd3vN1mI6qEw7gMa+Qgh9uAp4APDdh3Ke4c4w4OMYsK7OnFSu65B7o1Y7ga0B1CwmD3H4C1uwHVtZwyFfx68ld2OsEKT/j+yPck2IJ7JYwshDtyYUZgKL1KwbEDOokryXCwZekXs/jL35OXjibD1Kk4VFaZWhZobJi8uQ9/pbuy7Jp4ZgmnUReVDgJXMPebz8B1C5xeAPsPwfnwpq/TAQeR1zd+BPLg5b9fhuHIIxAXRVUbHDElVUPG4cP4PfssbNkCX3zBoocfZpEB+i3FnXRGkkUoGioJYhsB7EFDRbOiLDUWcPMs0Fl3YuzKU0D98FhDhcu+u/UJvDq5Ie8+uaz/mnBZnaRje+p2Hjj8LasHOVC8Ygo2jjb0dO9OiEcIXVy7YKmxpLpKh8ZC/k6ivUPuq0pXhYXaosHQW9mG/Bq+ORFJRVUlVpENvabw+ocabGeeVNha8f60SaQcOM5j69bxp5M9r3v3hssy4lZVVRk98215tZopm/vwy/hjLLkmni1FO5G/KrezldtW4OJTAH0nQ95/IPFjOLwN3H7n8OGrXCghx+UnwPGc4/R6qRf4AF5AKfKUVRbyZkAzRjgMoAvgN20a1SdPsg44/Mgj8MgjDbbVd39FEb6kMZo8QlBThR8xBLK9TmqP5jDqZnn9guFLiZruSPgaqW54bHg4KVFR/z5vRbisVyc3wp+/vzZEdPLccKKiICd+A+dcz3LOJZtKq3I0kiXO593Z/ORann3xdVSoyerdk5M1YZ+T54bz62dRuGi1tX1FhkcSHhlJQQOhoZfaXbru0KooQm8Pb7BNnWO9wyk4JrdvKxSkprLUw57H/v4bm+sn8MXSpXzWK4jvegSgU6lwuSKdurEor1YzeXNvvhlziru6bmXRcD+e3tNFzn4r+BePP8B1q1wrPP1F5JpwPwERyJ6hcUI8QyAJSAY8gU7Im72CkTcEngEuKCe9NXT4KalwIBogJ4fvgKt9UWgKHWpy6cV338FBHuI8nQlkB0NZRFf+arGz4PxhRt8MR3cDnSa1QmHzkZBIPp9MHCs40T2abM80rMvtCEzvyfCSOwg404PxncejEm+llnHNNdw+YTC7evbkqbhklvxzmKCiUpNKqtSpuWdbT/bYD+PJPpmsGHcce4sm9gR1VDRlELQAhgbzyisANyOvav8IDLz69TrklNexQAzyCMOj5tLByI7E+FWIm6TD/pdbAm8BW5H/ZuzbR2oL+yokgFdfhWie5jh3cO4cBLOZYSwkmL9b7igAW3tg+xRKi2DD9y3uptlUU0W+61niux7guyPfUUgqXnkBhMQPpUtqP1wLvdGIAapBKLS2JPK223g1rAfdCktYtXk/9+86hHW16RZ9JFRsdL6eZ/Z25lZtHtGTD9LD2bSOzGyxLOTNNwE6Ax8h5wk5AGyr+V2P0VkJ8sBkD3AKeQqrOzAC/kq4eqi9seiQDiME+e/yMvAVMBSgS5cW9VWCBx+TxP/9Hzhwhj78yBNPQCC7sGhNlRXkTBJT5wIXM1j5EZQYYZhaYlfIvC3z2Gu/mgy/eJDg5u43M4yn8c3ujFWljfIiOiIqFb8H+TD5+jA2+3ty/57DbNoUw81pOahMGEm18GgA1/3VD0+bSmImH+SOzjkm02L+5ADPAQHIMZadkfNEnAYia55fhWrgLLK/OSB3OdBXj9GKkehQDsMJeB952ikImAzMBopb0ac9edzELJKToS8/404CagPcVbUabn0UuvYHBn9KRv2iYIqQ5neS93a/h0u1N11O96d70iAG+A5A01bjANsY52yseGVICM/cfh2lFho+3neCP7ccYPyZPFQ60ziOv8+4MnDtIOLO27Fi3AlWjjsGZcJxNM4F5BjLLsgB+qeA15AXLqJYvBio8Lp6N0Xypd4OTe8yNyYdwmHYIO/UTwCeRt5b0Qv4zUD9h/IdQUEG6gw5IurWR6HvCNj8M9B1juE6vwpdkwdw+onT9C67FodSF1RisdMkHAzy5Ybxg3hiSE9sq6pZuvsYj933KXz8sUnCcDNLrBm9fgAv7Qvm5qB8WN+dZ/qmY6kWsdKNUwWsAiYCgcBLgA8PPQTsPgsHd0Lac1DaHT23YZmcdj0J7QikvfgiLt98A9nZMHo0LFzI7EGDmG2A/p9JTcbpsmLul4e1Xv57eWEBexYt0qtPF0+4/XHw6wKbfoTdf8IEA2jVF8sqK4JcDOj9BC1GUqlYF+jNn/6eTMrM44XiItyffJL9ajV/+7rxh78npwb3o8q28WlCbU20lb+/f4vDdIcNG4a1tWxjDzA7LY/vRpzmg2F/8cKgPFadH84fhQMpKNOxd+/eFtloKzSWGbdKV1Uni21jSBIcPQpPLvyHk7t6kpXwHpx+DyfPQoIHJBM8MBntgGScveT554IC8wqXatcO43PAZcECEoEdQOqOHTB4cINt9Q2XvRynQC1RU+Vv4JeHubYkxFVjAUOuq8kTJcHyD+HkgWZLErRDqtRq1gd44T73DiLt/8PyOyfzn4xcbsjMozLmFIfdHInxciHW3ZmTrg5csLLEpbcWoCYEWYuFRcv/1a2tbepkyE0BeCWKe+f247EeaTzmtZF7XLaysvAa2re7aDwzbuS2SFTXhjd6nZzlVr5O2hZFVMp8uVqfuzfkD+VCwQAO/z2Qw5tC5Quss8DpOBOnlVNu3MDIJmnXDuMt4J6YGH4IM+MkfRfPMuomGDxOHl0kHobfv4aCXFMLE5glYWFEDujG66FdGZJbyM0Xq+mfmMJDx1Nr55fP2FmTFJcNOh2T0rLxjT+LTYXhs+TuyHFjR44bA1wv8FD3dFxtS5AngAV6Y5MNfuvkh6SC4i5QEAoXekFhX6K+dcDyI1OL/Jd27TBOQqMjitYS0A04uxkXz5p0QDk76eKXjk6nxts+kQrPHKqrNVTr1DhZZODvk4+DXRmO9hfx9TqP1i+XEYG/wtrDjJ8OKSdg/TJIOqqIXEE7Q6dSsdfLhSytloIgdxwrKul9voieBcX0KCimd24uvPUWb+t0sO8k7gNDeK6zHgutLSD2vBMPR/cmuPcY5EIQghahksAxUX7U8PhTk1CrzSdvnEkcxvXXX89HH32ERqNh6dKlLFiwwBQyWsV/HgC2XUfoNTUHtozmtQcvnV16xb6dj+GDutdfLLPkbPU10O9NPpnwKvntuEqXQHmKrCzZ6+3GXm83QN79HvXSS9x68yimjezMlsRSuFikqAaxG9zw2DlfNLWEOhjdYajVaj777DMmTJhARkYGMTExrFu3jhMnThhbSqtY+yU8ErOD2NdGo1JBaMQmPpj9LWq1Dt9+IeSfOIKFuhqNWofX0Bs5suZPikttKCm1ISvPhdxzjoRHzCeyD+RnvWrqlyNoj1hbc9rJnhPXhJBQlAIpyjoMQfvH6A5jyJAhJCYmkpycDMDy5cu55ZZb2pzDyE4DvEZRmFdzwHcCR5N2AVDoN5qU4/+mUtCGzCJqt3ETyQkEAoGhUWHkCOCpU6cyceJEZs+WA1vvuecehg4dyuOPP16n3ezZs5kzR95/0KNHD06dOqWIHg8PD/Ly8q7e0Ixoa5rbml5oe5qFXuVpa5o9PDywt7fHy8uwa1eSMR9Tp06VlixZUvv8nnvukT755BOjarj8ERMTYzLbHUVzW9PbFjULvUKzMfQafad3ZmYmAQEBtc/9/f3JzMw0tgyBQCAQNBOjO4yYmBi6deuGVqvF0tKS6dOns26doatmCwQCgcDQGH3Ru7q6mscee4yNGzei0Wj46quvOH7cdJXRFy9ebDLbLaWtaW5reqHtaRZ6laetaVZCr9EXvQUCgUDQNukQ2WoFAoFA0HqEwxAIBAKBXrRbh+Hq6sqmTZuIj49n06ZNuLi4NNjur7/+4vz586xfv77Oca1Wy969e0lISGD58uVYWsoFhKysrFi+fDkJCQns3buXIAMVwtBX73333Ud8fDzx8fHcd999ADg4OBAbG1v7yM3NZeHChQDMmDGDnJyc2nMzZ840iN7WagbYtm0bJ0+erNXm6ekJmOc9trW15ffff+fEiRPExcXx9ttv17Y39D2+/vrrOXnyJAkJCbz4Yv08Qk3dn3nz5pGQkMDJkye57rrr9O6ztbRU8/jx49m/fz9Hjhxh//79XHvttbXXNPb+MKXeoKAgSktLazV98cUXtdcMHDiQI0eOkJCQwEcfGTZjYEv13nXXXXU+G6qrq+nfvz/Q8vtr8nhhJR4LFiyQXnzxRQmQXnzxRemdd95psN3YsWOlG2+8UVq/fn2d4ytWrJCmTZsmAdIXX3whPfzwwxIgPfLII9IXX3whAdK0adOk5cuXG02vq6urlJSUJLm6ukouLi5SUlKS5OLiUq/d/v37pdGjR0uANGPGDMX2ubRW87Zt26RBgwbVu8Yc77Gtra0UHh4uAZKlpaW0fft2aeLEiQa/x2q1WkpMTJSCg4MlS0tL6dChQ1JISIhe9yckJEQ6dOiQZGVlJWm1WikxMVFSq9V69WkqzaGhoZKvr68ESL1795YyMjJqr2ns/WFKvUFBQdLRo0cb7Dc6OloaOnSoBEh//vln7fvDlHovf/Tp00dKTExs7f017B/DXB4nT56UfHx8JEDy8fGRTp482WjbMWPG1HMYubm5kkajkQBp2LBh0oYNGyRA2rBhgzRs2DAJkDQajZSbm2s0vdOnT5e+/PLL2udffvmlNH369DptunXrJqWlpdU+V9JhtFZzY29Yc7/HgLRo0SJp1qxZBr/Hl7/XAGnevHnSvHnz9Lo/V7a91E6fPk2l+cpHfn6+ZGVl1eT7w5R6G3MYPj4+0okTJxp9H5nD/X3rrbekN998s/Z5S+5vu52S8vb2JitLTgGblZWFt7f+dXHd3d0pKCigulrOB5WRkYGfnx8Afn5+pKenA3KIcGFhIe7u7kbRe7ntK3VdYvr06axYsaLOsalTp3L48GFWrVqFv79/q7UaUvPXX39NbGwsr776aoPXmOM9dnZ25qabbmLr1q21xwx1j/Wx39j9aexaffpsDa3RfDlTp07l4MGDVFRU1B5r6P1har3BwcEcPHiQqKgoRo0aVdv+8oqGhrzHhrq/06ZN4+eff65zrLn3t03Xw9i8eTM+Pj71jr/yyiv1julTPlFpjKF3+vTp3HvvvbXP169fz88//0xFRQVz5szh22+/Zdy4cWah+e677+bMmTM4ODiwZs0a7r33Xr7//vtm9XElSt9jjUbDzz//zMcff1ybQLO191gAvXr1YsGCBXXWXZR4f7SWs2fPEhgYyLlz5xg4cCC//vorvXv3NqkmfRgyZAilpaUcO3as9lhL7m+bdhgTJjRe7To7OxsfHx+ysrLw8fEhJydH737z8/NxcXFBo9FQXV1dJ33JpdQmmZmZaDQanJ2dyc/PN4rezMxMwsPDa5/7+/sTdVkp2H79+mFhYcHBgwdrj507d67296VLl/Luu+/qpdUYms+cOQNAcXExP/30E0OGDOH7778363u8ePHieouarb3HV9q/Wuqcxu5PU9cqmY6nNZpB/na8du1a7rvvPk6fPl17TWPvD1PrvfT3PnjwIElJSXTv3p3MzMw6I0tD3uPW6gX5i+SVo4uW3l+DzxGaw+Pdd9+ts8C5YMGCRts2tIaxcuXKOovejzzyiARIjz76aJ3FpRUrVhhNr6urq3T69GnJxcVFcnFxkU6fPi25urrWnn/77belyMjIOtdcmrMHpMmTJ0t79uwx6j1uTLNGo5Hc3d0lQLKwsJBWrVolPfTQQ2Z9j9944w1p9erVkkqlUuweazQaKSkpSdJqtbULnL169arTprH706tXrzqL3klJSZJardarz9Y8WqPZ2dlZOnTokDRlypR6fTb2/jClXg8PD0mtVkuAFBwcLGVkZNS+P65c9J40aZLJ9QKSSqWSMjIypODgYEPcX8O8aczt4ebmJm3ZskWKj4+XNm/eXPtHHTRoUJ1sudu3b5dycnKk0tJSKT09Xbruuutq3wzR0dFSQkKCtHLlytqFOGtra2nlypVSQkKCFB0dXeePYAy9DzzwgJSQkCAlJCRI999/f50+kpKSpB49etQ59n//939SXFycdOjQIenvv/+ud95Umu3s7KT9+/dLhw8fluLi4qRFixbV/iOa4z328/OTJEmSjh8/LsXGxkqxsbHSzJkzFbnHkyZNkk6dOiUlJiZKL7/8sgRI8+fPl2666aar3p+XX35ZSkxMlE6ePFknSqehPg35aKnmV155RSouLq69p7GxsZKnp2eT7w9T6r311luluLg4KTY2Vjpw4IB044031vY5aNAg6ejRo1JiYqLBA01a854YM2ZMvS8xLb2/IjWIQCAQCPSi3UZJCQQCgcCwCIchEAgEAr0QDkMgEAgEeiEchkAgEAj0QjgMgUAgEOiFcBgCgUAg0AvhMAQCgUCgF/8PVgtbUxT3/f0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the results of the XGB\n",
    "sns.histplot(results_xgb_1,kde=True,bins=20,color='red')\n",
    "sns.histplot(results_xgb_2,kde=True,bins=20,color='orange')\n",
    "sns.histplot(results_xgb_3,kde=True,bins=20,color='blue')\n",
    "sns.histplot(results_xgb_4,kde=True,bins=20,color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4279cf1",
   "metadata": {},
   "source": [
    "# Comments regarding results of the tests we ran and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd443a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comments\n",
    "\n",
    "# baseline = 0.008297694850435258 (all features)\n",
    "\n",
    "# delta without Joao features = 0.014419296789770412 => F:-0.029970666611150436 and T:-0.015551369821380024\n",
    "# --> WE REMOVE JOAO FEATURE\n",
    "\n",
    "# delta when removing the odds buckets = -0.009317543146000251 => F:-0.022611272813043187 and T:-0.028804787343669917\n",
    "# --> WE KEEP THE ODDS BUCKETS\n",
    "\n",
    "# delta when removing the odds buckets = -0.009317543146000251 => F:-0.022611272813043187 and T:-0.028804787343669917\n",
    "# --> WE KEEP THE ODDS BUCKETS\n",
    "\n",
    "# delta when removing the countries and divisions = 0.004795286566703704\n",
    "# --> WE KEEP THE COUNTRIES AND DIVISIONS\n",
    "\n",
    "# delta when removing the divisions but keeping the countries = 0.008380480363148559 (worsening)\n",
    "# delta when removing the countries but keeping the divisions = 0.02259680830123266 (best score ever)\n",
    "# --> WE KEEP THE DIVSIONS AND REMOVE THE COUNTRIES\n",
    "\n",
    "# delta when removing the 'month_after_July': 0.013657154854343441 DECREASED A LOT! We keep month after July\n",
    "# year 2020_2021 = 0.012829398919170131 DECREASED A LOT! \n",
    "# TIME MATTERS!! We need months, years, time\n",
    "\n",
    "# New basline: 0.023917075840908224\n",
    "\n",
    "#'Pin pays better' does not improve the baseline and we remove it\n",
    "\n",
    "#'Market_consensus' MATTERS we keep it\n",
    "\n",
    "#VIG matters\n",
    "\n",
    "# We should remove the P<PC variable\n",
    "# BEST DELTA: 0.03151890594630853\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps:\n",
    "\n",
    "## Time: Further explore how to optimise the features of time (years, months, hours, etc.)\n",
    "## Odds: Further explore how to optimise the odds buckets (different bins, min-max scaling)\n",
    "## VIG + Mkt Consensus: Further explore how to optimise VIG + Market consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70fd7a8",
   "metadata": {},
   "source": [
    "# [SKIP] Other models + stats package we could use [SKIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ac051",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = RandomForestRegressor(random_state=0).fit(X_step_joao, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_model.predict(X_step_joao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_step_joao)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values, X_step_joao)\n",
    "\n",
    "#- Vertical location shows what feature it is depicting\n",
    "#- Color shows whether that feature was high or low for that row of the dataset\n",
    "#- Horizontal location shows whether the effect of that value caused a higher or lower prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a37281",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_step_joao, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd925cc7",
   "metadata": {},
   "source": [
    "#  Hyperparamethers Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c55717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select hyperparam values to try\n",
    "\n",
    "alphas = [0.01, 0.1, 1] # L1 + L2 \n",
    "l1_ratios = [0.2, 0.5, 0.8] # L1 / L2 ratio\n",
    "\n",
    "# create all combinations [(0.01, 0.2), (0.01, 0.5), (...)]\n",
    "import itertools\n",
    "hyperparams = itertools.product(alphas, l1_ratios) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103a67c",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5992ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.410e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.404e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.418e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.425e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.391e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.419e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.392e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.426e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.424e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.404e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.406e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.426e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.426e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.427e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.421e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.416e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.392e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.366e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.426e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.414e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.392e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.427e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.388e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.416e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.366e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.425e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.415e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.410e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.404e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.424e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.406e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.368e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.394e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.426e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.427e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.388e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.424e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.410e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.394e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.414e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.410e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.416e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.410e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.392e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.412e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.426e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.419e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.394e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.414e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.426e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.420e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.370e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.392e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.412e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.419e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.415e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.388e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.364e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.425e+03, tolerance: 1.286e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.394e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.394e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.420e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.396e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.370e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.364e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.392e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.366e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.418e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.366e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.368e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.421e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.410e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.364e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.389e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e+03, tolerance: 1.282e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.419e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.391e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.394e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e+03, tolerance: 1.274e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.421e+03, tolerance: 1.285e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e+03, tolerance: 1.279e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.415e+03, tolerance: 1.283e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "\n",
      "240 fits failed out of a total of 660.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 934, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1489, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio == 3, must be <= 1.0.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 934, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1489, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio == 4, must be <= 1.0.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 934, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1489, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio == 6, must be <= 1.0.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 934, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/rafael/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1489, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio == 7, must be <= 1.0.\n",
      "\n",
      "One or more of the test scores are non-finite: [-0.00060701 -0.00130184         nan -0.00130184         nan -0.00054273\n",
      " -0.00130184         nan -0.00130184         nan -0.00062342 -0.00061195\n",
      " -0.00076595         nan -0.00076595         nan -0.00061195 -0.00076595\n",
      "         nan -0.00076595         nan -0.00061195 -0.00061195 -0.00053243\n",
      "         nan -0.00053243         nan -0.00061195 -0.00053243         nan\n",
      " -0.00053243         nan -0.00061195 -0.00061195 -0.00048491         nan\n",
      " -0.00048491         nan -0.00061195 -0.00048491         nan -0.00048491\n",
      "         nan -0.00061195 -0.00061195 -0.00047582         nan -0.00047582\n",
      "         nan -0.00061195 -0.00047582         nan -0.00047582         nan\n",
      " -0.00061195 -0.00061195 -0.00048096         nan -0.00048096         nan\n",
      " -0.00061195 -0.00048096         nan -0.00048096         nan -0.00061195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.116e+03, tolerance: 1.424e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instanciate model\n",
    "model = ElasticNet()\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {'alpha': [0.01, 0.1, 0.3, 0.5, 0.7, 1], \n",
    "        'l1_ratio': [0.2, 0,3, 0,4, 0.5, 0,6, 0,7, 0.8]}\n",
    "\n",
    "# Instanciate Grid Search\n",
    "search = GridSearchCV(model, grid, \n",
    "                           scoring = 'r2',\n",
    "                           cv = 10,\n",
    "                           n_jobs=-1 # paralellize computation\n",
    "                          ) \n",
    "\n",
    "# Fit data to Grid Search\n",
    "search.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eae01c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.05, l1_ratio=0.09623877434194794)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.05, l1_ratio=0.09623877434194794)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0.05, l1_ratio=0.09623877434194794)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best score\n",
    "search.best_score_\n",
    "\n",
    "# Best Params\n",
    "search.best_params_\n",
    "\n",
    "# Best estimator\n",
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b45e0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet(alpha=0.7, l1_ratio=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a223a8",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60ea05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80e97e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.05, l1_ratio=0.09623877434194794)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.05, l1_ratio=0.09623877434194794)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0.05, l1_ratio=0.09623877434194794)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciate model\n",
    "model = ElasticNet()\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {'l1_ratio': stats.uniform(0, 1), 'alpha': [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1]}\n",
    "\n",
    "# Instanciate Grid Search\n",
    "search = RandomizedSearchCV(model, grid, \n",
    "                            scoring='r2',\n",
    "                            n_iter=100,  # number of draws\n",
    "                            cv=10, n_jobs=-1)\n",
    "\n",
    "# Fit data to Grid Search\n",
    "search.fit(X_train, y_train)\n",
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901c260",
   "metadata": {},
   "source": [
    "    ElasticNet(alpha=0.05, l1_ratio=0.09623877434194794)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe150b",
   "metadata": {},
   "source": [
    "Choose hyperparameter probability distribution wisely¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d20a1e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = stats.norm(10, 2) # if you have a best guess (say: 10)\n",
    "\n",
    "dist = stats.randint(1,100) # if you have no idea\n",
    "dist = stats.uniform(1, 100) # same\n",
    "\n",
    "dist = stats.loguniform(0.01, 1) # Coarse grain search\n",
    "\n",
    "r = dist.rvs(size=10000) # Random draws\n",
    "plt.hist(r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b54e1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
