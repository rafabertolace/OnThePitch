{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4431028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d6d0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618c0c1",
   "metadata": {},
   "source": [
    "## Creating the functiong that will get the data for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3685cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_simple():\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    leagues = [file for file in listdir('./../raw_data')]\n",
    "    for league in leagues:\n",
    "        files = [file for file in listdir(f'./../raw_data/{league}')]\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv('./../raw_data/Turkey/'+file)\n",
    "        data = pd.concat([data, df])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542626a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(league1, league2=None, league3=None, league4=None, League5=None):\n",
    "    \n",
    "    files = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    #For the case we have 2 leagues to concatenate:\n",
    "    if league2:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 3 leagues to concatenate:\n",
    "    if league2 and league3:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 4 leagues to concatenate:\n",
    "    if league2 and league3 and league4:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        files4 = [file for file in listdir(f'./../raw_data/{league4}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        for file4 in files4:\n",
    "            df = pd.read_csv(f'./../raw_data/{league4}/'+file4)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 5 leagues to concatenate:\n",
    "    if league2 and league3 and league4 and league5:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        files4 = [file for file in listdir(f'./../raw_data/{league4}')]\n",
    "        files5 = [file for file in listdir(f'./../raw_data/{league5}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        for file4 in files4:\n",
    "            df = pd.read_csv(f'./../raw_data/{league4}/'+file4)\n",
    "            data = pd.concat([data, df])\n",
    "        for file5 in files5:\n",
    "            df = pd.read_csv(f'./../raw_data/{league5}/'+file5)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb9c93c",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72acb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "    '''\n",
    "        \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "\n",
    "    # payout of betting on over 2.5 goals: we get 0 if we lose the bet, we get the AvgC if we win the bet (AvgC = market average of the odds)\n",
    "    data['payout_over_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    # payout of betting on under 2.5 goals: we get 0 if we lose the bet, we get the AvgC if we win the bet (AvgC = market average of the odds)\n",
    "    data['payout_under_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #Implied Probability OVER 2.5 goals for overall market (AvgC)\n",
    "    data['Implied Probability >2.5']=1/data['AvgC>2.5']*100\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market (AvgC)\n",
    "    data['Implied Probability <2.5']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    # Binning the implied probabilities with bins of 10\n",
    "    if binned:\n",
    "        b=b\n",
    "        bins = np.arange(0, 101, int(100/b))\n",
    "        bins = bins.tolist()\n",
    "\n",
    "        data['binned >2.5'] = pd.cut(data['Implied Probability >2.5'], bins)\n",
    "        data['binned <2.5'] = pd.cut(data['Implied Probability <2.5'], bins)\n",
    "        data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "        data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "        data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "        data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "        \n",
    "    #Cleaning the data\n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab978404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_dfs(data, pinnacle=True, bet365=True):\n",
    "    \n",
    "    if pinnacle == True and bet365 == True:\n",
    "        fdf = data[['Implied Probability','over_2.5_goals','binned','payout']]\n",
    "        fdf_under = data[['Implied Probability <2.5','under_2.5_goals','binned <2.5','payout_under_2.5']]\n",
    "        fdf_under_365 = data[['Implied Probability <2.5 365','under_2.5_goals','binned <2.5 365','payout_under_2.5_365']]\n",
    "        fdf_under_pinacle = data[['Implied Probability <2.5 pinacle','under_2.5_goals','binned <2.5 pinacle','payout_under_2.5_pinacle']]\n",
    "        fdf_over = data[['Implied Probability >2.5','over_2.5_goals','binned >2.5','payout_over_2.5']]\n",
    "        fdf_over_pinacle = data[['Implied Probability >2.5 pinacle','over_2.5_goals','binned >2.5 pinacle','payout_over_2.5_pinacle']]\n",
    "        fdf_over_365 = data[['Implied Probability >2.5 365','over_2.5_goals','binned >2.5 365','payout_over_2.5_365']]\n",
    "\n",
    "        return fdf, fdf_under, fdf_under_365, fdf_under_pinacle, fdf_over, fdf_over_pinacle, fdf_over_365\n",
    "    else:\n",
    "        fdf = data[['Implied Probability','over_2.5_goals','binned','payout']]\n",
    "        fdf_under = data[['Implied Probability <2.5','under_2.5_goals','binned <2.5','payout_under_2.5']]\n",
    "        fdf_over = data[['Implied Probability >2.5','over_2.5_goals','binned >2.5','payout_over_2.5']]\n",
    "        \n",
    "        return fdf, fdf_under, fdf_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c2669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd232d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = bins.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb62b442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eed45767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b3432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e4596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec1987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e945f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
