{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237bbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245eb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(league1, wall=False):\n",
    "    \n",
    "    if wall:\n",
    "        data = pd.DataFrame()\n",
    "        leagues = listdir(f'./../raw_data/')\n",
    "        data = pd.DataFrame()\n",
    "        for league in leagues:\n",
    "            files = listdir(f'./../raw_data/{league}')\n",
    "            for file in files:\n",
    "                df = pd.read_csv((f'./../raw_data/{league}/'+file))\n",
    "                data = pd.concat([data, df])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        files = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "        for file in files:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f1e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('turkey', wall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8d283b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>Referee</th>\n",
       "      <th>Unnamed: 105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>21/08/2020</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>22/08/2020</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Dijon</td>\n",
       "      <td>Angers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>22/08/2020</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>23/08/2020</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Reims</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1</td>\n",
       "      <td>23/08/2020</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date   Time  HomeTeam    AwayTeam  FTHG  FTAG FTR  HTHG  HTAG  \\\n",
       "0  F1  21/08/2020  18:00  Bordeaux      Nantes     0     0   D   0.0   0.0   \n",
       "1  F1  22/08/2020  16:00     Dijon      Angers     0     1   A   0.0   1.0   \n",
       "2  F1  22/08/2020  20:00     Lille      Rennes     1     1   D   1.0   0.0   \n",
       "3  F1  23/08/2020  12:00    Monaco       Reims     2     2   D   1.0   2.0   \n",
       "4  F1  23/08/2020  14:00   Lorient  Strasbourg     3     1   H   0.0   1.0   \n",
       "\n",
       "   ... B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  MaxCAHA  AvgCAHH  AvgCAHA  \\\n",
       "0  ...     1.86      2.04   1.85   2.07     1.90     2.24     1.82     2.05   \n",
       "1  ...     1.86      2.07   1.85   2.06     1.88     2.08     1.83     2.03   \n",
       "2  ...     1.90      2.03   1.92   2.00     1.95     2.05     1.89     1.96   \n",
       "3  ...     1.95      1.98   1.95   1.97     1.96     1.99     1.92     1.92   \n",
       "4  ...     2.08      1.85   2.09   1.83     2.14     1.86     2.07     1.80   \n",
       "\n",
       "   Referee  Unnamed: 105  \n",
       "0      NaN           NaN  \n",
       "1      NaN           NaN  \n",
       "2      NaN           NaN  \n",
       "3      NaN           NaN  \n",
       "4      NaN           NaN  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270345be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "        '''\n",
    "    #------------------------Number of Goals, Over and Under -----------------------------------\n",
    "    \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "    \n",
    "    #-----------------------------Payout Opening ----------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average OPENING odds\n",
    "    data['payout_avg_under_2.5'] = data['under_2.5_goals']*data['Avg<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average OPENING odds\n",
    "    data['payout_avg_over_2.5'] = data['over_2.5_goals']*data['Avg>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['P<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['P>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365>2.5']\n",
    "    \n",
    "    #------------------------------Payout Closing --------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_under_closing_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_over_closing_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE closing ddds specifically\n",
    "    data['payout_under_2.5_pinacle_closing'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE closing odds specifically\n",
    "    data['payout_over_2.5_pinacle_closing'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 closing odds specifically\n",
    "    data['payout_under_2.5_365_closing'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 closing odds specifically\n",
    "    data['payout_over_2.5_365_closing'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #-------------------------- Implied Probability Opening ----------------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability <2.5 avg']=1/data['Avg<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability >2.5 avg']=1/data['Avg>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['P<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['P>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365>2.5']*100\n",
    "    \n",
    "    #------------------------- Implied Probability Closing -----------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability <2.5 avg closing']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability >2.5 avg closing']=1/data['AvgC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability <2.5 pinacle closing']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability >2.5 pinacle closing']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability <2.5 365 closing']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability >2.5 365 closing']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    #---------------------------- Binning IP Opening -------------------------------------\n",
    "\n",
    "    b=b\n",
    "    bins = np.arange(0, 101, int(100/b))\n",
    "    bins = bins.tolist()\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned <2.5 avg'] = pd.cut(data['Implied Probability <2.5 avg'], bins)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned >2.5 avg'] = pd.cut(data['Implied Probability >2.5 avg'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "    \n",
    "    #----------------------------- Binning IP Closing ------------------------------------------------\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market closing odds\n",
    "    data['binned <2.5 avg closing'] = pd.cut(data['Implied Probability <2.5 avg closing'], bins)\n",
    "\n",
    "    #Binning OVER 2.5 Average Market closing odds\n",
    "    data['binned >2.5 avg closing'] = pd.cut(data['Implied Probability >2.5 avg closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle closing odds\n",
    "    data['binned <2.5 pinacle closing'] = pd.cut(data['Implied Probability <2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle CLOSING odds\n",
    "    data['binned >2.5 pinacle closing'] = pd.cut(data['Implied Probability >2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 CLOSING odds\n",
    "    data['binned <2.5 365 closing'] = pd.cut(data['Implied Probability <2.5 365 closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 CLOSING odds\n",
    "    data['binned >2.5 365 closing'] = pd.cut(data['Implied Probability >2.5 365 closing'], bins)\n",
    "    \n",
    "    #---------------------------- Binning Odds Opening ----------------------------------------------------\n",
    "    \n",
    "    bins2 = [1, 1.5, 2, 3, 99999]\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle'] = pd.cut(data['P<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle'] = pd.cut(data['P>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365'] = pd.cut(data['B365<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365'] = pd.cut(data['B365>2.5'], bins2)\n",
    "    \n",
    "    #----------------------------- Binning Odds Closing ----------------------------------------------------------\n",
    "    \n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg closing'] = pd.cut(data['AvgC<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg closing'] = pd.cut(data['AvgC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle closing'] = pd.cut(data['PC<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle closing'] = pd.cut(data['PC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365 closing'] = pd.cut(data['B365C<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365 closing'] = pd.cut(data['B365C>2.5'], bins2)\n",
    "    \n",
    "    \n",
    "    #----------------------------- Other Features from D3 ------------------------------------------------------\n",
    "    \n",
    "    data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "    data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "    data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "    data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "    data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "    data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "    \n",
    "    #----------------------- Odds and probability of the home team scoring under 2.5 -------------------------------\n",
    "    \n",
    "    lst1 = []\n",
    "    lst2 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst1.append(1/(n_under_home[1]/total))\n",
    "            lst2.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst1.append(np.nan)\n",
    "            lst2.append(np.nan)\n",
    "\n",
    "    data['odds_home_under'] = lst1\n",
    "    data['prob_home_under'] = lst2\n",
    "    \n",
    "    \n",
    "    \n",
    "    #----------------------- Odds and probability of the away team scoring under 2.5 -------------------------------\n",
    "    \n",
    "    lst3 = []\n",
    "    lst4  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst3.append(1/(n_under_away2[1] / total2))\n",
    "            lst4.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst3.append(np.nan)\n",
    "            lst4.append(np.nan)\n",
    "\n",
    "    data['odds_away_under'] = lst3\n",
    "    data['prob_away_under'] = lst4\n",
    "    \n",
    "    # -------------------- binning the odds and probability of the home and away teams ----------------------\n",
    "    \n",
    "    #------- Probability -------\n",
    "    \n",
    "    #binning the probability of the home team to have a game of less than 2.5 score\n",
    "    data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, bins)\n",
    "    \n",
    "    #binning the probability of the away team to have a game of less than 2.5 score\n",
    "    data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, bins)\n",
    "    \n",
    "    #--------- Odds ------------\n",
    "    binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "    \n",
    "    #binning the odds of the away team to have a game of less than 2.5 score\n",
    "    data['binned odds_away_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "    \n",
    "    #binning the odds of the home team to have a game of less than 2.5 score\n",
    "    data['binned odds_home_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "\n",
    "    #-------------------------- Creating the prob and odds of the game -----------------------------------------------\n",
    "    '''the mean between the probability of the home team to have a score of under 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data['odds_game'] = (data['odds_away_under'] +  data['odds_home_under']) / 2\n",
    "    data['prob_game'] = (data['prob_away_under'] + data['prob_home_under']) / 2\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned probabilities columns ------------------------------------------\n",
    "    \n",
    "\n",
    "    if b == 5:\n",
    "        data = data[~data['binned prob_home_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "        data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "        \n",
    "    if b == 10:\n",
    "        data = data[~data['binned prob_home_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "        data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "        data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "        \n",
    "    if b == 20:\n",
    "        data = data[~data['binned prob_home_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "        data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "        data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "        data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "        data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned odds columns ------------------------------------------\n",
    "    \n",
    "    data = data[~data['binned odds_away_under'].isna()]\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(data[['binned odds_away_under']])\n",
    "    bins_encoded = ohe.transform(data[['binned odds_away_under']])\n",
    "    data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "    data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "    data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "    \n",
    "    #------------------------------------ Cleaning the data ---------------------------------------------------------\n",
    "    \n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data = data[~data['PC>2.5'].isna()]\n",
    "    data.drop(columns=['Referee', 'Unnamed: 105'], inplace=True)\n",
    "    #data.dropna()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca881c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5385/1790643236.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
      "/tmp/ipykernel_5385/1790643236.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
      "/tmp/ipykernel_5385/1790643236.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
      "/tmp/ipykernel_5385/1790643236.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
      "/tmp/ipykernel_5385/1790643236.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
      "/tmp/ipykernel_5385/1790643236.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
      "/tmp/ipykernel_5385/1790643236.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
      "/tmp/ipykernel_5385/1790643236.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
      "/tmp/ipykernel_5385/1790643236.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
      "/tmp/ipykernel_5385/1790643236.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n"
     ]
    }
   ],
   "source": [
    "data = feature_engineering(data, b=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b42ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['odds_away_under'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['odds_away_under'], bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fcc76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30dbd394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8, 2.0]      1722\n",
       "(2.2, 2.5]      1596\n",
       "(1.6, 1.8]      1343\n",
       "(2.8, 3.5]       950\n",
       "(2.0, 2.2]       927\n",
       "(2.5, 2.8]       899\n",
       "(1.5, 1.6]       483\n",
       "(1.42, 1.5]      429\n",
       "(4.0, 100.0]     405\n",
       "(3.5, 4.0]       350\n",
       "(1.25, 1.42]     254\n",
       "(1.0, 1.25]      138\n",
       "Name: binned odds_away_under, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['binned odds_away_under'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e9490fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['binned odds_away_under'].isna()]\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(data[['binned odds_away_under']])\n",
    "bins_encoded = ohe.transform(data[['binned odds_away_under']])\n",
    "data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35342509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>1.25, 1.42</th>\n",
       "      <th>1.42, 1.5</th>\n",
       "      <th>1.5, 1.6</th>\n",
       "      <th>1.6, 1.8</th>\n",
       "      <th>1.8, 2.0</th>\n",
       "      <th>2.0, 2.2</th>\n",
       "      <th>2.2, 2.5</th>\n",
       "      <th>2.5, 2.8</th>\n",
       "      <th>2.8, 3.5</th>\n",
       "      <th>3.5, 4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>21/08/2020</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>22/08/2020</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Dijon</td>\n",
       "      <td>Angers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>22/08/2020</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>23/08/2020</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Reims</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1</td>\n",
       "      <td>23/08/2020</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Oostende</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Oud-Heverlee Leuven</td>\n",
       "      <td>Waasland-Beveren</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>St Truiden</td>\n",
       "      <td>Anderlecht</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Beerschot VA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Waregem</td>\n",
       "      <td>Gent</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9496 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Div        Date   Time             HomeTeam          AwayTeam  FTHG  FTAG  \\\n",
       "0    F1  21/08/2020  18:00             Bordeaux            Nantes     0     0   \n",
       "1    F1  22/08/2020  16:00                Dijon            Angers     0     1   \n",
       "2    F1  22/08/2020  20:00                Lille            Rennes     1     1   \n",
       "3    F1  23/08/2020  12:00               Monaco             Reims     2     2   \n",
       "4    F1  23/08/2020  14:00              Lorient        Strasbourg     3     1   \n",
       "..   ..         ...    ...                  ...               ...   ...   ...   \n",
       "301  B1  18/04/2021  17:00             Oostende     Cercle Brugge     1     1   \n",
       "302  B1  18/04/2021  17:00  Oud-Heverlee Leuven  Waasland-Beveren     1     2   \n",
       "303  B1  18/04/2021  17:00           St Truiden        Anderlecht     0     1   \n",
       "304  B1  18/04/2021  17:00             Standard      Beerschot VA     3     0   \n",
       "305  B1  18/04/2021  17:00              Waregem              Gent     2     7   \n",
       "\n",
       "    FTR  HTHG  HTAG  ... 1.25, 1.42  1.42, 1.5  1.5, 1.6  1.6, 1.8  1.8, 2.0  \\\n",
       "0     D   0.0   0.0  ...        0.0        0.0       0.0       1.0       0.0   \n",
       "1     A   0.0   1.0  ...        0.0        0.0       0.0       1.0       0.0   \n",
       "2     D   1.0   0.0  ...        0.0        0.0       0.0       1.0       0.0   \n",
       "3     D   1.0   2.0  ...        0.0        0.0       1.0       0.0       0.0   \n",
       "4     H   0.0   1.0  ...        0.0        0.0       1.0       0.0       0.0   \n",
       "..   ..   ...   ...  ...        ...        ...       ...       ...       ...   \n",
       "301   D   0.0   0.0  ...        0.0        0.0       0.0       0.0       1.0   \n",
       "302   A   0.0   1.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "303   A   0.0   0.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "304   H   1.0   0.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "305   A   0.0   3.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "\n",
       "     2.0, 2.2  2.2, 2.5  2.5, 2.8  2.8, 3.5  3.5, 4.0  \n",
       "0         0.0       0.0       0.0       0.0       0.0  \n",
       "1         0.0       0.0       0.0       0.0       0.0  \n",
       "2         0.0       0.0       0.0       0.0       0.0  \n",
       "3         0.0       0.0       0.0       0.0       0.0  \n",
       "4         0.0       0.0       0.0       0.0       0.0  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "301       0.0       0.0       0.0       0.0       0.0  \n",
       "302       1.0       0.0       0.0       0.0       0.0  \n",
       "303       0.0       1.0       0.0       0.0       0.0  \n",
       "304       0.0       0.0       0.0       1.0       0.0  \n",
       "305       1.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[9496 rows x 193 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data = data[~data['binned prob_home_under'].isna()]\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(data[['binned prob_home_under']])\n",
    "bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe05e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ab245",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ece1fc",
   "metadata": {},
   "source": [
    "## Analysing the probability of a payout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "binning = np.arange(0,101, int(100/20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, binning)\n",
    "\n",
    "data.groupby('binned prob_home_under')['payout_under_2.5_pinacle_closing'].agg(['mean','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b24bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, binning)\n",
    "data.groupby('binned prob_away_under')['payout_under_2.5_pinacle_closing'].agg(['mean','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448af0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d974c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
