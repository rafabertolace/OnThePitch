{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28eacb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "plt.style.use('dark_background')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e95e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f52a2e",
   "metadata": {},
   "source": [
    "## Getting the data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the functiong that will get the data for us\n",
    "'''def get_data_simple(league):\n",
    "    \n",
    "    files = [file for file in listdir(f'./../raw_data/{league}')]\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(f'./../raw_data/{league}/'+file)\n",
    "        data = pd.concat([data, df])\n",
    "    return data'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5912ff",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get_data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc37821",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data5(league1, league2=None, league3=None, league4=None, League5=None):\n",
    "    \n",
    "    files = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    #For the case we have 2 leagues to concatenate:\n",
    "    if league2:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 3 leagues to concatenate:\n",
    "    if league2 and league3:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 4 leagues to concatenate:\n",
    "    if league2 and league3 and league4:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        files4 = [file for file in listdir(f'./../raw_data/{league4}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        for file4 in files4:\n",
    "            df = pd.read_csv(f'./../raw_data/{league4}/'+file4)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 5 leagues to concatenate:\n",
    "    if league2 and league3 and league4 and league5:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        files4 = [file for file in listdir(f'./../raw_data/{league4}')]\n",
    "        files5 = [file for file in listdir(f'./../raw_data/{league5}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        for file4 in files4:\n",
    "            df = pd.read_csv(f'./../raw_data/{league4}/'+file4)\n",
    "            data = pd.concat([data, df])\n",
    "        for file5 in files5:\n",
    "            df = pd.read_csv(f'./../raw_data/{league5}/'+file5)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99afc0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = get_data(league1='turkey', league2='eredivisie', league3 = 'greece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49306a22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775810e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering_old(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "    '''\n",
    "        \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "\n",
    "    # payout of betting on over 2.5 goals: we get 0 if we lose the bet, we get the AvgC if we win the bet (AvgC = market average of the odds)\n",
    "    data['payout_over_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    # payout of betting on under 2.5 goals: we get 0 if we lose the bet, we get the AvgC if we win the bet (AvgC = market average of the odds)\n",
    "    data['payout_under_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #Implied Probability OVER 2.5 goals for overall market (AvgC)\n",
    "    data['Implied Probability >2.5']=1/data['AvgC>2.5']*100\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market (AvgC)\n",
    "    data['Implied Probability <2.5']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    # Binning the implied probabilities with bins of 10\n",
    "    if binned:\n",
    "        b=b\n",
    "        bins = np.arange(0, 101, int(100/b))\n",
    "        bins = bins.tolist()\n",
    "\n",
    "        data['binned >2.5'] = pd.cut(data['Implied Probability >2.5'], bins)\n",
    "        data['binned <2.5'] = pd.cut(data['Implied Probability <2.5'], bins)\n",
    "        data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "        data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "        data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "        data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "        \n",
    "    #Cleaning the data\n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data.drop(columns=['Referee', 'Unnamed: 105'], inplace=True)\n",
    "    #data.dropna()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e83653",
   "metadata": {},
   "source": [
    "## Working with all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79d0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(league1, wall=False):\n",
    "    \n",
    "    if wall:\n",
    "        data = pd.DataFrame()\n",
    "        leagues = listdir(f'./../raw_data/')\n",
    "        data = pd.DataFrame()\n",
    "        for league in leagues:\n",
    "            files = listdir(f'./../raw_data/{league}')\n",
    "            for file in files:\n",
    "                df = pd.read_csv((f'./../raw_data/{league}/'+file))\n",
    "                data = pd.concat([data, df])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        files = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "        for file in files:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd3a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('turkey', wall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31f10087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "        '''\n",
    "    #------------------------Number of Goals, Over and Under -----------------------------------\n",
    "    \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "    \n",
    "    #-----------------------------Payout Opening ----------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average OPENING odds\n",
    "    data['payout_avg_under_2.5'] = data['under_2.5_goals']*data['Avg<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average OPENING odds\n",
    "    data['payout_avg_over_2.5'] = data['over_2.5_goals']*data['Avg>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['P<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['P>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365>2.5']\n",
    "    \n",
    "    #------------------------------Payout Closing --------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_under_closing_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_over_closing_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE closing ddds specifically\n",
    "    data['payout_under_2.5_pinacle_closing'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE closing odds specifically\n",
    "    data['payout_over_2.5_pinacle_closing'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 closing odds specifically\n",
    "    data['payout_under_2.5_365_closing'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 closing odds specifically\n",
    "    data['payout_over_2.5_365_closing'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #-------------------------- Implied Probability Opening ----------------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability <2.5 avg']=1/data['Avg<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability >2.5 avg']=1/data['Avg>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['P<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['P>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365>2.5']*100\n",
    "    \n",
    "    #------------------------- Implied Probability Closing -----------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability <2.5 avg closing']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability >2.5 avg closing']=1/data['AvgC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability <2.5 pinacle closing']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability >2.5 pinacle closing']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability <2.5 365 closing']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability >2.5 365 closing']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    #---------------------------- Binning IP Opening -------------------------------------\n",
    "\n",
    "    b=b\n",
    "    bins = np.arange(0, 101, int(100/b))\n",
    "    bins = bins.tolist()\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned <2.5 avg'] = pd.cut(data['Implied Probability <2.5 avg'], bins)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned >2.5 avg'] = pd.cut(data['Implied Probability >2.5 avg'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "    \n",
    "    #----------------------------- Binning IP Closing ------------------------------------------------\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market closing odds\n",
    "    data['binned <2.5 avg closing'] = pd.cut(data['Implied Probability <2.5 avg closing'], bins)\n",
    "\n",
    "    #Binning OVER 2.5 Average Market closing odds\n",
    "    data['binned >2.5 avg closing'] = pd.cut(data['Implied Probability >2.5 avg closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle closing odds\n",
    "    data['binned <2.5 pinacle closing'] = pd.cut(data['Implied Probability <2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle CLOSING odds\n",
    "    data['binned >2.5 pinacle closing'] = pd.cut(data['Implied Probability >2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 CLOSING odds\n",
    "    data['binned <2.5 365 closing'] = pd.cut(data['Implied Probability <2.5 365 closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 CLOSING odds\n",
    "    data['binned >2.5 365 closing'] = pd.cut(data['Implied Probability >2.5 365 closing'], bins)\n",
    "    \n",
    "    #---------------------------- Binning Odds Opening ----------------------------------------------------\n",
    "    \n",
    "    bins2 = [1, 1.5, 2, 3, 99999]\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle'] = pd.cut(data['P<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle'] = pd.cut(data['P>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365'] = pd.cut(data['B365<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365'] = pd.cut(data['B365>2.5'], bins2)\n",
    "    \n",
    "    #----------------------------- Binning Odds Closing ----------------------------------------------------------\n",
    "    \n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg closing'] = pd.cut(data['AvgC<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg closing'] = pd.cut(data['AvgC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle closing'] = pd.cut(data['PC<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle closing'] = pd.cut(data['PC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365 closing'] = pd.cut(data['B365C<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365 closing'] = pd.cut(data['B365C>2.5'], bins2)\n",
    "    \n",
    "    \n",
    "    #----------------------------- Other Features from D3 ------------------------------------------------------\n",
    "    \n",
    "    data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "    data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "    data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "    data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "    data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "    data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "    \n",
    "    #----------------------- Odds and probability of the home team scoring under 2.5 -------------------------------\n",
    "    \n",
    "    lst1 = []\n",
    "    lst2 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst1.append(1/(n_under_home[1]/total))\n",
    "            lst2.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst1.append(np.nan)\n",
    "            lst2.append(np.nan)\n",
    "\n",
    "    data['odds_home_under'] = lst1\n",
    "    data['prob_home_under'] = lst2\n",
    "    \n",
    "    \n",
    "    \n",
    "    #----------------------- Odds and probability of the away team scoring under 2.5 -------------------------------\n",
    "    \n",
    "    lst3 = []\n",
    "    lst4  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst3.append(1/(n_under_away2[1] / total2))\n",
    "            lst4.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst3.append(np.nan)\n",
    "            lst4.append(np.nan)\n",
    "\n",
    "    data['odds_away_under'] = lst3\n",
    "    data['prob_away_under'] = lst4\n",
    "    \n",
    "        #----------------------- Odds and probability of the home team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst5 = []\n",
    "    lst6 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst5.append(1/(n_under_home[1]/total))\n",
    "            lst6.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst5.append(np.nan)\n",
    "            lst6.append(np.nan)\n",
    "\n",
    "    data['odds_home_over'] = lst5\n",
    "    data['prob_home_over'] = lst6\n",
    "    \n",
    "     #----------------------- Odds and probability of the away team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst7 = []\n",
    "    lst8  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst7.append(1/(n_under_away2[1] / total2))\n",
    "            lst8.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst7.append(np.nan)\n",
    "            lst8.append(np.nan)\n",
    "\n",
    "    data['odds_away_over'] = lst7\n",
    "    data['prob_away_over'] = lst8\n",
    "    \n",
    "    # -------------------- binning the odds and probability of the home and away teams under 2.5 ----------------------\n",
    "    \n",
    "    #------- Probability -------\n",
    "    \n",
    "    #binning the probability of the home team to have a game of less than 2.5 score\n",
    "    data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, bins)\n",
    "    \n",
    "    #binning the probability of the away team to have a game of less than 2.5 score\n",
    "    data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, bins)\n",
    "    \n",
    "    #--------- Odds ------------\n",
    "    binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "    \n",
    "    #binning the odds of the away team to have a game of less than 2.5 score\n",
    "    data['binned odds_away_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "    \n",
    "    #binning the odds of the home team to have a game of less than 2.5 score\n",
    "    data['binned odds_home_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "    \n",
    "    \n",
    "    # -------------------- binning the odds and probability of the home and away teams over 2.5 ----------------------\n",
    "    \n",
    "    #------- Probability -------\n",
    "    \n",
    "    #binning the probability of the home team to have a game of less than 2.5 score\n",
    "    data['binned prob_home_over'] = pd.cut(data['prob_home_over']*100, bins)\n",
    "    \n",
    "    #binning the probability of the away team to have a game of less than 2.5 score\n",
    "    data['binned prob_away_over'] = pd.cut(data['prob_away_over']*100, bins)\n",
    "    \n",
    "    #--------- Odds ------------\n",
    "    binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "    \n",
    "    #binning the odds of the away team to have a game of less than 2.5 score\n",
    "    data['binned odds_away_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "    \n",
    "    #binning the odds of the home team to have a game of less than 2.5 score\n",
    "    data['binned odds_home_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "    \n",
    "\n",
    "    #-------------------------- Creating the prob and odds of the game -----------------------------------------------\n",
    "    \n",
    "    #---------------- Under --------------\n",
    "    '''the mean between the probability of the home team to have a score of under 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data['odds_game_under'] = (data['odds_away_under'] +  data['odds_home_under']) / 2\n",
    "    data['prob_game_under'] = (data['prob_away_under'] + data['prob_home_under']) / 2\n",
    "    \n",
    "    #---------------- Over -------------\n",
    "\n",
    "    '''the mean between the probability of the home team to have a score of over 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data['odds_game_over'] = (data['odds_away_over'] +  data['odds_home_over']) / 2\n",
    "    data['prob_game_over'] = (data['prob_away_over'] + data['prob_home_over']) / 2\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned probabilities columns ------------------------------------------\n",
    "    \n",
    "\n",
    "    if b == 5:\n",
    "        #-------------------- Under -----------------------\n",
    "        data = data[~data['binned prob_home_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "        data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "        \n",
    "        #-------------------- Over -----------------------\n",
    "        data = data[~data['binned prob_home_over'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_over']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "        data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "        \n",
    "    if b == 10:\n",
    "        #-------------------- Under -----------------------\n",
    "        data = data[~data['binned prob_home_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "        data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "        data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "        \n",
    "        #-------------------- Over -----------------------\n",
    "        data = data[~data['binned prob_home_over'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_over']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "        data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "        data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "        \n",
    "    if b == 20:\n",
    "        #-------------------- Under -----------------------\n",
    "        data = data[~data['binned prob_home_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "        data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "        data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "        data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "        data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "        \n",
    "        #-------------------- Over -----------------------\n",
    "        data = data[~data['binned prob_home_over'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned prob_home_over']])\n",
    "        bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "        data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "        data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "        data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "        data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned odds columns ------------------------------------------\n",
    "    \n",
    "    #-------------------- Under -----------------------                                       \n",
    "    data = data[~data['binned odds_away_under'].isna()]\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(data[['binned odds_away_under']])\n",
    "    bins_encoded = ohe.transform(data[['binned odds_away_under']])\n",
    "    data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "    data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "    data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "                                           \n",
    "    #-------------------- Over -----------------------\n",
    "    data = data[~data['binned odds_away_over'].isna()]\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(data[['binned odds_away_over']])\n",
    "    bins_encoded = ohe.transform(data[['binned odds_away_over']])\n",
    "    data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "    data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "    data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "    \n",
    "    #------------------------------------ Cleaning the data ---------------------------------------------------------\n",
    "    \n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data = data[~data['PC>2.5'].isna()]\n",
    "    data.drop(columns=['Referee', 'Unnamed: 105'], inplace=True)\n",
    "    #data.dropna()\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fea390ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded the tutorial in 0.0000 seconds\n"
     ]
    }
   ],
   "source": [
    "data = feature_engineering(data, b=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "715b933c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>1.25, 1.42</th>\n",
       "      <th>1.42, 1.5</th>\n",
       "      <th>1.5, 1.6</th>\n",
       "      <th>1.6, 1.8</th>\n",
       "      <th>1.8, 2.0</th>\n",
       "      <th>2.0, 2.2</th>\n",
       "      <th>2.2, 2.5</th>\n",
       "      <th>2.5, 2.8</th>\n",
       "      <th>2.8, 3.5</th>\n",
       "      <th>3.5, 4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>21/08/2020</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>22/08/2020</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Dijon</td>\n",
       "      <td>Angers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>22/08/2020</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>23/08/2020</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>Reims</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1</td>\n",
       "      <td>23/08/2020</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Lorient</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Oostende</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Oud-Heverlee Leuven</td>\n",
       "      <td>Waasland-Beveren</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>St Truiden</td>\n",
       "      <td>Anderlecht</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Beerschot VA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>B1</td>\n",
       "      <td>18/04/2021</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Waregem</td>\n",
       "      <td>Gent</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9381 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Div        Date   Time             HomeTeam          AwayTeam  FTHG  FTAG  \\\n",
       "0    F1  21/08/2020  18:00             Bordeaux            Nantes   0.0   0.0   \n",
       "1    F1  22/08/2020  16:00                Dijon            Angers   0.0   1.0   \n",
       "2    F1  22/08/2020  20:00                Lille            Rennes   1.0   1.0   \n",
       "3    F1  23/08/2020  12:00               Monaco             Reims   2.0   2.0   \n",
       "4    F1  23/08/2020  14:00              Lorient        Strasbourg   3.0   1.0   \n",
       "..   ..         ...    ...                  ...               ...   ...   ...   \n",
       "301  B1  18/04/2021  17:00             Oostende     Cercle Brugge   1.0   1.0   \n",
       "302  B1  18/04/2021  17:00  Oud-Heverlee Leuven  Waasland-Beveren   1.0   2.0   \n",
       "303  B1  18/04/2021  17:00           St Truiden        Anderlecht   0.0   1.0   \n",
       "304  B1  18/04/2021  17:00             Standard      Beerschot VA   3.0   0.0   \n",
       "305  B1  18/04/2021  17:00              Waregem              Gent   2.0   7.0   \n",
       "\n",
       "    FTR  HTHG  HTAG  ... 1.25, 1.42  1.42, 1.5  1.5, 1.6  1.6, 1.8  1.8, 2.0  \\\n",
       "0     D   0.0   0.0  ...        0.0        0.0       0.0       1.0       0.0   \n",
       "1     A   0.0   1.0  ...        0.0        0.0       0.0       0.0       1.0   \n",
       "2     D   1.0   0.0  ...        0.0        0.0       0.0       0.0       1.0   \n",
       "3     D   1.0   2.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "4     H   0.0   1.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "..   ..   ...   ...  ...        ...        ...       ...       ...       ...   \n",
       "301   D   0.0   0.0  ...        0.0        0.0       0.0       1.0       0.0   \n",
       "302   A   0.0   1.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "303   A   0.0   0.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "304   H   1.0   0.0  ...        1.0        0.0       0.0       0.0       0.0   \n",
       "305   A   0.0   3.0  ...        0.0        0.0       0.0       0.0       0.0   \n",
       "\n",
       "     2.0, 2.2  2.2, 2.5  2.5, 2.8  2.8, 3.5  3.5, 4.0  \n",
       "0         0.0       0.0       0.0       0.0       0.0  \n",
       "1         0.0       0.0       0.0       0.0       0.0  \n",
       "2         0.0       0.0       0.0       0.0       0.0  \n",
       "3         0.0       1.0       0.0       0.0       0.0  \n",
       "4         0.0       1.0       0.0       0.0       0.0  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "301       0.0       0.0       0.0       0.0       0.0  \n",
       "302       0.0       0.0       0.0       0.0       0.0  \n",
       "303       0.0       0.0       0.0       0.0       0.0  \n",
       "304       0.0       0.0       0.0       0.0       0.0  \n",
       "305       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[9381 rows x 199 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba0dff",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CLT - Central Limit Theorem Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24403439",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "N = 20000\n",
    "means = [fdf_under_pinacle[fdf_under_pinacle['binned <2.5 pinacle'].astype(str)=='(45, 50]']['payout_under_2.5_pinacle'].sample(n, replace=True).mean() for i in range(N)]\n",
    "\n",
    "sns.histplot(means, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0224d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mu = fdf_under_pinacle[fdf_under_pinacle['binned <2.5 pinacle'].astype(str)=='(45, 50]']['payout_under_2.5_pinacle'].mean()\n",
    "sigma = fdf_under_pinacle[fdf_under_pinacle['binned <2.5 pinacle'].astype(str)=='(45, 50]']['payout_under_2.5_pinacle'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac4a8e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# $CHALLENGIFY_BEGIN\n",
    "index_df = ['mean', 'stdev', 'kurtosis', 'skewness']\n",
    "theory = [mu, sigma/np.sqrt(n), 0, 0]\n",
    "real_life = [np.mean(means), np.std(means), skew(means), kurtosis(means)]\n",
    "comparison_df = pd.DataFrame(list(zip(theory,real_life)), \n",
    "                             columns = [\"CLT Theory\",\"Real Tips\"],\n",
    "                             index = index_df)\n",
    "round(comparison_df,2)\n",
    "# $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d50cb9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analysing the numbers of a Buyuksehyr team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8777e96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#general numbers of the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9430587",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_df = data[(data['HomeTeam'] == 'Buyuksehyr') | (data['AwayTeam'] == 'Buyuksehyr')]\n",
    "number_of_games = len(buyu_df)\n",
    "total_goals = int(buyu_df[['nb_goals']].sum())\n",
    "mean_goals_games = total_goals / number_of_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ecf2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "number_of_games, total_goals, mean_goals_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b69a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_df['under_2.5_goals'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefc807",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Home numbers of the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8f9ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_home_df = buyu_df[buyu_df['HomeTeam'] == 'Buyuksehyr']\n",
    "goals_as_home = int(buyu_home_df['FTHG'].sum())\n",
    "total_goals_ishome = int(buyu_home_df[['nb_goals']].sum())\n",
    "total_away_goals = int(buyu_home_df['FTAG'].sum())\n",
    "total_home_victory = buyu_home_df['FTR'].value_counts()[0]\n",
    "total_home_draws = buyu_home_df['FTR'].value_counts()[1]\n",
    "total_home_losses = buyu_home_df['FTR'].value_counts()[2]\n",
    "mean_home_goals_games = total_goals_ishome / 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087bdc49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_home_df['under_2.5_goals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2d77f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "goals_as_home, total_away_goals, total_goals_ishome, mean_home_goals_games, total_home_victory, total_home_draws, total_home_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6aaab5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_home_df['FTHG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e08fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Away numbers of the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff374658",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_away_df = buyu_df[buyu_df['AwayTeam'] == 'Buyuksehyr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf23b1d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "goals_as_away = int(buyu_away_df['FTAG'].sum())\n",
    "total_goals_isaway = int(buyu_away_df[['nb_goals']].sum())\n",
    "total_thome_goals = int(buyu_away_df['FTHG'].sum())\n",
    "total_away_victory = buyu_away_df['FTR'].value_counts()[0]\n",
    "total_away_draws = buyu_away_df['FTR'].value_counts()[2]\n",
    "total_away_losses = buyu_away_df['FTR'].value_counts()[1]\n",
    "mean_away_goals_games = total_goals_isaway / 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f02ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_away_df['under_2.5_goals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39204200",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_odd_away = 1/(109/192)    \n",
    "buyu_odd_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0003a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "goals_as_away, total_thome_goals, total_goals_isaway, mean_away_goals_games, total_away_victory, total_away_draws, total_away_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0107f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_away_df[['nb_goals']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a28838",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buyu_away_df['FTR'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e6ced",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating the home and away under odds feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb059bf7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''lst1 = []\n",
    "lst2 = []\n",
    "for i, team in enumerate(data['HomeTeam']):\n",
    "    total = len(data[data['HomeTeam'] == team])\n",
    "    n_under_home = data[data['HomeTeam'] == team]['under_2.5_goals'].value_counts()[1]\n",
    "    lst1.append(1/(n_under_home/total))\n",
    "    lst2.append(n_under_home/total)\n",
    "data['odds_home_under'] = lst1\n",
    "data['prob_home_under'] = lst2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4ab40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''lst3 = []\n",
    "lst4  = []\n",
    "for i, team in enumerate(data['AwayTeam']):\n",
    "    total2 = len(data[data['AwayTeam'] == team])\n",
    "    n_under_away2 = data[data['AwayTeam'] == team]['under_2.5_goals'].value_counts()[1]\n",
    "    lst3.append(1/(n_under_away2 / total2))\n",
    "    lst4.append(n_under_away2 / total2)\n",
    "data['odds_away_under'] = lst3\n",
    "data['prob_away_under'] = lst4'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2251d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8896672",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8502f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfff5d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "date = data['Date'].iloc[21]\n",
    "data[(data['HomeTeam'] == 'Goztep') & (data['Date'] < date)]\n",
    "data[(data['HomeTeam'] == 'Goztep') & (data['Date'] < date)]['under_2.5_goals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc4abf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lst1 = []\n",
    "lst2 = []\n",
    "for i, team in enumerate(data['HomeTeam']):\n",
    "    date = data['Date'].iloc[i]\n",
    "    total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "    n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "    try:\n",
    "        lst1.append(1/(n_under_home[1]/total))\n",
    "        lst2.append(n_under_home[1]/total)\n",
    "    except:\n",
    "        lst1.append(np.nan)\n",
    "        lst2.append(np.nan)\n",
    "        \n",
    "data['odds_home_under'] = lst1\n",
    "data['prob_home_under'] = lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad43293",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lst3 = []\n",
    "lst4  = []\n",
    "for i, team in enumerate(data['AwayTeam']):\n",
    "    date = data['Date'].iloc[i]\n",
    "    total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "    n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "    try:\n",
    "        lst3.append(1/(n_under_away2[1] / total2))\n",
    "        lst4.append(n_under_away2[1] / total2)\n",
    "    except:\n",
    "        lst3.append(np.nan)\n",
    "        lst4.append(np.nan)\n",
    "        \n",
    "data['odds_away_under'] = lst3\n",
    "data['prob_away_under'] = lst4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede4daf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e01cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae0df5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87973f7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Does Pinnacle pays better than the market feature\n",
    "data['PC<2.5_is_better_than_AvgC'] = data['PC<2.5']>data['AvgC<2.5']\n",
    "data['PC>2.5_is_better_than_AvgC'] = data['PC>2.5']>data['AvgC>2.5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "16h06\n",
    "# binned OVER 2.5 Pinacle\n",
    "new_view = data.groupby('prob_away_under')['payout_under_2.5_pinacle_closing'].agg(['mean','count'])\n",
    "new_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d6bfd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_view = data.groupby('prob_away_under')['payout_under_2.5'].agg(['mean','count'])\n",
    "new_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58518952",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_view = data.groupby('prob_home_under')['payout_under_2.5'].agg(['mean','count'])\n",
    "new_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6b4fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# I am binning the odds of Pinnacle with the bins_odds defined below for feature exploration\n",
    "bins_odds = [1, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4,  2.5, 3, 999999]\n",
    "bins_odds_2 = [1,2,999999]\n",
    "binning = np.arange(0,101, int(100/20))\n",
    "#Binned UNDER 2.5 Pinnacle opening odds\n",
    "data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, binning)\n",
    "#data['PC<2.5 low odds'] = data['PC<2.5']<2\n",
    "#Binned OVER 2.5 Pinnacle opening odds\n",
    "#data['binned PC>2.5'] = pd.cut(data['PC>2.5'], bins_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8d7a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, binning)\n",
    "\n",
    "data.groupby('binned prob_home_under')['payout_under_2.5'].agg(['mean','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f7169",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffa46f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, binning)\n",
    "data.groupby('binned prob_away_under')['payout_under_2.5'].agg(['mean','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532574ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a38d62",
   "metadata": {},
   "source": [
    "## Creating the home and away over odds feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #----------------------- Odds and probability of the home team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst5 = []\n",
    "    lst6 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst5.append(1/(n_under_home[1]/total))\n",
    "            lst6.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst5.append(np.nan)\n",
    "            lst6.append(np.nan)\n",
    "\n",
    "    data['odds_home_over'] = lst5\n",
    "    data['prob_home_over'] = lst6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26102de6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #----------------------- Odds and probability of the away team scoring over 2.5 -------------------------------\n",
    "    \n",
    "lst7 = []\n",
    "lst8  = []\n",
    "for i, team in enumerate(data['AwayTeam']):\n",
    "    date = data['Date'].iloc[i]\n",
    "    total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "    n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "    try:\n",
    "        lst7.append(1/(n_under_away2[1] / total2))\n",
    "        lst8.append(n_under_away2[1] / total2)\n",
    "    except:\n",
    "        lst7.append(np.nan)\n",
    "        lst8.append(np.nan)\n",
    "\n",
    "data['odds_away_over'] = lst7\n",
    "data['prob_away_over'] = lst8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb90a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=5\n",
    "bins = np.arange(0, 101, int(100/b))\n",
    "bins = bins.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ad735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- binning the odds and probability of the home and away teams over 2.5 ----------------------\n",
    "    \n",
    "    #------- Probability -------\n",
    "    \n",
    "    #binning the probability of the home team to have a game of less than 2.5 score\n",
    "    data['binned prob_home_over'] = pd.cut(data['prob_home_over']*100, bins)\n",
    "    \n",
    "    #binning the probability of the away team to have a game of less than 2.5 score\n",
    "    data['binned prob_away_over'] = pd.cut(data['prob_away_over']*100, bins)\n",
    "    \n",
    "    #--------- Odds ------------\n",
    "    binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "    \n",
    "    #binning the odds of the away team to have a game of less than 2.5 score\n",
    "    data['binned odds_away_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "    \n",
    "    #binning the odds of the home team to have a game of less than 2.5 score\n",
    "    data['binned odds_home_over'] = pd.cut(data['odds_away_over'], binodds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6674bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['odds_game_over'] = (data['odds_away_over'] +  data['odds_home_over']) / 2\n",
    "data['prob_game_over'] = (data['prob_away_over'] + data['prob_home_over']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d219071",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['odds_game_over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5905a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prob_game_over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f31ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
