{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28eacb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "plt.style.use('dark_background')\n",
    "import time\n",
    "from datetime import datetime\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831f6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e95e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f52a2e",
   "metadata": {},
   "source": [
    "## Getting the data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the functiong that will get the data for us\n",
    "'''def get_data_simple(league):\n",
    "    \n",
    "    files = [file for file in listdir(f'./../raw_data/{league}')]\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(f'./../raw_data/{league}/'+file)\n",
    "        data = pd.concat([data, df])\n",
    "    return data'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0c8fa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get_data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc37821",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data5(league1, league2=None, league3=None, league4=None, League5=None):\n",
    "    \n",
    "    files = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    #For the case we have 2 leagues to concatenate:\n",
    "    if league2:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 3 leagues to concatenate:\n",
    "    if league2 and league3:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 4 leagues to concatenate:\n",
    "    if league2 and league3 and league4:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        files4 = [file for file in listdir(f'./../raw_data/{league4}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        for file4 in files4:\n",
    "            df = pd.read_csv(f'./../raw_data/{league4}/'+file4)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    #For the case we have 5 leagues to concatenate:\n",
    "    if league2 and league3 and league4 and league5:\n",
    "        files1 = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        files2 = [file for file in listdir(f'./../raw_data/{league2}')]\n",
    "        files3 = [file for file in listdir(f'./../raw_data/{league3}')]\n",
    "        files4 = [file for file in listdir(f'./../raw_data/{league4}')]\n",
    "        files5 = [file for file in listdir(f'./../raw_data/{league5}')]\n",
    "        \n",
    "        for file1 in files1:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file1)\n",
    "            data = pd.concat([data, df])\n",
    "        for file2 in files2:\n",
    "            df = pd.read_csv(f'./../raw_data/{league2}/'+file2)\n",
    "            data = pd.concat([data, df])\n",
    "        for file3 in files3:\n",
    "            df = pd.read_csv(f'./../raw_data/{league3}/'+file3)\n",
    "            data = pd.concat([data, df])\n",
    "        for file4 in files4:\n",
    "            df = pd.read_csv(f'./../raw_data/{league4}/'+file4)\n",
    "            data = pd.concat([data, df])\n",
    "        for file5 in files5:\n",
    "            df = pd.read_csv(f'./../raw_data/{league5}/'+file5)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99afc0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = get_data(league1='turkey', league2='eredivisie', league3 = 'greece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49306a22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775810e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering_old(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "    '''\n",
    "        \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "\n",
    "    # payout of betting on over 2.5 goals: we get 0 if we lose the bet, we get the AvgC if we win the bet (AvgC = market average of the odds)\n",
    "    data['payout_over_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    # payout of betting on under 2.5 goals: we get 0 if we lose the bet, we get the AvgC if we win the bet (AvgC = market average of the odds)\n",
    "    data['payout_under_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #Implied Probability OVER 2.5 goals for overall market (AvgC)\n",
    "    data['Implied Probability >2.5']=1/data['AvgC>2.5']*100\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market (AvgC)\n",
    "    data['Implied Probability <2.5']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    # Binning the implied probabilities with bins of 10\n",
    "    if binned:\n",
    "        b=b\n",
    "        bins = np.arange(0, 101, int(100/b))\n",
    "        bins = bins.tolist()\n",
    "\n",
    "        data['binned >2.5'] = pd.cut(data['Implied Probability >2.5'], bins)\n",
    "        data['binned <2.5'] = pd.cut(data['Implied Probability <2.5'], bins)\n",
    "        data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "        data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "        data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "        data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "        \n",
    "    #Cleaning the data\n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data.drop(columns=['Referee', 'Unnamed: 105'], inplace=True)\n",
    "    #data.dropna()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b366d9a",
   "metadata": {},
   "source": [
    "## Working with all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370bcac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(league1, wall=False):\n",
    "    \n",
    "    if wall:\n",
    "        data = pd.DataFrame()\n",
    "        leagues = listdir(f'./../raw_data/')\n",
    "        data = pd.DataFrame()\n",
    "        for league in leagues:\n",
    "            files = listdir(f'./../raw_data/{league}')\n",
    "            for file in files:\n",
    "                df = pd.read_csv((f'./../raw_data/{league}/'+file))\n",
    "                data = pd.concat([data, df])\n",
    "\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        files = [file for file in listdir(f'./../raw_data/{league1}')]\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "        for file in files:\n",
    "            df = pd.read_csv(f'./../raw_data/{league1}/'+file)\n",
    "            data = pd.concat([data, df])\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae798858",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('turkey', wall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f10087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "        '''\n",
    "    #------------------------Number of Goals, Over and Under -----------------------------------\n",
    "    \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "    \n",
    "    #-----------------------------Payout Opening ----------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average OPENING odds\n",
    "    data['payout_avg_under_2.5'] = data['under_2.5_goals']*data['Avg<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average OPENING odds\n",
    "    data['payout_avg_over_2.5'] = data['over_2.5_goals']*data['Avg>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['P<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['P>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365>2.5']\n",
    "    \n",
    "    #------------------------------Payout Closing --------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_under_closing_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_over_closing_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE closing ddds specifically\n",
    "    data['payout_under_2.5_pinacle_closing'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE closing odds specifically\n",
    "    data['payout_over_2.5_pinacle_closing'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 closing odds specifically\n",
    "    data['payout_under_2.5_365_closing'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 closing odds specifically\n",
    "    data['payout_over_2.5_365_closing'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #-------------------------- Implied Probability Opening ----------------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability <2.5 avg']=1/data['Avg<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability >2.5 avg']=1/data['Avg>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['P<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['P>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365>2.5']*100\n",
    "    \n",
    "    #------------------------- Implied Probability Closing -----------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability <2.5 avg closing']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability >2.5 avg closing']=1/data['AvgC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability <2.5 pinacle closing']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability >2.5 pinacle closing']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability <2.5 365 closing']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability >2.5 365 closing']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    #---------------------------- Binning IP Opening -------------------------------------\n",
    "\n",
    "    b=b\n",
    "    bins = np.arange(0, 101, int(100/b))\n",
    "    bins = bins.tolist()\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned <2.5 avg'] = pd.cut(data['Implied Probability <2.5 avg'], bins)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned >2.5 avg'] = pd.cut(data['Implied Probability >2.5 avg'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "    \n",
    "    #----------------------------- Binning IP Closing ------------------------------------------------\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market closing odds\n",
    "    data['binned <2.5 avg closing'] = pd.cut(data['Implied Probability <2.5 avg closing'], bins)\n",
    "\n",
    "    #Binning OVER 2.5 Average Market closing odds\n",
    "    data['binned >2.5 avg closing'] = pd.cut(data['Implied Probability >2.5 avg closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle closing odds\n",
    "    data['binned <2.5 pinacle closing'] = pd.cut(data['Implied Probability <2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle CLOSING odds\n",
    "    data['binned >2.5 pinacle closing'] = pd.cut(data['Implied Probability >2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 CLOSING odds\n",
    "    data['binned <2.5 365 closing'] = pd.cut(data['Implied Probability <2.5 365 closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 CLOSING odds\n",
    "    data['binned >2.5 365 closing'] = pd.cut(data['Implied Probability >2.5 365 closing'], bins)\n",
    "    \n",
    "    #---------------------------- Binning Odds Opening ----------------------------------------------------\n",
    "    \n",
    "    bins2 = [1, 1.5, 2, 3, 99999]\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle'] = pd.cut(data['P<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle'] = pd.cut(data['P>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365'] = pd.cut(data['B365<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365'] = pd.cut(data['B365>2.5'], bins2)\n",
    "    \n",
    "    #----------------------------- Binning Odds Closing ----------------------------------------------------------\n",
    "    \n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg closing'] = pd.cut(data['AvgC<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg closing'] = pd.cut(data['AvgC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle closing'] = pd.cut(data['PC<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle closing'] = pd.cut(data['PC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365 closing'] = pd.cut(data['B365C<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365 closing'] = pd.cut(data['B365C>2.5'], bins2)\n",
    "    \n",
    "    \n",
    "    #----------------------------- Other Features from D3 ------------------------------------------------------\n",
    "    \n",
    "    data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "    data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "    data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "    data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "    data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "    data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "    \n",
    "    #----------------------- Odds and probability of the home team scoring under 2.5 -------------------------------\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    \n",
    "    lst1 = []\n",
    "    lst2 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst1.append(1/(n_under_home[1]/total))\n",
    "            lst2.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst1.append(np.nan)\n",
    "            lst2.append(np.nan)\n",
    "\n",
    "    data['odds_home_under'] = lst1\n",
    "    data['prob_home_under'] = lst2\n",
    "    \n",
    "    \n",
    "    \n",
    "    #----------------------- Odds and probability of the away team scoring under 2.5 -------------------------------\n",
    "    \n",
    "    lst3 = []\n",
    "    lst4  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst3.append(1/(n_under_away2[1] / total2))\n",
    "            lst4.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst3.append(np.nan)\n",
    "            lst4.append(np.nan)\n",
    "\n",
    "    data['odds_away_under'] = lst3\n",
    "    data['prob_away_under'] = lst4\n",
    "    \n",
    "        #----------------------- Odds and probability of the home team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst5 = []\n",
    "    lst6 = []\n",
    "    for i, team in enumerate(data['HomeTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst5.append(1/(n_under_home[1]/total))\n",
    "            lst6.append(n_under_home[1]/total)\n",
    "        except:\n",
    "            lst5.append(np.nan)\n",
    "            lst6.append(np.nan)\n",
    "\n",
    "    data['odds_home_over'] = lst5\n",
    "    data['prob_home_over'] = lst6\n",
    "    \n",
    "     #----------------------- Odds and probability of the away team scoring over 2.5 -------------------------------\n",
    "    \n",
    "    lst7 = []\n",
    "    lst8  = []\n",
    "    for i, team in enumerate(data['AwayTeam']):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "        try:\n",
    "            lst7.append(1/(n_under_away2[1] / total2))\n",
    "            lst8.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst7.append(np.nan)\n",
    "            lst8.append(np.nan)\n",
    "\n",
    "    data['odds_away_over'] = lst7\n",
    "    data['prob_away_over'] = lst8\n",
    "    \n",
    "    # -------------------- binning the odds and probability of the home and away teams under 2.5 ----------------------\n",
    "    if binned:\n",
    "\n",
    "        #------- Probability -------\n",
    "\n",
    "        #binning the probability of the home team to have a game of less than 2.5 score\n",
    "        data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, bins)\n",
    "\n",
    "        #binning the probability of the away team to have a game of less than 2.5 score\n",
    "        data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, bins)\n",
    "\n",
    "        #--------- Odds ------------\n",
    "        binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "\n",
    "        #binning the odds of the away team to have a game of less than 2.5 score\n",
    "        data['binned odds_away_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "\n",
    "        #binning the odds of the home team to have a game of less than 2.5 score\n",
    "        data['binned odds_home_under'] = pd.cut(data['odds_away_under'], binodds)\n",
    "\n",
    "\n",
    "        # -------------------- binning the odds and probability of the home and away teams over 2.5 ----------------------\n",
    "\n",
    "        #------- Probability -------\n",
    "\n",
    "        #binning the probability of the home team to have a game of less than 2.5 score\n",
    "        data['binned prob_home_over'] = pd.cut(data['prob_home_over']*100, bins)\n",
    "\n",
    "        #binning the probability of the away team to have a game of less than 2.5 score\n",
    "        data['binned prob_away_over'] = pd.cut(data['prob_away_over']*100, bins)\n",
    "\n",
    "        #--------- Odds ------------\n",
    "        binodds = [1, 1.25, 1.42, 1.5, 1.6, 1.8, 2, 2.2, 2.5, 2.8, 3.5, 4, 100]\n",
    "\n",
    "        #binning the odds of the away team to have a game of less than 2.5 score\n",
    "        data['binned odds_away_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "\n",
    "        #binning the odds of the home team to have a game of less than 2.5 score\n",
    "        data['binned odds_home_over'] = pd.cut(data['odds_away_over'], binodds)\n",
    "\n",
    "\n",
    "    #-------------------------- Creating the prob and odds of the game -----------------------------------------------\n",
    "    \n",
    "    #---------------- Under --------------\n",
    "    '''the mean between the probability of the home team to have a score of under 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data[' '] = (data['odds_away_under'] +  data['odds_home_under']) / 2\n",
    "    data['prob_game_under'] = (data['prob_away_under'] + data['prob_home_under']) / 2\n",
    "    \n",
    "    #---------------- Over -------------\n",
    "\n",
    "    '''the mean between the probability of the home team to have a score of over 2.5 and the probability \n",
    "    of the away team to do the same'''\n",
    "    \n",
    "    data['odds_game_over'] = (data['odds_away_over'] +  data['odds_home_over']) / 2\n",
    "    data['prob_game_over'] = (data['prob_away_over'] + data['prob_home_over']) / 2\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned probabilities columns ------------------------------------------\n",
    "    \n",
    "    if binned:\n",
    "        if b == 5:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "\n",
    "        if b == 10:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "            data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "            data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "\n",
    "        if b == 20:\n",
    "            #-------------------- Under -----------------------\n",
    "            data = data[~data['binned prob_home_under'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_under']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "            data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "            data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "            data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "            data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "\n",
    "            #-------------------- Over -----------------------\n",
    "            data = data[~data['binned prob_home_over'].isna()]\n",
    "            ohe = OneHotEncoder(sparse=False)\n",
    "            ohe.fit(data[['binned prob_home_over']])\n",
    "            bins_encoded = ohe.transform(data[['binned prob_home_over']])\n",
    "            data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "            data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "            data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "            data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "\n",
    "    #-------------------------- OneHotEncoding the binned odds columns ------------------------------------------\n",
    "    \n",
    "        #-------------------- Under -----------------------                                       \n",
    "        data = data[~data['binned odds_away_under'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned odds_away_under']])\n",
    "        bins_encoded = ohe.transform(data[['binned odds_away_under']])\n",
    "        data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "        data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "        data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "\n",
    "        #-------------------- Over -----------------------\n",
    "        data = data[~data['binned odds_away_over'].isna()]\n",
    "        ohe = OneHotEncoder(sparse=False)\n",
    "        ohe.fit(data[['binned odds_away_over']])\n",
    "        bins_encoded = ohe.transform(data[['binned odds_away_over']])\n",
    "        data[\"1.0, 1.25\"], data[\"1.25, 1.42\"], data[\"1.42, 1.5\"], data[\"1.5, 1.6\"],\\\n",
    "        data[\"1.6, 1.8\"], data[\"1.6, 1.8\"], data[\"1.8, 2.0\"], data[\"2.0, 2.2\"], \\\n",
    "        data[\"2.2, 2.5\"], data[\"2.5, 2.8\"], data[\"2.8, 3.5\"], data[\"3.5, 4.0\"] = bins_encoded.T\n",
    "    \n",
    "    #------------------------------------ Cleaning the data ---------------------------------------------------------\n",
    "    \n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    data = data[~data['PC>2.5'].isna()]\n",
    "    data.drop(columns=['Referee', 'Unnamed: 105'], inplace=True)\n",
    "    #data.dropna()\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea390ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_engineering(data, b=5, binned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebc13c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19080, 199)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34fbbdbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['odds_game_under'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHomeTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAwayTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43modds_home_under\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43modds_away_under\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43modds_game_under\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPC<2.5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnb_goals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['odds_game_under'] not in index\""
     ]
    }
   ],
   "source": [
    "data[['Date','HomeTeam','AwayTeam','odds_home_under','odds_away_under', 'odds_game_under', 'PC<2.5', 'nb_goals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Date','HomeTeam','AwayTeam','odds_home_over','odds_away_over','odds_home_under','odds_away_under', 'odds_game_over', 'odds_game_under', 'PC<2.5', 'AvgC<2.5','nb_goals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67147c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'odds_game_under'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'odds_game_under'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPC<2.5\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43modds_game_under\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_goals\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'odds_game_under'"
     ]
    }
   ],
   "source": [
    "data['wp'] = (data['PC<2.5'] - data['odds_game_under'] >= 0) & (data['nb_goals'] < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['wp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pred_odds'] = (data['odds_game_over'] - data['odds_game_under'] >= 0) & (data['nb_goals'] < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pred_odds'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba0dff",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CLT - Central Limit Theorem Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24403439",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "N = 20000\n",
    "means = [fdf_under_pinacle[fdf_under_pinacle['binned <2.5 pinacle'].astype(str)=='(45, 50]']['payout_under_2.5_pinacle'].sample(n, replace=True).mean() for i in range(N)]\n",
    "\n",
    "sns.histplot(means, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0224d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mu = fdf_under_pinacle[fdf_under_pinacle['binned <2.5 pinacle'].astype(str)=='(45, 50]']['payout_under_2.5_pinacle'].mean()\n",
    "sigma = fdf_under_pinacle[fdf_under_pinacle['binned <2.5 pinacle'].astype(str)=='(45, 50]']['payout_under_2.5_pinacle'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac4a8e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# $CHALLENGIFY_BEGIN\n",
    "index_df = ['mean', 'stdev', 'kurtosis', 'skewness']\n",
    "theory = [mu, sigma/np.sqrt(n), 0, 0]\n",
    "real_life = [np.mean(means), np.std(means), skew(means), kurtosis(means)]\n",
    "comparison_df = pd.DataFrame(list(zip(theory,real_life)), \n",
    "                             columns = [\"CLT Theory\",\"Real Tips\"],\n",
    "                             index = index_df)\n",
    "round(comparison_df,2)\n",
    "# $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d50cb9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analysing the numbers of a Buyuksehyr team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8777e96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#general numbers of the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9430587",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_df = data[(data['HomeTeam'] == 'Buyuksehyr') | (data['AwayTeam'] == 'Buyuksehyr')]\n",
    "number_of_games = len(buyu_df)\n",
    "total_goals = int(buyu_df[['nb_goals']].sum())\n",
    "mean_goals_games = total_goals / number_of_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ecf2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "number_of_games, total_goals, mean_goals_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b69a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_df['under_2.5_goals'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefc807",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Home numbers of the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8f9ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_home_df = buyu_df[buyu_df['HomeTeam'] == 'Buyuksehyr']\n",
    "goals_as_home = int(buyu_home_df['FTHG'].sum())\n",
    "total_goals_ishome = int(buyu_home_df[['nb_goals']].sum())\n",
    "total_away_goals = int(buyu_home_df['FTAG'].sum())\n",
    "total_home_victory = buyu_home_df['FTR'].value_counts()[0]\n",
    "total_home_draws = buyu_home_df['FTR'].value_counts()[1]\n",
    "total_home_losses = buyu_home_df['FTR'].value_counts()[2]\n",
    "mean_home_goals_games = total_goals_ishome / 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087bdc49",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_home_df['under_2.5_goals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2d77f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "goals_as_home, total_away_goals, total_goals_ishome, mean_home_goals_games, total_home_victory, total_home_draws, total_home_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6aaab5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_home_df['FTHG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e08fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Away numbers of the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff374658",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_away_df = buyu_df[buyu_df['AwayTeam'] == 'Buyuksehyr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf23b1d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "goals_as_away = int(buyu_away_df['FTAG'].sum())\n",
    "total_goals_isaway = int(buyu_away_df[['nb_goals']].sum())\n",
    "total_thome_goals = int(buyu_away_df['FTHG'].sum())\n",
    "total_away_victory = buyu_away_df['FTR'].value_counts()[0]\n",
    "total_away_draws = buyu_away_df['FTR'].value_counts()[2]\n",
    "total_away_losses = buyu_away_df['FTR'].value_counts()[1]\n",
    "mean_away_goals_games = total_goals_isaway / 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f02ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_away_df['under_2.5_goals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39204200",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_odd_away = 1/(109/192)    \n",
    "buyu_odd_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0003a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "goals_as_away, total_thome_goals, total_goals_isaway, mean_away_goals_games, total_away_victory, total_away_draws, total_away_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0107f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buyu_away_df[['nb_goals']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a28838",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buyu_away_df['FTR'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e6ced",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating the home and away under odds feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb059bf7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''lst1 = []\n",
    "lst2 = []\n",
    "for i, team in enumerate(data['HomeTeam']):\n",
    "    total = len(data[data['HomeTeam'] == team])\n",
    "    n_under_home = data[data['HomeTeam'] == team]['under_2.5_goals'].value_counts()[1]\n",
    "    lst1.append(1/(n_under_home/total))\n",
    "    lst2.append(n_under_home/total)\n",
    "data['odds_home_under'] = lst1\n",
    "data['prob_home_under'] = lst2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4ab40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''lst3 = []\n",
    "lst4  = []\n",
    "for i, team in enumerate(data['AwayTeam']):\n",
    "    total2 = len(data[data['AwayTeam'] == team])\n",
    "    n_under_away2 = data[data['AwayTeam'] == team]['under_2.5_goals'].value_counts()[1]\n",
    "    lst3.append(1/(n_under_away2 / total2))\n",
    "    lst4.append(n_under_away2 / total2)\n",
    "data['odds_away_under'] = lst3\n",
    "data['prob_away_under'] = lst4'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2251d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8896672",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8502f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfff5d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "date = data['Date'].iloc[21]\n",
    "data[(data['HomeTeam'] == 'Goztep') & (data['Date'] < date)]\n",
    "data[(data['HomeTeam'] == 'Goztep') & (data['Date'] < date)]['under_2.5_goals'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc4abf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lst1 = []\n",
    "lst2 = []\n",
    "for i, team in enumerate(data['HomeTeam']):\n",
    "    date = data['Date'].iloc[i]\n",
    "    total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "    n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "    try:\n",
    "        lst1.append(1/(n_under_home[1]/total))\n",
    "        lst2.append(n_under_home[1]/total)\n",
    "    except:\n",
    "        lst1.append(np.nan)\n",
    "        lst2.append(np.nan)\n",
    "        \n",
    "data['odds_home_under'] = lst1\n",
    "data['prob_home_under'] = lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad43293",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lst3 = []\n",
    "lst4  = []\n",
    "for i, team in enumerate(data['AwayTeam']):\n",
    "    date = data['Date'].iloc[i]\n",
    "    total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "    n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "    try:\n",
    "        lst3.append(1/(n_under_away2[1] / total2))\n",
    "        lst4.append(n_under_away2[1] / total2)\n",
    "    except:\n",
    "        lst3.append(np.nan)\n",
    "        lst4.append(np.nan)\n",
    "        \n",
    "data['odds_away_under'] = lst3\n",
    "data['prob_away_under'] = lst4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede4daf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e01cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae0df5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87973f7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Does Pinnacle pays better than the market feature\n",
    "data['PC<2.5_is_better_than_AvgC'] = data['PC<2.5']>data['AvgC<2.5']\n",
    "data['PC>2.5_is_better_than_AvgC'] = data['PC>2.5']>data['AvgC>2.5']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "16h06\n",
    "# binned OVER 2.5 Pinacle\n",
    "new_view = data.groupby('prob_away_under')['payout_under_2.5_pinacle_closing'].agg(['mean','count'])\n",
    "new_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d6bfd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_view = data.groupby('prob_away_under')['payout_under_2.5'].agg(['mean','count'])\n",
    "new_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58518952",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_view = data.groupby('prob_home_under')['payout_under_2.5'].agg(['mean','count'])\n",
    "new_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6b4fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# I am binning the odds of Pinnacle with the bins_odds defined below for feature exploration\n",
    "bins_odds = [1, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4,  2.5, 3, 999999]\n",
    "bins_odds_2 = [1,2,999999]\n",
    "binning = np.arange(0,101, int(100/20))\n",
    "#Binned UNDER 2.5 Pinnacle opening odds\n",
    "data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, binning)\n",
    "#data['PC<2.5 low odds'] = data['PC<2.5']<2\n",
    "#Binned OVER 2.5 Pinnacle opening odds\n",
    "#data['binned PC>2.5'] = pd.cut(data['PC>2.5'], bins_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8d7a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, binning)\n",
    "\n",
    "data.groupby('binned prob_home_under')['payout_under_2.5'].agg(['mean','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f7169",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffa46f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, binning)\n",
    "data.groupby('binned prob_away_under')['payout_under_2.5'].agg(['mean','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532574ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c58b3",
   "metadata": {},
   "source": [
    "## Creating the home and away over odds feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80011eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310501e",
   "metadata": {},
   "outputs": [],
   "source": [
    " #----------------------- Odds and probability of the away team scoring over 2.5 -------------------------------\n",
    "    \n",
    "lst7 = []\n",
    "lst8  = []\n",
    "for i, team in enumerate(data['AwayTeam']):\n",
    "    date = data['Date'].iloc[i]\n",
    "    total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "    n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['over_2.5_goals'].value_counts()\n",
    "    try:\n",
    "        lst7.append(1/(n_under_away2[1] / total2))\n",
    "        lst8.append(n_under_away2[1] / total2)\n",
    "    except:\n",
    "        lst7.append(np.nan)\n",
    "        lst8.append(np.nan)\n",
    "\n",
    "data['odds_away_over'] = lst7\n",
    "data['prob_away_over'] = lst8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dab34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f498156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06deb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime(2022,8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390497b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Date'] < date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c724d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['HomeTeam'] == 'Bordeaux') & (data['AwayTeam'] == 'Nantes') & (data['Date'] < date)]['over_2.5_goals'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['HomeTeam'] == 'Bordeaux') & (data['AwayTeam'] == 'Nantes') & (data['Date'] < date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceba47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['HomeTeam'] == hometeam) & (data['AwayTeam'] == awayteam) & (data['Date'] < date)]['over_2.5_goals'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1798b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst9 = []\n",
    "lst10 = []\n",
    "for i in range(len(data)):\n",
    "    date = data['Date'].iloc[i]\n",
    "    for hometeam in data['HomeTeam'].unique():\n",
    "        for awayteam in data['AwayTeam'].unique():\n",
    "            total2 = len(data[(data['HomeTeam'] == hometeam) & (data['AwayTeam'] == awayteam) & (data['Date'] < date)])\n",
    "            n_under_away2 = data[(data['HomeTeam'] == hometeam) & (data['AwayTeam'] == awayteam) & (data['Date'] < date)]['over_2.5_goals'].value_counts()[0]\n",
    "            try:\n",
    "                lst9.append(1/(n_under_away2[1] / total2))\n",
    "                lst10.append(n_under_away2[1] / total2)\n",
    "            except:\n",
    "                lst9.append(np.nan)\n",
    "                lst10.append(np.nan)\n",
    "\n",
    "data['odds_game_home_under'] = lst9\n",
    "data['prob_game_home_under'] = lst10\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    date = data['Date'].iloc[i]\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "for awayteam in data['AwayTeam'].unique():\n",
    "    for hometeam in data['HomeTeam'].unique():\n",
    "        for j in enumerate(tqdm(data[data['AwayTeam'] == awayteam])):\n",
    "            for i in enumerate(tqdm(data[data['HomeTeam'] == hometeam])):\n",
    "                date = data['Date'].iloc[i]\n",
    "                total2 = len(data[(data['HomeTeam'] == hometeam) & (data['AwayTeam'] == awayteam) & (data['Date'] < date)])\n",
    "                n_under_away2 = data[(data['HomeTeam'] == hometeam) & (data['AwayTeam'] == awayteam) & (data['Date'] < date)]\n",
    "                try:\n",
    "                    lst9.append(1/(n_under_away2[1] / total2))\n",
    "                    lst10.append(n_under_away2[1] / total2)\n",
    "                except:\n",
    "                    lst9.append(np.nan)\n",
    "                    lst10.append(np.nan)\n",
    "\n",
    "data['odds_away_over'] = lst9\n",
    "data['prob_away_over'] = lst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst9 = []\n",
    "lst10 = []\n",
    "\n",
    "\n",
    "for i, team1 in enumerate(tqdm(data['AwayTeam'])):\n",
    "    for i, team2 in enumerate(tqdm(data['HomeTeam'])):\n",
    "        date = data['Date'].iloc[i]\n",
    "        total2 = len(data[(data['HomeTeam'] == team2) & (data['AwayTeam'] == team1) & (data['Date'] < date)])\n",
    "        n_under_away2 = data[(data['HomeTeam'] == team2) & (data['AwayTeam'] == team1) & (data['Date'] < date)]\n",
    "        try:\n",
    "            lst9.append(1/(n_under_away2[1] / total2))\n",
    "            lst10.append(n_under_away2[1] / total2)\n",
    "        except:\n",
    "            lst9.append(np.nan)\n",
    "            lst10.append(np.nan)\n",
    "\n",
    "data['odds_away_over'] = lst9\n",
    "data['prob_away_over'] = lst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "total2 = len(data[(data['HomeTeam'] == 'Bordeaux') & (data['AwayTeam'] == 'Nantes') & (data['Date'] < date)])\n",
    "total2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf52d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    df['newcol'] = pool.map(f, df['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be644a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34939b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a9382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
