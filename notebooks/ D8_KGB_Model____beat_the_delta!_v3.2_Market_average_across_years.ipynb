{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1816ff7",
   "metadata": {},
   "source": [
    "# Imports and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e1f50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.pyenv/versions/3.8.12/envs/OnThePitch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score, accuracy_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "import shap\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295e690",
   "metadata": {},
   "source": [
    "# Loading the Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4f75c",
   "metadata": {},
   "source": [
    "## Merging the Seasons csv files (2019-2020 untill 2021-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3452d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(league1, wall=False):\n",
    "    '''\n",
    "    This function is getting the CSVs in the raw_data folder per country.\n",
    "    We can have only one country, we just need to pass the name of the country in lower case.\n",
    "    Or we can have all the countries inside the folder, we just need to pass the param wall=True.\n",
    "    '''\n",
    "    data = pd.DataFrame()\n",
    "    if wall:\n",
    "        leagues = listdir(f'../complete/')\n",
    "        data = pd.DataFrame()\n",
    "        for league in leagues:\n",
    "            files = listdir(f'../complete/{league}')\n",
    "            for file in files:\n",
    "                df = pd.read_csv((f'../complete/{league}/'+file), encoding='windows-1254')\n",
    "                df['country']=str(file)[0:2]\n",
    "                df['country_division']=int(str(league)[-1])\n",
    "                data = pd.concat([data, df])\n",
    "        return data\n",
    "    else:\n",
    "        files = [file for file in listdir(f'../complete/{league1}')]\n",
    "        for file in files:\n",
    "            df = pd.read_csv(f'./../complete/{league1}/'+file)\n",
    "            df['country']=str(file)[0:2]\n",
    "            data = pd.concat([data, df])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cedbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('italy', wall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450bc644",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Avg2<2.5'] = data['BbAv<2.5'].fillna(0) + data['Avg<2.5'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30164c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Avg2>2.5'] = data['BbAv>2.5'].fillna(0) + data['Avg>2.5'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f3defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Max2<2.5'] = data['BbMx<2.5'].fillna(0) + data['Max<2.5'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ff62905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Max2>2.5'] = data['BbMx>2.5'].fillna(0) + data['Max>2.5'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd58397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Avg2<2.5']>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8ad8d",
   "metadata": {},
   "source": [
    "# Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acad4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the function\n",
    "\n",
    "def feature_engineering(data, b=20, binned=False):\n",
    "    '''\n",
    "    This function creates all the columns that will be needed to create the analysis \n",
    "    and return the dataframe with all this changes\n",
    "    \n",
    "    b is the number of bins that we want to work with. Our start value for b will be 20.\n",
    "        '''\n",
    "    #------------------------Number of Goals, Over and Under -----------------------------------\n",
    "    \n",
    "    # total number of goals = goals from the home team + goals from visiting team\n",
    "    data['nb_goals']=data['FTHG']+data['FTAG']\n",
    "\n",
    "    # boolean: true or false regarding whether they were more than 2.5 goals\n",
    "    data['over_2.5_goals']=data['nb_goals']>2.5\n",
    "\n",
    "    # boolean: true or false regarding whether they were less than 2.5 goals\n",
    "    data['under_2.5_goals']=data['nb_goals']<2.5\n",
    "    \n",
    "    #-----------------------------Payout Opening ----------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average OPENING odds\n",
    "    data['payout_avg_under_2.5'] = data['under_2.5_goals']*data['Avg2<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average OPENING odds\n",
    "    data['payout_avg_over_2.5'] = data['over_2.5_goals']*data['Avg2>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE specifically\n",
    "    data['payout_under_2.5_pinacle'] = data['under_2.5_goals']*data['P<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE specifically\n",
    "    data['payout_over_2.5_pinacle'] = data['over_2.5_goals']*data['P>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 specifically\n",
    "    data['payout_under_2.5_365'] = data['under_2.5_goals']*data['B365<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 specifically\n",
    "    data['payout_over_2.5_365'] = data['over_2.5_goals']*data['B365>2.5']\n",
    "    \n",
    "    #------------------------------Payout Closing --------------------------------------------\n",
    "    \n",
    "    # payout under 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_under_closing_2.5'] = data['under_2.5_goals']*data['AvgC<2.5']\n",
    "\n",
    "    # payout over 2.5 for Average CLOSING odds\n",
    "    data['payout_avg_over_closing_2.5'] = data['over_2.5_goals']*data['AvgC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for PINACLE closing ddds specifically\n",
    "    data['payout_under_2.5_pinacle_closing'] = data['under_2.5_goals']*data['PC<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for PINACLE closing odds specifically\n",
    "    data['payout_over_2.5_pinacle_closing'] = data['over_2.5_goals']*data['PC>2.5']\n",
    "\n",
    "    #payout UNDER 2.5 for 365 closing odds specifically\n",
    "    data['payout_under_2.5_365_closing'] = data['under_2.5_goals']*data['B365C<2.5']\n",
    "\n",
    "    #payout OVER 2.5 for 365 closing odds specifically\n",
    "    data['payout_over_2.5_365_closing'] = data['over_2.5_goals']*data['B365C>2.5']\n",
    "    \n",
    "    #-------------------------- Implied Probability Opening ----------------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability <2.5 avg']=1/data['Avg<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for for overall market opening odds (Avg) \n",
    "    data['Implied Probability >2.5 avg']=1/data['Avg>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE\n",
    "    data['Implied Probability <2.5 pinacle']=1/data['P<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE\n",
    "    data['Implied Probability >2.5 pinacle']=1/data['P>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365\n",
    "    data['Implied Probability <2.5 365']=1/data['B365<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365\n",
    "    data['Implied Probability >2.5 365']=1/data['B365>2.5']*100\n",
    "    \n",
    "    #------------------------- Implied Probability Closing -----------------------------------\n",
    "    \n",
    "    #Implied Probability UNDER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability <2.5 avg closing']=1/data['AvgC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for overall market closing odds (AvgC)\n",
    "    data['Implied Probability >2.5 avg closing']=1/data['AvgC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability <2.5 pinacle closing']=1/data['PC<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for PINACLE closing odds\n",
    "    data['Implied Probability >2.5 pinacle closing']=1/data['PC>2.5']*100\n",
    "\n",
    "    #Implied Probability UNDER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability <2.5 365 closing']=1/data['B365C<2.5']*100\n",
    "\n",
    "    #Implied Probability OVER 2.5 goals for 365 closing odds\n",
    "    data['Implied Probability >2.5 365 closing']=1/data['B365C>2.5']*100\n",
    "    \n",
    "    #---------------------------- Binning IP Opening -------------------------------------\n",
    "\n",
    "    b=b\n",
    "    bins = np.arange(0, 101, int(100/b))\n",
    "    bins = bins.tolist()\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned <2.5 avg'] = pd.cut(data['Implied Probability <2.5 avg'], bins)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned >2.5 avg'] = pd.cut(data['Implied Probability >2.5 avg'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned <2.5 pinacle'] = pd.cut(data['Implied Probability <2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned >2.5 pinacle'] = pd.cut(data['Implied Probability >2.5 pinacle'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned <2.5 365'] = pd.cut(data['Implied Probability <2.5 365'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned >2.5 365'] = pd.cut(data['Implied Probability >2.5 365'], bins)\n",
    "    \n",
    "    #----------------------------- Binning IP Closing ------------------------------------------------\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market closing odds\n",
    "    data['binned <2.5 avg closing'] = pd.cut(data['Implied Probability <2.5 avg closing'], bins)\n",
    "\n",
    "    #Binning OVER 2.5 Average Market closing odds\n",
    "    data['binned >2.5 avg closing'] = pd.cut(data['Implied Probability >2.5 avg closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle closing odds\n",
    "    data['binned <2.5 pinacle closing'] = pd.cut(data['Implied Probability <2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle CLOSING odds\n",
    "    data['binned >2.5 pinacle closing'] = pd.cut(data['Implied Probability >2.5 pinacle closing'], bins)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 CLOSING odds\n",
    "    data['binned <2.5 365 closing'] = pd.cut(data['Implied Probability <2.5 365 closing'], bins)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 CLOSING odds\n",
    "    data['binned >2.5 365 closing'] = pd.cut(data['Implied Probability >2.5 365 closing'], bins)\n",
    "    \n",
    "    #---------------------------- Binning Odds Opening ----------------------------------------------------\n",
    "    \n",
    "    bins2 = [1, 1.5, 2, 3, 100]\n",
    "\n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle'] = pd.cut(data['P<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle'] = pd.cut(data['P>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365'] = pd.cut(data['B365<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365'] = pd.cut(data['B365>2.5'], bins2)\n",
    "    \n",
    "    #----------------------------- Binning Odds Closing ----------------------------------------------------------\n",
    "    \n",
    "    #Binning UNDER 2.5 Average Market opening odds\n",
    "    data['binned odds <2.5 avg'] = pd.cut(data['Avg2<2.5'], bins2)\n",
    "\n",
    "    #Binning Over 2.5 Average Market opening odds\n",
    "    data['binned odds >2.5 avg'] = pd.cut(data['Avg2>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 Pinnacle opening odds\n",
    "    data['binned odds <2.5 pinacle closing'] = pd.cut(data['PC<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 Pinnacle\n",
    "    data['binned odds >2.5 pinacle closing'] = pd.cut(data['PC>2.5'], bins2)\n",
    "\n",
    "    #Binned UNDER 2.5 bet365 OPENING odds\n",
    "    data['binned odds <2.5 365 closing'] = pd.cut(data['B365C<2.5'], bins2)\n",
    "\n",
    "    #Binned OVER 2.5 bet365 OPENING odds\n",
    "    data['binned odds >2.5 365 closing'] = pd.cut(data['B365C>2.5'], bins2)\n",
    "    \n",
    "    \n",
    "    #----------------------------- Other Features from D3 ------------------------------------------------------\n",
    "    \n",
    "    data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "    data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "    data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "    data['%vig_avg'] = (1 - (1 / (1/data['AvgC>2.5'] + 1/data['AvgC<2.5'])))*100\n",
    "    data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "    data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "    \n",
    "    #----------------------- Odds and probability of the home team scoring under 2.5 -------------------------------\n",
    "    \n",
    "#     lst1 = []\n",
    "#     lst2 = []\n",
    "#     for i, team in enumerate(data['HomeTeam']):\n",
    "#         date = data['Date'].iloc[i]\n",
    "#         total = len(data[(data['HomeTeam'] == team) & (data['Date'] < date)])\n",
    "#         n_under_home = data[(data['HomeTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "#         try:\n",
    "#             lst1.append(1/(n_under_home[1]/total))\n",
    "#             lst2.append(n_under_home[1]/total)\n",
    "#         except:\n",
    "#             lst1.append(np.nan)\n",
    "#             lst2.append(np.nan)\n",
    "\n",
    "#     data['odds_home_under'] = lst1\n",
    "#     data['prob_home_under'] = lst2\n",
    "    \n",
    "#     #binning the probability of the home team to have a game of less than 2.5 score\n",
    "#     data['binned prob_home_under'] = pd.cut(data['prob_home_under']*100, bins)\n",
    "    \n",
    "    \n",
    "    #----------------------- Odds and probability of the away team scoring under 2.5 -------------------------------\n",
    "    \n",
    "#     lst3 = []\n",
    "#     lst4  = []\n",
    "#     for i, team in enumerate(data['AwayTeam']):\n",
    "#         date = data['Date'].iloc[i]\n",
    "#         total2 = len(data[(data['AwayTeam'] == team) & (data['Date'] < date)])\n",
    "#         n_under_away2 = data[(data['AwayTeam'] == team) & (data['Date'] < date)]['under_2.5_goals'].value_counts()\n",
    "#         try:\n",
    "#             lst3.append(1/(n_under_away2[1] / total2))\n",
    "#             lst4.append(n_under_away2[1] / total2)\n",
    "#         except:\n",
    "#             lst3.append(np.nan)\n",
    "#             lst4.append(np.nan)\n",
    "\n",
    "#     data['odds_away_under'] = lst3\n",
    "#     data['prob_away_under'] = lst4\n",
    "    \n",
    "#     #binning the probability of the away team to have a game of less than 2.5 score\n",
    "#     data['binned prob_away_under'] = pd.cut(data['prob_away_under']*100, bins)\n",
    "\n",
    "    #-------------------------- Creating the prob and odds of the game -----------------------------------------------\n",
    "#     '''the mean between the probability of the home team to have a score of under 2.5 and the probability \n",
    "#     of the away team to do the same'''\n",
    "    \n",
    "#     data['odds_game'] = (data['odds_away_under'] +  data['odds_home_under']) / 2\n",
    "#     data['prob_game'] = (data['prob_away_under'] + data['prob_home_under']) / 2\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned probabilities columns ------------------------------------------\n",
    "    \n",
    "\n",
    "#     if b == 5:\n",
    "#         data = data[~data['binned prob_home_under'].isna()]\n",
    "#         ohe = OneHotEncoder(sparse=False)\n",
    "#         ohe.fit(data[['binned prob_home_under']])\n",
    "#         bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "#         data[\"0, 20\"], data[\"20, 40\"], data[\"40, 60\"], data[\"60, 80\"], data[\"80, 100\"] = bins_encoded.T\n",
    "        \n",
    "#     if b == 10:\n",
    "#         data = data[~data['binned prob_home_under'].isna()]\n",
    "#         ohe = OneHotEncoder(sparse=False)\n",
    "#         ohe.fit(data[['binned prob_home_under']])\n",
    "#         bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "#         data[\"0, 10\"], data[\"10, 20\"], data[\"20, 30\"], data[\"30, 40\"], data[\"40, 50\"], data[\"50, 60\"], \\\n",
    "#         data[\"60, 70\"], data[\"70, 80\"], data[\"80, 90\"], data[\"90, 100\"] = bins_encoded.T\n",
    "        \n",
    "#     if b == 20:\n",
    "#         data = data[~data['binned prob_home_under'].isna()]\n",
    "#         ohe = OneHotEncoder(sparse=False)\n",
    "#         ohe.fit(data[['binned prob_home_under']])\n",
    "#         bins_encoded = ohe.transform(data[['binned prob_home_under']])\n",
    "#         data[\"0, 5\"], data[\"5, 10\"], data[\"10, 15\"], data[\"15, 20\"], data[\"20, 25\"], data[\"25, 30\"], \\\n",
    "#         data[\"30, 35\"], data[\"35, 40\"], data[\"40, 45\"], data[\"45, 50\"], data[\"50, 55\"], data[\"55, 60\"], \\\n",
    "#         data[\"60, 65\"], data[\"65, 70\"], data[\"70, 75\"], data[\"75, 80\"], data[\"80, 85\"], data[\"85, 90\"], \\\n",
    "#         data[\"90, 95\"], data[\"95, 100\"]= bins_encoded.T\n",
    "    \n",
    "    #------------------------------------ Cleaning the data ---------------------------------------------------------\n",
    "    \n",
    "    #data = data.dropna(subset=['HomeTeam', 'AwayTeam'], how='any')\n",
    "    data = data[~data['HomeTeam'].isna()]\n",
    "    data = data[~data['AwayTeam'].isna()]\n",
    "    #data = data[~data['PC>2.5'].isna()]\n",
    "    data = data[~data['Avg2<2.5'].isna()]\n",
    "    data.drop(columns=['Referee','Unnamed: 105'], inplace=True) #, 'Unnamed: 105' 'Referee', \n",
    "    #data.dropna()\n",
    "    \n",
    "     #-------------------------- OneHotEncoding the binned odds ------------------------------------------\n",
    "   \n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['binned odds <2.5 avg']])\n",
    "    bins_encoded = ohe.transform(data[['binned odds <2.5 avg']])\n",
    "    data[\"1.0_to_1.5\"], data[\"1.5_to_2.0\"], data[\"2.0_to_3\"], data[\"3_to_100\"] = bins_encoded.T\n",
    "    data.drop(columns='binned odds <2.5 avg', inplace=True)\n",
    "    \n",
    "    #-------------------------- OneHotEncoding the binned countries ------------------------------------------\n",
    "\n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['country']])\n",
    "    bins_encoded = ohe.transform(data[['country']])\n",
    "    data[\"country_1\"], data[\"country_2\"], data[\"country_3\"], data[\"country_4\"], data[\"country_5\"],data[\"country_6\"], data[\"country_7\"], data[\"country_8\"], data[\"country_9\"], data[\"country_10\"], data[\"country_11\"] = bins_encoded.T\n",
    "    data.drop(columns='country', inplace=True)\n",
    "\n",
    "    #-------------------------- OneHotEncoding the binned country divisions ------------------------------------------\n",
    "    \n",
    "    ohe = OneHotEncoder(sparse=False) \n",
    "    ohe.fit(data[['country_division']])\n",
    "    bins_encoded = ohe.transform(data[['country_division']])\n",
    "    data[\"country_div_1\"], data[\"country_div_2\"], data[\"country_div_3\"], data[\"country_div_4\"] = bins_encoded.T\n",
    "    #data.drop(columns='country_division', inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c518df9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Running the function and creating the dataset data\n",
    "\n",
    "data = feature_engineering(data, b=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24d725b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE WILL NEED TO ADD ALL THOSE IN THE feature_engineering FUNCTION\n",
    "\n",
    "## Adding the Year Feature \n",
    "data_date = data['Date']\n",
    "data_time = data['Time']\n",
    "data_date_2 = pd.to_datetime(data_date, dayfirst = True)\n",
    "data_time_2 = pd.to_datetime(data_time, dayfirst = True)\n",
    "data['month'] = pd.DatetimeIndex(data_date_2).month\n",
    "data['month_after_July'] = data['month']>=7\n",
    "data['year'] = pd.DatetimeIndex(data_date_2).year\n",
    "data['year_2021_2022'] = data['year']>=2021\n",
    "data['year_2022'] = data['year']>=2022\n",
    "data['year_2020'] = data['year']==2020\n",
    "data['season_21_22'] = data_date_2>='2021-09-01'\n",
    "data['season_20_21'] = (data_date_2>='2020-09-01') & (data_date_2<'2021-09-01')\n",
    "data['season_training2'] = (data_date_2<'2020-09-01')\n",
    "\n",
    "#Hours\n",
    "data['hour'] = pd.DatetimeIndex(data_time_2).hour\n",
    "data['game_starts_after_4pm']=data['hour']>=16\n",
    "\n",
    "#Hours feature\n",
    "data['hour_number'] = data['hour'].map({10:1, 11:2, 12:3, 13:4, 14:5, 15:6, 16:7, 17:8, 18:9, 19:10, 20:11, 21:12})\n",
    "data['hour_number_2'] = data['hour'].map({10:1, 11:1, 12:1, 13:2, 14:2, 15:2, 16:3, 17:3, 18:3, 19:4, 20:4, 21:4})\n",
    "data['hour_number_2_ratio'] = data['hour'].map({10:1, 11:1, 12:1, 13:2, 14:2, 15:2, 16:3, 17:3, 18:3, 19:4, 20:4, 21:4})/4\n",
    "data['hour_number_ratio'] = data['hour'].map({10:1, 11:2, 12:3, 13:4, 14:5, 15:6, 16:7, 17:8, 18:9, 19:10, 20:11, 21:12})/12\n",
    "\n",
    "#OHE before after 4pm\n",
    "ohe = OneHotEncoder(sparse=False) \n",
    "ohe.fit(data[['game_starts_after_4pm']])\n",
    "bins_encoded = ohe.transform(data[['game_starts_after_4pm']])\n",
    "data[\"game_starts_after_4pm_1\"], data[\"game_starts_after_4pm_2\"] = bins_encoded.T\n",
    "   # data.drop(columns='country_division', inplace=True)\n",
    "\n",
    "#OHE Hours groups (4 groups)  \n",
    "#ohe.fit(data[['hour_number_2']])\n",
    "#bins_encoded = ohe.transform(data[['hour_number_2']])\n",
    "#data[\"hour_group_1\"], data[\"hour_group_2\"], data[\"hour_group_3\"], data[\"hour_group_4\"] = bins_encoded.T\n",
    "    \n",
    "#Other features\n",
    "data['Pin_pays_better_under_boolean'] = data['PC<2.5'] > data['AvgC<2.5']\n",
    "data['Pin_pays_better_under_difference'] = data['PC<2.5'] / data['AvgC<2.5']\n",
    "data['%vig_p'] = (1 - (1 / (1/data['PC>2.5'] + 1/data['PC<2.5'])))*100\n",
    "data['%vig_p_bool'] = data['%vig_p']>3.3\n",
    "data['%vig_avg'] = (1 - (1 / (1/data['Avg2>2.5'] + 1/data['Avg2<2.5'])))*100\n",
    "data['%vig_avg_bool'] = data['%vig_avg']>5.2\n",
    "\n",
    "data['PC<2.5_P_boolean'] = data['PC<2.5'] < data['P<2.5']\n",
    "data['PC<2.5_P_relative_diff'] = data['PC<2.5'] / data['P<2.5']\n",
    "data['Max>2.5_Avg_relative_diff'] = data['Max2>2.5']/data['Avg2>2.5']\n",
    "data['Market_consensus'] = data['Max>2.5_Avg_relative_diff']<1.05\n",
    "\n",
    "#Months\n",
    "data['month_number']=data['month']\n",
    "data['month_number_ratio']=data['month']/12\n",
    "data['year_number'] = data['year'].map({2010:1, 2011:2, 2012:3, 2013:4, 2014:5, 2015:6, 2016:7, 2017:8, 2018:9, 2019:10, 2020:11, 2021:12, 2022:13})\n",
    "data['year_number_ratio'] = data['year'].map({2019:1, 2020:2, 2021:3, 2022:4})/4\n",
    "data['year_number_month_ratio'] = data['year_number']+data['month_number_ratio']\n",
    "data['year_number_month_decimal'] = data['year_number']+data['month_number']/10\n",
    "\n",
    "#OHE years\n",
    "#ohe = OneHotEncoder(sparse=False) \n",
    "#ohe.fit(data[['year_number']])\n",
    "#bins_encoded = ohe.transform(data[['year_number']])\n",
    "#data[\"year_1\"], data[\"year_2\"], data[\"year_3\"], data[\"year_4\"] = bins_encoded.T\n",
    "\n",
    "#OHE months\n",
    "ohe = OneHotEncoder(sparse=False) \n",
    "ohe.fit(data[['month_number']])\n",
    "bins_encoded = ohe.transform(data[['month_number']])\n",
    "data[\"month_1\"], data[\"month_2\"], data[\"month_3\"], data[\"month_4\"], data[\"month_5\"], data[\"month_6\"], data[\"month_7\"], data[\"month_8\"], data[\"month_9\"], data[\"month_10\"], data[\"month_11\"], data[\"month_12\"] = bins_encoded.T\n",
    "\n",
    "data.rename(columns = {'PC<2.5':'PC_under_2.5'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b72900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min_max_scaler\n",
    "scaler = RobustScaler().fit(data[['PC_under_2.5']]) \n",
    "data['PC_under_2.5_scaled'] = scaler.transform(data[['PC_under_2.5']]) # Use scaler to transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32918dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Binned PC_under_2.5\n",
    "# B1 = data['PC_under_2.5'].min()\n",
    "# B2 = np.quantile(data['PC_under_2.5'], 0.25, interpolation='midpoint')\n",
    "# B3 = np.quantile(data['PC_under_2.5'], 0.50, interpolation='midpoint')\n",
    "# B4 = np.quantile(data['PC_under_2.5'], 0.75, interpolation='midpoint')\n",
    "# B5 = data['PC_under_2.5'].max()\n",
    "\n",
    "# bins = [B1-0.1,B2,B3,B4,B5+0.1]\n",
    "# data[\"binned_odds\"] = pd.cut(data['PC_under_2.5'], bins)\n",
    "\n",
    "# #OHE Binned PC_under_2.5\n",
    "# ohe = OneHotEncoder(sparse=False) \n",
    "# ohe.fit(data[[\"binned_odds\"]])\n",
    "# bins_encoded = ohe.transform(data[[\"binned_odds\"]])\n",
    "# data[\"bin_odds_1\"], data[\"bin_odds_2\"],data[\"bin_odds_3\"], data[\"bin_odds_4\"] = bins_encoded.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0df27",
   "metadata": {},
   "source": [
    "# Defining the Model functions (XGB models for under 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42aedd1",
   "metadata": {},
   "source": [
    "## Regression Model functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0bb8a",
   "metadata": {},
   "source": [
    "### Function testing_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "ab21f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lr_true = []\n",
    "# results_lr_false = []\n",
    "\n",
    "def testing_models_regressor(iterations,test_size_0,train_size_0):   \n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while i < iterations:\n",
    "        # Split into Train/Test\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.3) # Split into Train/Test\n",
    "        #_ignore1, X_test_model, _ignore2, y_test_model = train_test_split(X_test_0, y_test_0, test_size=test_size_0)\n",
    "        #X_train_model, _ignore3, y_train_model, _ignore4 = train_test_split(X_train_0, y_train_0, test_size=(1-train_size_0)) # Split into Train/Test\n",
    "\n",
    "            #------------------------Run the Models -----------------------------------\n",
    "\n",
    "        #Run Linear Regression\n",
    "#         results_linear_regression = sm.OLS(y_train,X_train.astype(float)).fit()\n",
    "#         y_pred_lr = results_linear_regression.predict(X_test.astype(float))\n",
    "#         #results.summary()\n",
    "\n",
    "        #Initiate XGBoost\n",
    "        m = 0\n",
    "        m = xgb.XGBRegressor()\n",
    "        \n",
    "        #Rename columns for XGBoost to run\n",
    "        ##X_test.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        ##X_train.rename(columns = {'PC<2.5_P_boolean':'PC_under_2.5_P_boolean'}, inplace = True)\n",
    "        \n",
    "        #Fit XGBoost\n",
    "        m.fit(X_train_0,y_train_0) \n",
    "        \n",
    "        #Make and store the predictions XGBoost\n",
    "        y_pred_xgb = m.predict(X_test_0)\n",
    "        y_pred_xgb = pd.DataFrame(y_pred_xgb)\n",
    "\n",
    "            #------------------------Creating the bins for the predictions for both models -----------------------------------\n",
    "        #Function to replace bin with default value when it is null\n",
    "        def ifnull(var, val):\n",
    "          if var > 0:\n",
    "            return var\n",
    "          return val\n",
    "\n",
    "        #Linear Regression\n",
    "#         y_pred_lr_under_0_median = y_pred_lr[y_pred_lr<0].median()\n",
    "#         y_pred_lr_under_0_min = y_pred_lr[y_pred_lr<0].min()\n",
    "#         y_pred_lr_over_0_median = ifnull(y_pred_lr[y_pred_lr>0].median(),0.05)\n",
    "\n",
    "        #XGB bins\n",
    "        y_pred_xgb_under_0_median = y_pred_xgb[y_pred_xgb<0].median()\n",
    "        y_pred_xgb_under_0_min = y_pred_xgb[y_pred_xgb<0].min()\n",
    "        y_pred_xgb_over_0_median = ifnull(y_pred_xgb[0][y_pred_xgb[0]>0].median(),0.05)\n",
    "\n",
    "            #------------------------Betting decisions for both models -----------------------------------\n",
    "#         #Linear Regression\n",
    "#         bins3_lr = [y_pred_lr_under_0_min-0.0000002, y_pred_lr_under_0_median-0.0000001, 0, y_pred_lr_over_0_median+0.0000001, 1]\n",
    "#         y_lr_df = pd.DataFrame(y_test)\n",
    "#         y_pred_lr_df = pd.DataFrame(y_pred_lr)\n",
    "#         y_pred_lr_df[\"binned_pred\"] = pd.cut(y_pred_lr_df[0], bins3_lr)\n",
    "#         ind = np.arange(0, len(y_pred_lr_df))\n",
    "#         ind = ind.tolist()\n",
    "#         y_lr_df['ind'] = ind\n",
    "#         y_pred_lr_df['ind'] = ind\n",
    "#         y_final_lr = y_lr_df.merge(y_pred_lr_df, on=\"ind\")#, on = \"axis\")#, how = \"inner\")\n",
    "#         y_final_lr['bet_opp']=y_final_lr[0]>0\n",
    "\n",
    "        #XGB\n",
    "        bins3_xgb = [-0.0000002, -0.0000001, 0, y_pred_xgb_over_0_median+0.0000001, 1] #int(y_pred_xgb_over_0_median[0])\n",
    "        y_xgb_df = pd.DataFrame(y_test_0)\n",
    "        y_pred_xgb_df = pd.DataFrame(y_pred_xgb)\n",
    "        y_pred_xgb_df[\"binned_pred\"] = pd.cut(y_pred_xgb_df[0], bins3_xgb)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_1\"] = y_pred_xgb_df[0]<y_pred_xgb_under_0_median[0]-0.0000001\n",
    "        y_pred_xgb_df[\"binned_pred_bin_2\"] = (y_pred_xgb_df[0]>y_pred_xgb_under_0_median[0]-0.0000001) & (y_pred_xgb_df[0]<0)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_3\"] = (y_pred_xgb_df[0]>0) & (y_pred_xgb_df[0]<y_pred_xgb_over_0_median+0.0000001)\n",
    "        y_pred_xgb_df[\"binned_pred_bin_4\"] = (y_pred_xgb_df[0]>y_pred_xgb_over_0_median+0.0000001)\n",
    "        y_pred_xgb_df[\"bin_number\"] = y_pred_xgb_df[\"binned_pred_bin_1\"]*1 + y_pred_xgb_df[\"binned_pred_bin_2\"]*2 + y_pred_xgb_df[\"binned_pred_bin_3\"]*3 + y_pred_xgb_df[\"binned_pred_bin_4\"]*4     \n",
    "        ind = np.arange(0, len(y_pred_xgb_df))\n",
    "        ind = ind.tolist()\n",
    "        y_xgb_df['ind'] = ind\n",
    "        y_pred_xgb_df['ind'] = ind\n",
    "        y_final_xgb = y_xgb_df.merge(y_pred_xgb_df, on=\"ind\")#, on = \"axis\")#, how = \"inner\")\n",
    "        \n",
    "        #Defining the variable bet_opp based on the y_pred of the XGB\n",
    "        y_final_xgb['bet_opp']=y_final_xgb[0]>0\n",
    "\n",
    "            #------------------------Getting the results based on predictions -----------------------------------\n",
    "        #Linear Regression\n",
    "#         y_final_lr.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].count()\n",
    "#         y_final_lr.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].agg([\"mean\", \"count\"])\n",
    "\n",
    "#         y_final_lr.groupby('binned_pred')['payout_under_2.5_pinacle_closing'].count()\n",
    "#         y_final_lr.groupby('binned_pred')['payout_under_2.5_pinacle_closing'].agg([\"mean\", \"count\"])\n",
    "#         lr_results_False = y_final_lr[y_final_lr['bet_opp']==False]['payout_under_2.5_pinacle_closing'].mean()\n",
    "#         lr_results_True = y_final_lr[y_final_lr['bet_opp']==True]['payout_under_2.5_pinacle_closing'].mean()        \n",
    "        \n",
    "\n",
    "        #XGB\n",
    "        #xgb_count = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].count()\n",
    "        #xgb_mean = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].mean()\n",
    "        #xgb_results = y_final_xgb.groupby('bet_opp')['payout_under_2.5_pinacle_closing'].agg([\"mean\", \"count\"])\n",
    "        xgb_results_False = y_final_xgb[y_final_xgb['bet_opp']==False][payout_cat].mean()\n",
    "        xgb_results_True = y_final_xgb[y_final_xgb['bet_opp']==True][payout_cat].mean()\n",
    "        xgb_results_False_count = y_final_xgb[y_final_xgb['bet_opp']==False][payout_cat].count()\n",
    "        xgb_results_True_count = y_final_xgb[y_final_xgb['bet_opp']==True][payout_cat].count()               \n",
    "        xgb_results_bin_1 = y_final_xgb[y_final_xgb['bin_number']==1][payout_cat].mean()\n",
    "        xgb_results_bin_2 = y_final_xgb[y_final_xgb['bin_number']==2][payout_cat].mean()\n",
    "        xgb_results_bin_3 = y_final_xgb[y_final_xgb['bin_number']==3][payout_cat].mean()\n",
    "        xgb_results_bin_4 = y_final_xgb[y_final_xgb['bin_number']==4][payout_cat].mean()\n",
    "        \n",
    "        results_xgb_false.append(xgb_results_False)\n",
    "        results_xgb_true.append(xgb_results_True)\n",
    "        results_xgb_false_count.append(xgb_results_False_count)\n",
    "        results_xgb_true_count.append(xgb_results_True_count)\n",
    "        results_xgb_1.append(xgb_results_bin_1)\n",
    "        results_xgb_2.append(xgb_results_bin_2)\n",
    "        results_xgb_3.append(xgb_results_bin_3)\n",
    "        results_xgb_4.append(xgb_results_bin_4)\n",
    "         \n",
    "        i=i+1\n",
    "        \n",
    "    return results_xgb_false, results_xgb_true, results_xgb_false_count, results_xgb_true_count, results_xgb_1, results_xgb_2, results_xgb_3, results_xgb_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d85c27",
   "metadata": {},
   "source": [
    "### Function checking_model_regressor_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53c13e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_model_regressor_results(n=10, test_size_0=0.99, train_size_0=0.99):\n",
    "    \n",
    "    # Empty_lists\n",
    "    results_xgb_true=[] \n",
    "    results_xgb_false=[]\n",
    "    results_xgb_false_count=[]\n",
    "    results_xgb_true_count=[]\n",
    "    results_xgb_1=[]\n",
    "    results_xgb_2=[]\n",
    "    results_xgb_3=[]\n",
    "    results_xgb_4=[]\n",
    "    \n",
    "    # Run the model regressor X times\n",
    "    results_xgb_false, results_xgb_true, results_xgb_false_count, results_xgb_true_count, results_xgb_1, results_xgb_2, results_xgb_3, results_xgb_4 = testing_models_regressor(n,test_size_0,train_size_0)\n",
    "    \n",
    "    # Results\n",
    "    median_results_bad_bets = np.median(np.array(results_xgb_false))\n",
    "    median_results_good_bets = np.median(np.array(results_xgb_true))\n",
    "    \n",
    "    median_results_bad_bets_count = np.median(np.array(results_xgb_false_count))\n",
    "    median_results_good_bets_count = np.median(np.array(results_xgb_true_count))   \n",
    "    \n",
    "    median_results_group_1_bets = np.median(np.array(results_xgb_1))\n",
    "    median_results_group_2_bets = np.median(np.array(results_xgb_2))\n",
    "    median_results_group_3_bets = np.median(np.array(results_xgb_3))\n",
    "    median_results_group_4_bets = np.median(np.array(results_xgb_4))\n",
    "    delta = np.median(np.array(median_results_good_bets))-np.median(np.array(median_results_bad_bets))\n",
    "    delta_extremes = np.median(np.array(results_xgb_4))-np.median(np.array(results_xgb_1))\n",
    "    #print(delta, delta_extremes)\n",
    "    \n",
    "    #Plotting the results of the XGB\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,10))\n",
    "#     sns.histplot(results_xgb_true,kde=True,bins=20,color='green',ax=ax[0])\n",
    "#     sns.histplot(results_xgb_false,kde=True,bins=20,color='red',ax=ax[0])\n",
    "    \n",
    "#     sns.histplot(results_xgb_1,kde=True,bins=20,color='red',ax=ax[1])\n",
    "#     sns.histplot(results_xgb_2,kde=True,bins=20,color='orange',ax=ax[1])\n",
    "#     sns.histplot(results_xgb_3,kde=True,bins=20,color='grey',ax=ax[1])\n",
    "#     sns.histplot(results_xgb_4,kde=True,bins=20,color='green',ax=ax[1])\n",
    "    \n",
    "#     my_model = xgb.XGBRegressor()\n",
    "#     my_model.fit(X_train_0,y_train_0)\n",
    "#     explainer = shap.TreeExplainer(my_model)\n",
    "#     shap_values = explainer.shap_values(X_test_0)\n",
    "#     shap.summary_plot(shap_values, X_test_0)\n",
    "\n",
    "    return median_results_bad_bets, median_results_good_bets, median_results_group_1_bets, median_results_group_2_bets, median_results_group_3_bets, median_results_group_4_bets, delta, delta_extremes, median_results_bad_bets_count, median_results_good_bets_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d1e72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_model_regressor_results_shap(n=10, test_size_0=0.9, train_size_0=0.1):\n",
    "    \n",
    "    # Empty_lists\n",
    "    results_xgb_true=[] \n",
    "    results_xgb_false=[]\n",
    "    results_xgb_1=[]\n",
    "    results_xgb_2=[]\n",
    "    results_xgb_3=[]\n",
    "    results_xgb_4=[]\n",
    "    \n",
    "    # Run the model regressor X times\n",
    "    results_xgb_false, results_xgb_true, results_xgb_1, results_xgb_2, results_xgb_3, results_xgb_4 = testing_models_regressor(n,test_size_0,train_size_0)\n",
    "    \n",
    "    # Results\n",
    "    median_results_bad_bets = np.median(np.array(results_xgb_false))\n",
    "    median_results_good_bets = np.median(np.array(results_xgb_true))\n",
    "    delta = np.median(np.array(median_results_good_bets))-np.median(np.array(median_results_bad_bets))\n",
    "    delta_extremes = np.median(np.array(results_xgb_4))-np.median(np.array(results_xgb_1))\n",
    "    #print(delta, delta_extremes)\n",
    "    \n",
    "    #Plotting the results of the XGB\n",
    "\n",
    "    return delta, delta_extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179ca1a",
   "metadata": {},
   "source": [
    "## Classification Model functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2ed1f",
   "metadata": {},
   "source": [
    "### Function testing_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a19d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lr_true = []\n",
    "# results_lr_false = []\n",
    "\n",
    "def testing_models_classifier(iterations,test_size_0):   \n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while i < iterations:\n",
    "        # Split into Train/Test\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.3) # Split into Train/Test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_test_0, y_test_0_classifier, test_size=test_size_0) # Split into Train/Test\n",
    "\n",
    "            #------------------------Run the Models -----------------------------------\n",
    "\n",
    "        #Initiate XGBoost\n",
    "        m = 0\n",
    "        m = xgb.XGBClassifier()\n",
    "        \n",
    "        #Fit XGBoost\n",
    "        m.fit(X_train_0,y_train_0_classifier) \n",
    "        \n",
    "        #Make and store the predictions XGBoost\n",
    "        y_pred_test = m.predict(X_test)\n",
    "        y_pred_test_df = pd.DataFrame(y_pred_test,columns=['prediction'])\n",
    "        y_pred_train = m.predict(X_train_0)\n",
    "        y_pred_train_df = pd.DataFrame(y_pred_train)\n",
    "        y_test_df = pd.DataFrame(y_test).reset_index()\n",
    "        y_final_df = y_pred_test_df.copy()\n",
    "        y_final_df['actual'] = y_test_df['payout_under_2.5_pinacle_closing']\n",
    "\n",
    "        # accuracy\n",
    "        accuracy_test = accuracy_score(y_test,y_pred_test)\n",
    "        accuracy_train = accuracy_score(y_train_0_classifier,y_pred_train)\n",
    "        \n",
    "        # precision\n",
    "        precision_test = precision_score(y_test,y_pred_test)\n",
    "        precision_train = precision_score(y_train_0_classifier,y_pred_train)\n",
    "    \n",
    "  #------------------------Creating the bins for the predictions for both models -----------------------------------\n",
    "        #Function to replace bin with default value when it is null\n",
    "        def ifnull(var, val):\n",
    "          if var > 0:\n",
    "            return var\n",
    "          return val\n",
    "        \n",
    "        #XGB\n",
    "        #ind = np.arange(0, len(y_pred_test_df))\n",
    "        #ind = ind.tolist()\n",
    "        #y_xgb_df['ind'] = ind\n",
    "        #y_pred_test_df['ind'] = ind\n",
    "        \n",
    "        #Defining the variable bet_opp based on the y_pred of the XGB\n",
    "\n",
    "        y_final_df['payout_under_2.5_pinacle_closing'] = y_test_0.loc[y_test.index].reset_index()['payout_under_2.5_pinacle_closing']\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        #y_final_df['payout_avg_under_closing_2.5'] = 0\n",
    "\n",
    "        result_False = y_final_df[y_final_df['prediction']==False]['payout_under_2.5_pinacle_closing'].mean()\n",
    "        result_True = y_final_df[y_final_df['prediction']==True]['payout_under_2.5_pinacle_closing'].mean()\n",
    "        \n",
    "        results_False.append(result_False)\n",
    "        results_True.append(result_True)\n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "    return accuracy_test, accuracy_train, precision_train, precision_test, y_final_df,results_True, results_False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1252b4b",
   "metadata": {},
   "source": [
    "### Function checking_model_classifier_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67deb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_model_classifier_results(n=10, test_size_0=0.9):\n",
    "    \n",
    "    #empty_lists\n",
    "    results_False=[]\n",
    "    results_True=[]\n",
    "    \n",
    "    #empty_lists\n",
    "    accuracy_test, accuracy_train, precision_train, precision_test, y_final_df,results_True, results_False = testing_models_classifier(n,test_size_0)\n",
    "    median_results_bad_bets = np.median(np.array(results_False))\n",
    "    median_results_good_bets = np.median(np.array(results_True))\n",
    "    delta = median_results_good_bets-median_results_bad_bets\n",
    "    \n",
    "    #Plotting the results of the XGB\n",
    "    sns.histplot(results_True,kde=True,bins=20,color='green')\n",
    "    sns.histplot(results_False,kde=True,bins=20,color='red')\n",
    "    \n",
    "    return delta, accuracy_test, precision_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dac4f9",
   "metadata": {},
   "source": [
    "# Running the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084fdbb",
   "metadata": {},
   "source": [
    "### Define the features for the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "070423a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features_0 = ['country_div_1','country_div_2','country_div_3','country_div_4','%vig_avg_bool','Market_consensus','year_number','1.0_to_1.5','1.5_to_2.0','2.0_to_3','3_to_100']\n",
    "list_of_features = ['country_div_1','country_div_2','country_div_3','country_div_4','%vig_avg_bool','Market_consensus','year_number','1.0_to_1.5','1.5_to_2.0','2.0_to_3','3_to_100']\n",
    "odds_min_input = 1\n",
    "odds_max_input = 1000\n",
    "payout_cat = 'payout_avg_under_2.5'\n",
    "\n",
    "min_date = '2010-01-01'\n",
    "\n",
    "# year cutoffs\n",
    "year_cutoffs = [\n",
    "#['2011-09-01','2012-09-01'],\n",
    "#['2012-09-01','2013-09-01'],\n",
    "#['2013-09-01','2014-09-01'],\n",
    "#['2014-09-01','2015-09-01'],\n",
    "#['2015-09-01','2016-09-01'],\n",
    "#['2016-09-01','2017-09-01'],\n",
    "#['2017-09-01','2018-09-01'],\n",
    "#['2018-09-01','2019-09-01'],\n",
    "['2019-09-01','2020-09-01'],\n",
    "['2020-09-01','2021-09-01'],\n",
    "['2021-09-01','2022-09-01']\n",
    "]\n",
    "#payout = 'payout_avg_under_2.5', 'payout_under_2.5_pinacle_closing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "623e1318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good_bets_avg_across_years: -0.06422352044087946 bad_bets_avg_across_years: -0.0455344333607292 best_bets_avg_across_years: -0.06872113526570049 worse_bets_avg_across_years: -0.035803221342794116\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GET THE GRAPHICS + DELTAS\n",
    "\n",
    "delta_list_years = {}\n",
    "delta_extremes_years = {}\n",
    "list_1 = {}\n",
    "list_2 = {}\n",
    "list_3 = {}\n",
    "list_4 = {}\n",
    "list_bad = {}\n",
    "list_good = {}\n",
    "list_bad_count = {}\n",
    "list_good_count = {}\n",
    "\n",
    "for year_cutoff in year_cutoffs:\n",
    "    data2=data\n",
    "    #data2=data2[(data2['country_div_1']==True)] #& (data2['country_div_4']==True)] ## DELETE\n",
    "    data2['odds_max_input_condition'] = data2['Avg2<2.5']<=odds_max_input\n",
    "    data2['odds_min_input_condition'] = data2['Avg2<2.5']>=odds_min_input\n",
    "    data2 = data2[(data2['odds_max_input_condition']==True) & (data2['odds_min_input_condition']==True)]\n",
    "    data_date2 = data2['Date']\n",
    "    data_date_2 = pd.to_datetime(data_date2, dayfirst = True) \n",
    "    data2['test_dates'] = (data_date_2>=year_cutoff[0]) & (data_date_2<year_cutoff[1])\n",
    "    data2['train_dates'] = (data_date_2>=min_date) & (data_date_2<year_cutoff[0])\n",
    "     #& (data['1.0_to_1.5']==True)\n",
    "    \n",
    "    # Build the train and test datasets\n",
    "    X_train_0 = data2[data2['train_dates']==True][list_of_features]#,'year_number_ratio','month_number_ratio']]\n",
    "    X_test_0 = data2[(data2['test_dates']==True)][list_of_features]#,'year_number_ratio','month_number_ratio']]\n",
    "    y_train_0 = data2[data2['train_dates']==True][payout_cat]-1\n",
    "    y_test_0 = data2[(data2['test_dates']==True)][payout_cat]-1\n",
    "    # & (data['1.0_to_1.5']==True)\n",
    "    \n",
    "    # Storing year_number variable (to build the dictionaries)\n",
    "    year_number = X_test_0['year_number'].min()\n",
    "    \n",
    "    # null the lists\n",
    "    results_xgb_true=[] \n",
    "    results_xgb_false=[]\n",
    "    results_xgb_true_count=[] \n",
    "    results_xgb_false_count=[]\n",
    "    results_xgb_1=[]\n",
    "    results_xgb_2=[]\n",
    "    results_xgb_3=[]\n",
    "    results_xgb_4=[]\n",
    "    \n",
    "    # reinitate the test_size\n",
    "    test_size_0=0\n",
    "    train_size_0=0\n",
    "\n",
    "    # run the function -- 98% only!! fix\n",
    "    median_results_bad_bets, median_results_good_bets, median_results_group_1_bets, median_results_group_2_bets, median_results_group_3_bets, median_results_group_4_bets, delta, delta_extremes, median_results_bad_bets_count, median_results_good_bets_count = checking_model_regressor_results(1,0.80,0.80)\n",
    "    \n",
    "    # store the results\n",
    "    delta_list_years[year_number]=delta\n",
    "    delta_extremes_years[year_number]=delta_extremes\n",
    "    \n",
    "    list_1[year_number]=median_results_group_1_bets\n",
    "    list_2[year_number]=median_results_group_2_bets\n",
    "    list_3[year_number]=median_results_group_3_bets\n",
    "    list_4[year_number]=median_results_group_4_bets\n",
    "    \n",
    "    list_bad[year_number]=median_results_bad_bets\n",
    "    list_good[year_number]=median_results_good_bets\n",
    "    \n",
    "    list_bad_count[year_number]=median_results_bad_bets_count\n",
    "    list_good_count[year_number]=median_results_good_bets_count\n",
    "\n",
    "#Plotting the results of the XGB Year over Year\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,4))\n",
    "sns.lineplot(list_bad.keys(), list_bad.values(), color='red',ax=ax[0])\n",
    "sns.lineplot(list_good.keys(), list_good.values(), color='green',ax=ax[0])\n",
    "    \n",
    "sns.lineplot(list_1.keys(), list_1.values(), color='red',ax=ax[1])\n",
    "sns.lineplot(list_2.keys(), list_2.values(), color='yellow',ax=ax[1])\n",
    "sns.lineplot(list_3.keys(), list_3.values(), color='grey',ax=ax[1])\n",
    "sns.lineplot(list_4.keys(), list_4.values(), color='green',ax=ax[1])\n",
    "\n",
    "ax[0].set_ylim(-0.15,+0.15)\n",
    "ax[1].set_ylim(-0.2,+0.2)\n",
    "\n",
    "#np.array(list(delta_list_years.values())).mean(), np.array(list(delta_extremes_years.values())).mean()\n",
    "list_good_values = np.array(list(list_good.values()))\n",
    "list_good_values_without_na = [x for x in list_good_values if math.isnan(x) == False]\n",
    "good_bets_across_years_mean = np.array(list_good_values_without_na).mean()\n",
    "\n",
    "list_bad_values = np.array(list(list_bad.values()))\n",
    "list_bad_values_without_na = [x for x in list_bad_values if math.isnan(x) == False]\n",
    "bad_bets_across_years_mean = np.array(list_bad_values_without_na).mean()\n",
    "\n",
    "list_4_values = np.array(list(list_4.values()))\n",
    "list_4_values_without_na = [x for x in list_4_values if math.isnan(x) == False]\n",
    "best_bets_across_years_mean = np.array(list_4_values_without_na).mean()\n",
    "\n",
    "list_1_values = np.array(list(list_1.values()))\n",
    "list_1_values_without_na = [x for x in list_1_values if math.isnan(x) == False]\n",
    "worse_bets_across_years_mean = np.array(list_1_values_without_na).mean()\n",
    "\n",
    "print('good_bets_avg_across_years:', good_bets_across_years_mean,\n",
    "      'bad_bets_avg_across_years:', bad_bets_across_years_mean,\n",
    "      'best_bets_avg_across_years:', best_bets_across_years_mean,\n",
    "      'worse_bets_avg_across_years:', worse_bets_across_years_mean)\n",
    "#sns.histplot(results_xgb_false,kde=True,bins=20,color='red',ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a785b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857bc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab60720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE SHAP VALUES\n",
    "\n",
    "delta_list_years = {}\n",
    "delta_extremes_years = {}\n",
    "\n",
    "## Declaring TEST and TRAIN dates\n",
    "#year_cutoffs = ['2010-09-01','2011-09-01','2012-09-01','2013-09-01','2014-09-01','2015-09-01','2016-09-01','2017-09-01','2018-09-01','2019-09-01','2020-09-01','2021-09-01']\n",
    "year_cutoffs = ['2010-09-01','2011-09-01','2012-09-01','2013-09-01','2014-09-01','2015-09-01']\n",
    "\n",
    "for year_cutoff in year_cutoffs:\n",
    "    data['test_dates'] = (data_date_2>=year_cutoff) & (data_date_2<'2022-09-01')\n",
    "    data['train_dates'] = (data_date_2>='1900-09-01') & (data_date_2<year_cutoff)\n",
    "    \n",
    "    X_train_0 = data[data['train_dates']==True][['country_div_1','country_div_2','country_div_3','country_div_4','%vig_avg_bool','Market_consensus','year_number','1.0_to_1.5','1.5_to_2.0','2.0_to_3','3_to_100']]#,'year_number_ratio','month_number_ratio']]\n",
    "    X_test_0 = data[data['test_dates']==True][['country_div_1','country_div_2','country_div_3','country_div_4','%vig_avg_bool','Market_consensus','year_number','1.0_to_1.5','1.5_to_2.0','2.0_to_3','3_to_100']]#,'year_number_ratio','month_number_ratio']]\n",
    "    y_train_0 = data[data['train_dates']==True]['payout_avg_under_2.5']-1\n",
    "    y_test_0 = data[data['test_dates']==True]['payout_avg_under_2.5']-1\n",
    "    \n",
    "    # null the lists\n",
    "    results_xgb_true=[] \n",
    "    results_xgb_false=[]\n",
    "    results_xgb_1=[]\n",
    "    results_xgb_2=[]\n",
    "    results_xgb_3=[]\n",
    "    results_xgb_4=[]\n",
    "    \n",
    "    # reinitate the test_size\n",
    "    test_size_0=0\n",
    "    train_size_0=0\n",
    "\n",
    "    # run the function\n",
    "    delta, delta_extremes = checking_model_regressor_results_shap(10,0.999,0.999)\n",
    "    \n",
    "    # SHAP values\n",
    "    my_model = xgb.XGBRegressor()\n",
    "    my_model.fit(X_train_0,y_train_0)\n",
    "    explainer = shap.TreeExplainer(my_model)\n",
    "    shap_values = explainer.shap_values(X_test_0)\n",
    "    shap.summary_plot(shap_values, X_test_0)\n",
    "    \n",
    "    delta_list_years[year_cutoff]=delta\n",
    "    delta_extremes_years[year_cutoff]=delta_extremes\n",
    "    #delta_list_years.append(delta)\n",
    "    #delta_extremes_years.append(delta_extremes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINNACLE\n",
    "\n",
    "# Reset the indices\n",
    "#data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Regressor Model variables\n",
    "X_train_0 = data[data['train_dates']==True][['country_div_1','country_div_2','country_div_3','country_div_4','%vig_avg_bool','Market_consensus','year_number','1.0_to_1.5','1.5_to_2.0','2.0_to_3','3_to_100']]#,'year_number_ratio','month_number_ratio']]\n",
    "X_test_0 = data[data['test_dates']==True][['country_div_1','country_div_2','country_div_3','country_div_4','%vig_avg_bool','Market_consensus','year_number','1.0_to_1.5','1.5_to_2.0','2.0_to_3','3_to_100']]#,'year_number_ratio','month_number_ratio']]\n",
    "y_train_0 = data[data['train_dates']==True]['payout_avg_under_2.5']-1\n",
    "y_test_0 = data[data['test_dates']==True]['payout_avg_under_2.5']-1\n",
    "\n",
    "# Classifier Model variables\n",
    "#y_test_0_classifier = data[data['test_dates']==True]['payout_under_2.5_pinacle_closing']!=0\n",
    "#y_train_0_classifier = data[data['train_dates']==True]['payout_under_2.5_pinacle_closing']!=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aba1bc",
   "metadata": {},
   "source": [
    "### Run Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e8ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## RUN THE WHOLE CELL #\n",
    "\n",
    "# We need to run this to null the lists\n",
    "results_xgb_true=[] \n",
    "results_xgb_false=[]\n",
    "results_xgb_1=[]\n",
    "results_xgb_2=[]\n",
    "results_xgb_3=[]\n",
    "results_xgb_4=[]\n",
    "    \n",
    "#We need to run this to reinitate the test_size\n",
    "test_size_0=0\n",
    "train_size_0=0\n",
    "\n",
    "# We need to run the function -> first: # of tests, second: test size (cannot be 1!), third: train size (cannot be 1!)\n",
    "checking_model_regressor_results(10,0.999,0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90f98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the SHAP values for the Regression model\n",
    "\n",
    "my_model = xgb.XGBRegressor()\n",
    "my_model.fit(X_train_0,y_train_0)\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "shap_values = explainer.shap_values(X_test_0)\n",
    "shap.summary_plot(shap_values, X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02b4f6",
   "metadata": {},
   "source": [
    "### Run Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THE WHOLE CELL #\n",
    "\n",
    "# We need to run this to null the lists\n",
    "results_False=[]\n",
    "results_True=[]\n",
    "    \n",
    "#We need to run this to reinitate the test_size\n",
    "test_size_0=0\n",
    "\n",
    "# We need to run the function -> first argument is the # of tests, second one is the size of test\n",
    "checking_model_classifier_results(20,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4279cf1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Comments regarding results of the tests we ran and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd443a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Comments\n",
    "\n",
    "# baseline = 0.008297694850435258 (all features)\n",
    "\n",
    "# delta without Joao features = 0.014419296789770412 => F:-0.029970666611150436 and T:-0.015551369821380024\n",
    "# --> WE REMOVE JOAO FEATURE\n",
    "\n",
    "# delta when removing the odds buckets = -0.009317543146000251 => F:-0.022611272813043187 and T:-0.028804787343669917\n",
    "# --> WE KEEP THE ODDS BUCKETS\n",
    "\n",
    "# delta when removing the odds buckets = -0.009317543146000251 => F:-0.022611272813043187 and T:-0.028804787343669917\n",
    "# --> WE KEEP THE ODDS BUCKETS\n",
    "\n",
    "# delta when removing the countries and divisions = 0.004795286566703704\n",
    "# --> WE KEEP THE COUNTRIES AND DIVISIONS\n",
    "\n",
    "# delta when removing the divisions but keeping the countries = 0.008380480363148559 (worsening)\n",
    "# delta when removing the countries but keeping the divisions = 0.02259680830123266 (best score ever)\n",
    "# --> WE KEEP THE DIVSIONS AND REMOVE THE COUNTRIES\n",
    "\n",
    "# delta when removing the 'month_after_July': 0.013657154854343441 DECREASED A LOT! We keep month after July\n",
    "# year 2020_2021 = 0.012829398919170131 DECREASED A LOT! \n",
    "# TIME MATTERS!! We need months, years, time\n",
    "\n",
    "# New basline: 0.023917075840908224\n",
    "\n",
    "#'Pin pays better' does not improve the baseline and we remove it\n",
    "\n",
    "#'Market_consensus' MATTERS we keep it\n",
    "\n",
    "#VIG matters\n",
    "\n",
    "# We should remove the P<PC variable\n",
    "# BEST DELTA: 0.03151890594630853\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3ddff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Next steps:\n",
    "\n",
    "## Time: Further explore how to optimise the features of time (years, months, hours, etc.)\n",
    "## Odds: Further explore how to optimise the odds buckets (different bins, min-max scaling)\n",
    "## VIG + Mkt Consensus: Further explore how to optimise VIG + Market consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db8eb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70fd7a8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# [SKIP] Other models + stats package we could use [SKIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c50b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1a60e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_model = xgb.XGBRegressor()\n",
    "my_model.fit(X_train_0,y_train_0) \n",
    "        \n",
    "        #Make and store the predictions XGBoost\n",
    "       # y_pred_xgb = m.predict(X_test)\n",
    "       # y_pred_xgb = pd.DataFrame(y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ac051",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#my_model = RandomForestRegressor(random_state=0).fit(X_step_joao, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92f724",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = my_model.predict(X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1128b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4b403",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_test_0)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values, X_test_0)\n",
    "\n",
    "#- Vertical location shows what feature it is depicting\n",
    "#- Color shows whether that feature was high or low for that row of the dataset\n",
    "#- Horizontal location shows whether the effect of that value caused a higher or lower prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a37281",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_0, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b968f9",
   "metadata": {},
   "source": [
    "# [SKIP] Features selection [SKIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Selection function (TO BE CREATED)\n",
    "\n",
    "# iterables = [[feature_1], [feature_2], [feature_3]]\n",
    "\n",
    "# for t in itertools.product(*iterables):\n",
    "#     print (t)\n",
    "\n",
    "# feature_1 = ['1.0_to_1.5', '1.5_to_2.0', '2.0_to_3.0','3.0_to_99999.0']\n",
    "# feature_2 = ['country_div_1','country_div_2','country_div_3','country_div_4']\n",
    "# feature_3 = ['month_after_July']\n",
    "# feature_4 = ['year_2021_2022']\n",
    "# feature_5 = ['game_starts_after_4pm']\n",
    "# feature_6 = ['Market_consensus']\n",
    "# feature_7 = ['%vig_p_bool']\n",
    "# feature_8 = ['payout_under_2.5_pinacle_closing']\n",
    "\n",
    "# list_features = [feature_1,feature_2,feature_3,feature_4,feature_5,feature_6,feature_7,feature_8]\n",
    "\n",
    "# from itertools import combinations\n",
    "# sample_list = list_features\n",
    "# list_combinations = list()\n",
    "# for n in range(len(sample_list) + 1):\n",
    "#     list_combinations += list(combinations(sample_list, n))\n",
    "# print(list_combinations)\n",
    "\n",
    "# list_combinations\n",
    "\n",
    "# ls = list(list_combinations)\n",
    "# flat_ls = [item for sublist in ls for item in sublist]\n",
    "\n",
    "# a = list(list_combinations[3])\n",
    "\n",
    "# mylist = list(list_combinations[3])\n",
    "# [item[0] for item in mylist]\n",
    "\n",
    "# list_features_array = np.array(list_features)\n",
    "\n",
    "# list_features_array\n",
    "\n",
    "# np.multiply(x[0]*list_features_array)\n",
    "\n",
    "# from itertools import product\n",
    "# import numpy as np\n",
    "\n",
    "# n = 2\n",
    "\n",
    "# x = product([1, 0], repeat=n)\n",
    "# x = np.reshape(list(x), (-1, n))\n",
    "# print(x)\n",
    "\n",
    "# i=1\n",
    "# #while i < 3:\n",
    "# feature_selection_1 = x[0]*list_features_array[i]\n",
    "# i=i=1\n",
    "# final_feature_selection = feature_selection_1+feature_selection_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
